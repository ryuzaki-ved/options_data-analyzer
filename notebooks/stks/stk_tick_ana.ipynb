{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45861f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "File path: D:\\Market Projects\\options_data_analyzer\\Aug '25\\Aug 07 Exp\\07 Aug\\BEL_EQ.csv\n",
      "Shape: (18250, 5)\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr']\n",
      "\n",
      "First few rows:\n",
      "                     date   price    qty        trnvr    cum_trnvr\n",
      "0  2025-08-07 09:15:00 AM  386.85  65740  25431519.00  25431519.00\n",
      "1  2025-08-07 09:15:01 AM  386.65      0         0.00  25431519.00\n",
      "2  2025-08-07 09:15:01 AM  386.30      0         0.00  25431519.00\n",
      "3  2025-08-07 09:15:01 AM  386.30    895    345738.50  25777257.50\n",
      "4  2025-08-07 09:15:01 AM  386.75   1401    541836.75  26319094.25\n",
      "\n",
      "Data types:\n",
      "date          object\n",
      "price        float64\n",
      "qty            int64\n",
      "trnvr        float64\n",
      "cum_trnvr    float64\n",
      "dtype: object\n",
      "\n",
      "Basic statistics:\n",
      "              price            qty         trnvr     cum_trnvr\n",
      "count  18250.000000   18250.000000  1.825000e+04  1.825000e+04\n",
      "mean     386.537181     630.694301  2.439435e+05  2.317732e+09\n",
      "std        1.570300    2651.792039  1.026096e+06  1.129666e+09\n",
      "min      383.500000       0.000000  0.000000e+00  2.543152e+07\n",
      "25%      385.150000       0.000000  0.000000e+00  1.473757e+09\n",
      "50%      386.400000      10.000000  3.850250e+03  2.248665e+09\n",
      "75%      387.950000     331.000000  1.284426e+05  3.123428e+09\n",
      "max      390.200000  153858.000000  5.955074e+07  4.451969e+09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"D:\\Market Projects\\options_data_analyzer\\Aug '25\\Aug 07 Exp\\07 Aug\\BEL_EQ.csv\"\n",
    "\n",
    "# Load CSV with pandas\n",
    "# Using default encoding (utf-8) and comma delimiter\n",
    "# The file appears to have standard CSV format\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the loaded data\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"File path: {file_path}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc1406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FIRST 10 ROWS ===\n",
      "                     date   price    qty        trnvr    cum_trnvr\n",
      "0  2025-08-07 09:15:00 AM  386.85  65740  25431519.00  25431519.00\n",
      "1  2025-08-07 09:15:01 AM  386.65      0         0.00  25431519.00\n",
      "2  2025-08-07 09:15:01 AM  386.30      0         0.00  25431519.00\n",
      "3  2025-08-07 09:15:01 AM  386.30    895    345738.50  25777257.50\n",
      "4  2025-08-07 09:15:01 AM  386.75   1401    541836.75  26319094.25\n",
      "5  2025-08-07 09:15:02 AM  386.80   1795    694306.00  27013400.25\n",
      "6  2025-08-07 09:15:02 AM  386.95    741    286729.95  27300130.20\n",
      "7  2025-08-07 09:15:03 AM  386.85      0         0.00  27300130.20\n",
      "8  2025-08-07 09:15:03 AM  386.50      0         0.00  27300130.20\n",
      "9  2025-08-07 09:15:03 AM  386.90   2717   1051207.30  28351337.50\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== LAST 10 ROWS ===\n",
      "                         date   price   qty       trnvr     cum_trnvr\n",
      "18240  2025-08-07 03:29:31 PM  388.25   226    87744.50  4.446928e+09\n",
      "18241  2025-08-07 03:29:31 PM  388.10     0        0.00  4.446928e+09\n",
      "18242  2025-08-07 03:29:37 PM  388.25  2075   805618.75  4.447734e+09\n",
      "18243  2025-08-07 03:29:39 PM  388.30  1157   449263.10  4.448183e+09\n",
      "18244  2025-08-07 03:29:41 PM  388.10     0        0.00  4.448183e+09\n",
      "18245  2025-08-07 03:29:44 PM  388.25  1183   459299.75  4.448643e+09\n",
      "18246  2025-08-07 03:29:46 PM  388.25   958   371943.50  4.449015e+09\n",
      "18247  2025-08-07 03:29:51 PM  388.25  5331  2069760.75  4.451084e+09\n",
      "18248  2025-08-07 03:29:52 PM  388.25   539   209266.75  4.451294e+09\n",
      "18249  2025-08-07 03:29:58 PM  388.25  1740   675555.00  4.451969e+09\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== CHRONOLOGICAL ORDER CHECK ===\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "✓ Data is in CHRONOLOGICAL order (ascending)\n",
      "  - First row: Earliest time\n",
      "  - Last row: Latest time\n",
      "\n",
      "Total time range: 0 days 06:14:58\n"
     ]
    }
   ],
   "source": [
    "# Preview first and last 10 rows to check ordering\n",
    "print(\"=== FIRST 10 ROWS ===\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"=== LAST 10 ROWS ===\")\n",
    "print(df.tail(10))\n",
    "\n",
    "# Check if data is in chronological order\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"=== CHRONOLOGICAL ORDER CHECK ===\")\n",
    "\n",
    "# Convert date column to datetime if not already\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Check first and last timestamps\n",
    "first_time = df['date'].iloc[0]\n",
    "last_time = df['date'].iloc[-1]\n",
    "\n",
    "print(f\"First timestamp: {first_time}\")\n",
    "print(f\"Last timestamp: {last_time}\")\n",
    "\n",
    "# Check if chronological (ascending) or reverse chronological (descending)\n",
    "if first_time < last_time:\n",
    "    print(\"✓ Data is in CHRONOLOGICAL order (ascending)\")\n",
    "    print(\"  - First row: Earliest time\")\n",
    "    print(\"  - Last row: Latest time\")\n",
    "else:\n",
    "    print(\"✗ Data is in REVERSE CHRONOLOGICAL order (descending)\")\n",
    "    print(\"  - First row: Latest time\")\n",
    "    print(\"  - Last row: Earliest time\")\n",
    "\n",
    "# Show time range\n",
    "time_range = last_time - first_time\n",
    "print(f\"\\nTotal time range: {time_range}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17543f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATETIME CONVERSION AND FEATURE EXTRACTION ===\n",
      "New datetime features added:\n",
      "  - date_only: object\n",
      "  - time: object\n",
      "  - hour: int32\n",
      "  - minute: int32\n",
      "  - second: int32\n",
      "\n",
      "=== SAMPLE DATA WITH NEW FEATURES ===\n",
      "                 date   date_only      time  hour  minute  second   price  \\\n",
      "0 2025-08-07 09:15:00  2025-08-07  09:15:00     9      15       0  386.85   \n",
      "1 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.65   \n",
      "2 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.30   \n",
      "3 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.30   \n",
      "4 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.75   \n",
      "5 2025-08-07 09:15:02  2025-08-07  09:15:02     9      15       2  386.80   \n",
      "6 2025-08-07 09:15:02  2025-08-07  09:15:02     9      15       2  386.95   \n",
      "7 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.85   \n",
      "8 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.50   \n",
      "9 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.90   \n",
      "\n",
      "     qty  \n",
      "0  65740  \n",
      "1      0  \n",
      "2      0  \n",
      "3    895  \n",
      "4   1401  \n",
      "5   1795  \n",
      "6    741  \n",
      "7      0  \n",
      "8      0  \n",
      "9   2717  \n",
      "\n",
      "=== DATETIME VERIFICATION ===\n",
      "Original date column dtype: datetime64[ns]\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "Total unique dates: 1\n",
      "Date range: 2025-08-07 to 2025-08-07\n"
     ]
    }
   ],
   "source": [
    "# Convert date to datetime64[ns] and extract datetime features\n",
    "print(\"=== DATETIME CONVERSION AND FEATURE EXTRACTION ===\")\n",
    "\n",
    "# Convert date column to datetime64[ns]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract additional datetime features\n",
    "df['date_only'] = df['date'].dt.date\n",
    "df['time'] = df['date'].dt.time\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "df['second'] = df['date'].dt.second\n",
    "\n",
    "# Display the new datetime features\n",
    "print(\"New datetime features added:\")\n",
    "print(f\"  - date_only: {df['date_only'].dtype}\")\n",
    "print(f\"  - time: {df['time'].dtype}\")\n",
    "print(f\"  - hour: {df['hour'].dtype}\")\n",
    "print(f\"  - minute: {df['minute'].dtype}\")\n",
    "print(f\"  - second: {df['second'].dtype}\")\n",
    "\n",
    "# Show sample of the enhanced dataframe\n",
    "print(\"\\n=== SAMPLE DATA WITH NEW FEATURES ===\")\n",
    "print(df[['date', 'date_only', 'time', 'hour', 'minute', 'second', 'price', 'qty']].head(10))\n",
    "\n",
    "# Verify datetime conversion\n",
    "print(f\"\\n=== DATETIME VERIFICATION ===\")\n",
    "print(f\"Original date column dtype: {df['date'].dtype}\")\n",
    "print(f\"First timestamp: {df['date'].iloc[0]}\")\n",
    "print(f\"Last timestamp: {df['date'].iloc[-1]}\")\n",
    "print(f\"Total unique dates: {df['date_only'].nunique()}\")\n",
    "print(f\"Date range: {df['date_only'].min()} to {df['date_only'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2229a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HANDLING ZERO-QUANTITY TRADES ===\n",
      "Original data shape: (18250, 10)\n",
      "Rows with zero quantity: 7294\n",
      "Percentage of zero qty rows: 39.97%\n",
      "\n",
      "=== SAMPLE OF ZERO QTY ROWS (BEFORE REMOVAL) ===\n",
      "                  date   price  qty  trnvr    cum_trnvr\n",
      "1  2025-08-07 09:15:01  386.65    0    0.0  25431519.00\n",
      "2  2025-08-07 09:15:01  386.30    0    0.0  25431519.00\n",
      "7  2025-08-07 09:15:03  386.85    0    0.0  27300130.20\n",
      "8  2025-08-07 09:15:03  386.50    0    0.0  27300130.20\n",
      "13 2025-08-07 09:15:05  386.45    0    0.0  32995767.85\n",
      "\n",
      "=== AFTER CLEANING ===\n",
      "Cleaned data shape: (10956, 10)\n",
      "Rows removed: 7294\n",
      "Remaining rows: 10956\n",
      "\n",
      "=== SAMPLE OF CLEANED DATA ===\n",
      "                 date   price    qty        trnvr    cum_trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30    895    345738.50  25777257.50\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75  26319094.25\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00  27013400.25\n",
      "4 2025-08-07 09:15:02  386.95    741    286729.95  27300130.20\n",
      "5 2025-08-07 09:15:03  386.90   2717   1051207.30  28351337.50\n",
      "6 2025-08-07 09:15:03  386.80   9068   3507502.40  31858839.90\n",
      "7 2025-08-07 09:15:04  386.75   1141    441281.75  32300121.65\n",
      "8 2025-08-07 09:15:04  386.90   1798    695646.20  32995767.85\n",
      "9 2025-08-07 09:15:05  386.65   2092    808871.80  33804639.65\n",
      "\n",
      "Zero qty rows remaining: 0\n",
      "\n",
      "✓ Main dataframe 'df' now contains 10956 rows with non-zero quantities\n"
     ]
    }
   ],
   "source": [
    "# Handle zero-quantity trades - remove rows with 0 qty\n",
    "print(\"=== HANDLING ZERO-QUANTITY TRADES ===\")\n",
    "\n",
    "# Check current data shape and zero qty count\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "zero_qty_count = (df['qty'] == 0).sum()\n",
    "print(f\"Rows with zero quantity: {zero_qty_count}\")\n",
    "print(f\"Percentage of zero qty rows: {(zero_qty_count/len(df)*100):.2f}%\")\n",
    "\n",
    "# Show sample of zero qty rows before removal\n",
    "print(\"\\n=== SAMPLE OF ZERO QTY ROWS (BEFORE REMOVAL) ===\")\n",
    "zero_qty_sample = df[df['qty'] == 0][['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(5)\n",
    "print(zero_qty_sample)\n",
    "\n",
    "# Remove rows with zero quantity\n",
    "df_clean = df[df['qty'] > 0].copy()\n",
    "\n",
    "# Reset index after filtering\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "# Display results after cleaning\n",
    "print(f\"\\n=== AFTER CLEANING ===\")\n",
    "print(f\"Cleaned data shape: {df_clean.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")\n",
    "print(f\"Remaining rows: {len(df_clean)}\")\n",
    "\n",
    "# Show sample of cleaned data\n",
    "print(\"\\n=== SAMPLE OF CLEANED DATA ===\")\n",
    "print(df_clean[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(10))\n",
    "\n",
    "# Verify no zero qty rows remain\n",
    "remaining_zero_qty = (df_clean['qty'] == 0).sum()\n",
    "print(f\"\\nZero qty rows remaining: {remaining_zero_qty}\")\n",
    "\n",
    "# Update the main dataframe reference\n",
    "df = df_clean\n",
    "print(f\"\\n✓ Main dataframe 'df' now contains {len(df)} rows with non-zero quantities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73b099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NUMERIC COLUMN VALIDATION ===\n",
      "=== NEGATIVE VALUE CHECK ===\n",
      "price: 0 negative values\n",
      "qty: 0 negative values\n",
      "trnvr: 0 negative values\n",
      "cum_trnvr: 0 negative values\n",
      "\n",
      "=== ZERO VALUE CHECK ===\n",
      "price: 0 zero values\n",
      "qty: 0 zero values\n",
      "trnvr: 0 zero values\n",
      "cum_trnvr: 0 zero values\n",
      "\n",
      "=== STATISTICAL SUMMARY ===\n",
      "              price            qty         trnvr     cum_trnvr\n",
      "count  10956.000000   10956.000000  1.095600e+04  1.095600e+04\n",
      "mean     386.561094    1050.581508  4.063499e+05  2.377823e+09\n",
      "std        1.574324    3357.505716  1.299189e+06  1.165181e+09\n",
      "min      383.500000       1.000000  3.836000e+02  2.543152e+07\n",
      "25%      385.150000      26.000000  1.003177e+04  1.490814e+09\n",
      "50%      386.450000     200.000000  7.732500e+04  2.355502e+09\n",
      "75%      387.950000     799.000000  3.085895e+05  3.321858e+09\n",
      "max      390.200000  153858.000000  5.955074e+07  4.451969e+09\n",
      "\n",
      "=== OUTLIER DETECTION (IQR METHOD) ===\n",
      "\n",
      "price:\n",
      "  Q1: 385.15, Q3: 387.95, IQR: 2.80\n",
      "  Lower bound: 380.95, Upper bound: 392.15\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 0\n",
      "\n",
      "qty:\n",
      "  Q1: 26.00, Q3: 799.00, IQR: 773.00\n",
      "  Lower bound: -1133.50, Upper bound: 1958.50\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 1337\n",
      "\n",
      "trnvr:\n",
      "  Q1: 10031.77, Q3: 308589.53, IQR: 298557.75\n",
      "  Lower bound: -437804.85, Upper bound: 756426.15\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 1340\n",
      "\n",
      "cum_trnvr:\n",
      "  Q1: 1490814230.85, Q3: 3321857538.50, IQR: 1831043307.65\n",
      "  Lower bound: -1255750730.62, Upper bound: 6068422499.97\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 0\n",
      "\n",
      "=== EXTREME VALUE CHECK (3 STD DEV) ===\n",
      "\n",
      "price:\n",
      "  Mean: 386.56, Std: 1.57\n",
      "  Lower 3σ: 381.84, Upper 3σ: 391.28\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 0\n",
      "\n",
      "qty:\n",
      "  Mean: 1050.58, Std: 3357.51\n",
      "  Lower 3σ: -9021.94, Upper 3σ: 11123.10\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 148\n",
      "\n",
      "trnvr:\n",
      "  Mean: 406349.86, Std: 1299188.95\n",
      "  Lower 3σ: -3491216.99, Upper 3σ: 4303916.71\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 149\n",
      "\n",
      "cum_trnvr:\n",
      "  Mean: 2377822586.83, Std: 1165180692.88\n",
      "  Lower 3σ: -1117719491.81, Upper 3σ: 5873364665.46\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 0\n",
      "\n",
      "=== SAMPLE OF POTENTIAL OUTLIERS ===\n",
      "\n",
      "qty outliers (top 5):\n",
      "                  date    qty    qty        trnvr\n",
      "0  2025-08-07 09:15:00  65740  65740  25431519.00\n",
      "5  2025-08-07 09:15:03   2717   2717   1051207.30\n",
      "6  2025-08-07 09:15:03   9068   9068   3507502.40\n",
      "9  2025-08-07 09:15:05   2092   2092    808871.80\n",
      "11 2025-08-07 09:15:06   4519   4519   1747271.35\n",
      "\n",
      "trnvr outliers (top 5):\n",
      "                  date        trnvr    qty        trnvr\n",
      "0  2025-08-07 09:15:00  25431519.00  65740  25431519.00\n",
      "5  2025-08-07 09:15:03   1051207.30   2717   1051207.30\n",
      "6  2025-08-07 09:15:03   3507502.40   9068   3507502.40\n",
      "9  2025-08-07 09:15:05    808871.80   2092    808871.80\n",
      "11 2025-08-07 09:15:06   1747271.35   4519   1747271.35\n",
      "\n",
      "=== DATA QUALITY SUMMARY ===\n",
      "Total rows: 10956\n",
      "Columns with potential issues:\n",
      "  price: ✓ clean\n",
      "  qty: ✓ clean\n",
      "  trnvr: ✓ clean\n",
      "  cum_trnvr: ✓ clean\n"
     ]
    }
   ],
   "source": [
    "# Validate numeric columns for negatives or outliers\n",
    "print(\"=== NUMERIC COLUMN VALIDATION ===\")\n",
    "\n",
    "# List of numeric columns to validate\n",
    "numeric_cols = ['price', 'qty', 'trnvr', 'cum_trnvr']\n",
    "\n",
    "# Check for negative values\n",
    "print(\"=== NEGATIVE VALUE CHECK ===\")\n",
    "for col in numeric_cols:\n",
    "    negative_count = (df[col] < 0).sum()\n",
    "    print(f\"{col}: {negative_count} negative values\")\n",
    "\n",
    "# Check for zero values (after qty cleaning)\n",
    "print(\"\\n=== ZERO VALUE CHECK ===\")\n",
    "for col in numeric_cols:\n",
    "    zero_count = (df[col] == 0).sum()\n",
    "    print(f\"{col}: {zero_count} zero values\")\n",
    "\n",
    "# Statistical summary for outlier detection\n",
    "print(\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Outlier detection using IQR method\n",
    "print(\"\\n=== OUTLIER DETECTION (IQR METHOD) ===\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_lower = (df[col] < lower_bound).sum()\n",
    "    outliers_upper = (df[col] > upper_bound).sum()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "    print(f\"  Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
    "    print(f\"  Outliers below lower bound: {outliers_lower}\")\n",
    "    print(f\"  Outliers above upper bound: {outliers_upper}\")\n",
    "\n",
    "# Check for extreme values (beyond 3 standard deviations)\n",
    "print(\"\\n=== EXTREME VALUE CHECK (3 STD DEV) ===\")\n",
    "for col in numeric_cols:\n",
    "    mean_val = df[col].mean()\n",
    "    std_val = df[col].std()\n",
    "    \n",
    "    lower_3std = mean_val - 3 * std_val\n",
    "    upper_3std = mean_val + 3 * std_val\n",
    "    \n",
    "    extreme_lower = (df[col] < lower_3std).sum()\n",
    "    extreme_upper = (df[col] > upper_3std).sum()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {mean_val:.2f}, Std: {std_val:.2f}\")\n",
    "    print(f\"  Lower 3σ: {lower_3std:.2f}, Upper 3σ: {upper_3std:.2f}\")\n",
    "    print(f\"  Extreme values below: {extreme_lower}\")\n",
    "    print(f\"  Extreme values above: {extreme_upper}\")\n",
    "\n",
    "# Show sample of potential outliers\n",
    "print(\"\\n=== SAMPLE OF POTENTIAL OUTLIERS ===\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[df[col] > upper_bound]\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"\\n{col} outliers (top 5):\")\n",
    "        print(outliers[['date', col, 'qty', 'trnvr']].head())\n",
    "\n",
    "# Data quality summary\n",
    "print(\"\\n=== DATA QUALITY SUMMARY ===\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Columns with potential issues:\")\n",
    "for col in numeric_cols:\n",
    "    issues = []\n",
    "    if (df[col] < 0).any():\n",
    "        issues.append(\"negative values\")\n",
    "    if (df[col] == 0).any() and col != 'qty':  # qty can legitimately be 0\n",
    "        issues.append(\"zero values\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"  {col}: {', '.join(issues)}\")\n",
    "    else:\n",
    "        print(f\"  {col}: ✓ clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fe8c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TIME-SERIES INTEGRITY CHECK AND SORTING ===\n",
      "=== CURRENT SORTING STATUS ===\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "Data is already sorted chronologically: True\n",
      "Duplicate timestamps: 1961\n",
      "\n",
      "=== DUPLICATE TIMESTAMP ANALYSIS ===\n",
      "Sample duplicate timestamps:\n",
      "                  date   price   qty       trnvr\n",
      "1  2025-08-07 09:15:01  386.30   895   345738.50\n",
      "2  2025-08-07 09:15:01  386.75  1401   541836.75\n",
      "3  2025-08-07 09:15:02  386.80  1795   694306.00\n",
      "4  2025-08-07 09:15:02  386.95   741   286729.95\n",
      "5  2025-08-07 09:15:03  386.90  2717  1051207.30\n",
      "6  2025-08-07 09:15:03  386.80  9068  3507502.40\n",
      "7  2025-08-07 09:15:04  386.75  1141   441281.75\n",
      "8  2025-08-07 09:15:04  386.90  1798   695646.20\n",
      "9  2025-08-07 09:15:05  386.65  2092   808871.80\n",
      "10 2025-08-07 09:15:05  386.75  1679   649353.25\n",
      "\n",
      "=== SORTING DATA BY DATETIME ===\n",
      "Data is now sorted chronologically: True\n",
      "\n",
      "=== SORTING VERIFICATION ===\n",
      "First 5 rows after sorting:\n",
      "                 date   price    qty        trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30    895    345738.50\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00\n",
      "4 2025-08-07 09:15:02  386.95    741    286729.95\n",
      "\n",
      "Last 5 rows after sorting:\n",
      "                     date   price   qty       trnvr\n",
      "10951 2025-08-07 15:29:44  388.25  1183   459299.75\n",
      "10952 2025-08-07 15:29:46  388.25   958   371943.50\n",
      "10953 2025-08-07 15:29:51  388.25  5331  2069760.75\n",
      "10954 2025-08-07 15:29:52  388.25   539   209266.75\n",
      "10955 2025-08-07 15:29:58  388.25  1740   675555.00\n",
      "\n",
      "=== TIME SERIES CONTINUITY CHECK ===\n",
      "Time differences between consecutive rows:\n",
      "  Min: 0 days 00:00:00\n",
      "  Max: 0 days 00:00:12\n",
      "  Mean: 0 days 00:00:02.053674121\n",
      "  Most common: 0 days 00:00:01\n",
      "\n",
      "✓ Main dataframe 'df' is now properly sorted chronologically\n",
      "✓ Total rows: 10956\n",
      "✓ Time range: 2025-08-07 09:15:00 to 2025-08-07 15:29:58\n",
      "\n",
      "=== FINAL VERIFICATION ===\n",
      "✓ Data is sorted chronologically\n",
      "✓ Index is reset and sequential\n",
      "✓ Ready for time-series analysis\n"
     ]
    }
   ],
   "source": [
    "# Ensure sorting by datetime for time-series integrity\n",
    "print(\"=== TIME-SERIES INTEGRITY CHECK AND SORTING ===\")\n",
    "\n",
    "# Check current sorting status\n",
    "print(\"=== CURRENT SORTING STATUS ===\")\n",
    "print(f\"First timestamp: {df['date'].iloc[0]}\")\n",
    "print(f\"Last timestamp: {df['date'].iloc[-1]}\")\n",
    "\n",
    "# Check if data is already sorted\n",
    "is_sorted = df['date'].is_monotonic_increasing\n",
    "print(f\"Data is already sorted chronologically: {is_sorted}\")\n",
    "\n",
    "# Check for any duplicate timestamps\n",
    "duplicate_timestamps = df['date'].duplicated().sum()\n",
    "print(f\"Duplicate timestamps: {duplicate_timestamps}\")\n",
    "\n",
    "if duplicate_timestamps > 0:\n",
    "    print(\"\\n=== DUPLICATE TIMESTAMP ANALYSIS ===\")\n",
    "    duplicate_samples = df[df['date'].duplicated(keep=False)].sort_values('date')\n",
    "    print(\"Sample duplicate timestamps:\")\n",
    "    print(duplicate_samples[['date', 'price', 'qty', 'trnvr']].head(10))\n",
    "\n",
    "# Sort the dataframe by datetime\n",
    "print(\"\\n=== SORTING DATA BY DATETIME ===\")\n",
    "df_sorted = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Verify sorting\n",
    "is_now_sorted = df_sorted['date'].is_monotonic_increasing\n",
    "print(f\"Data is now sorted chronologically: {is_now_sorted}\")\n",
    "\n",
    "# Display sorting verification\n",
    "print(f\"\\n=== SORTING VERIFICATION ===\")\n",
    "print(\"First 5 rows after sorting:\")\n",
    "print(df_sorted[['date', 'price', 'qty', 'trnvr']].head())\n",
    "print(f\"\\nLast 5 rows after sorting:\")\n",
    "print(df_sorted[['date', 'price', 'qty', 'trnvr']].tail())\n",
    "\n",
    "# Check for any time gaps or irregularities\n",
    "print(f\"\\n=== TIME SERIES CONTINUITY CHECK ===\")\n",
    "time_diffs = df_sorted['date'].diff().dropna()\n",
    "print(f\"Time differences between consecutive rows:\")\n",
    "print(f\"  Min: {time_diffs.min()}\")\n",
    "print(f\"  Max: {time_diffs.max()}\")\n",
    "print(f\"  Mean: {time_diffs.mean()}\")\n",
    "print(f\"  Most common: {time_diffs.mode().iloc[0] if len(time_diffs.mode()) > 0 else 'N/A'}\")\n",
    "\n",
    "# Check for any large time gaps\n",
    "large_gaps = time_diffs[time_diffs > pd.Timedelta(minutes=5)]\n",
    "if len(large_gaps) > 0:\n",
    "    print(f\"\\n⚠️  Found {len(large_gaps)} time gaps larger than 5 minutes:\")\n",
    "    gap_indices = time_diffs[time_diffs > pd.Timedelta(minutes=5)].index\n",
    "    for idx in gap_indices[:5]:  # Show first 5 gaps\n",
    "        gap_start = df_sorted.loc[idx-1, 'date']\n",
    "        gap_end = df_sorted.loc[idx, 'date']\n",
    "        gap_duration = gap_end - gap_start\n",
    "        print(f\"  Gap: {gap_start} to {gap_end} (Duration: {gap_duration})\")\n",
    "\n",
    "# Update the main dataframe with sorted version\n",
    "df = df_sorted\n",
    "print(f\"\\n✓ Main dataframe 'df' is now properly sorted chronologically\")\n",
    "print(f\"✓ Total rows: {len(df)}\")\n",
    "print(f\"✓ Time range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "# Final verification\n",
    "print(f\"\\n=== FINAL VERIFICATION ===\")\n",
    "print(\"✓ Data is sorted chronologically\")\n",
    "print(\"✓ Index is reset and sequential\")\n",
    "print(\"✓ Ready for time-series analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64545d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd6431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881a59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a43503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17d8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01afc28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
