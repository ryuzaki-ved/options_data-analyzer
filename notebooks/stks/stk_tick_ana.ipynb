{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45861f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "File path: D:\\Market Projects\\options_data_analyzer\\Aug '25\\Aug 07 Exp\\07 Aug\\BEL_EQ.csv\n",
      "Shape: (18250, 5)\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr']\n",
      "\n",
      "First few rows:\n",
      "                     date   price    qty        trnvr    cum_trnvr\n",
      "0  2025-08-07 09:15:00 AM  386.85  65740  25431519.00  25431519.00\n",
      "1  2025-08-07 09:15:01 AM  386.65      0         0.00  25431519.00\n",
      "2  2025-08-07 09:15:01 AM  386.30      0         0.00  25431519.00\n",
      "3  2025-08-07 09:15:01 AM  386.30    895    345738.50  25777257.50\n",
      "4  2025-08-07 09:15:01 AM  386.75   1401    541836.75  26319094.25\n",
      "\n",
      "Data types:\n",
      "date          object\n",
      "price        float64\n",
      "qty            int64\n",
      "trnvr        float64\n",
      "cum_trnvr    float64\n",
      "dtype: object\n",
      "\n",
      "Basic statistics:\n",
      "              price            qty         trnvr     cum_trnvr\n",
      "count  18250.000000   18250.000000  1.825000e+04  1.825000e+04\n",
      "mean     386.537181     630.694301  2.439435e+05  2.317732e+09\n",
      "std        1.570300    2651.792039  1.026096e+06  1.129666e+09\n",
      "min      383.500000       0.000000  0.000000e+00  2.543152e+07\n",
      "25%      385.150000       0.000000  0.000000e+00  1.473757e+09\n",
      "50%      386.400000      10.000000  3.850250e+03  2.248665e+09\n",
      "75%      387.950000     331.000000  1.284426e+05  3.123428e+09\n",
      "max      390.200000  153858.000000  5.955074e+07  4.451969e+09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"D:\\Market Projects\\options_data_analyzer\\Aug '25\\Aug 07 Exp\\07 Aug\\BEL_EQ.csv\"\n",
    "\n",
    "# Load CSV with pandas\n",
    "# Using default encoding (utf-8) and comma delimiter\n",
    "# The file appears to have standard CSV format\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the loaded data\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"File path: {file_path}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc1406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FIRST 10 ROWS ===\n",
      "                     date   price    qty        trnvr    cum_trnvr\n",
      "0  2025-08-07 09:15:00 AM  386.85  65740  25431519.00  25431519.00\n",
      "1  2025-08-07 09:15:01 AM  386.65      0         0.00  25431519.00\n",
      "2  2025-08-07 09:15:01 AM  386.30      0         0.00  25431519.00\n",
      "3  2025-08-07 09:15:01 AM  386.30    895    345738.50  25777257.50\n",
      "4  2025-08-07 09:15:01 AM  386.75   1401    541836.75  26319094.25\n",
      "5  2025-08-07 09:15:02 AM  386.80   1795    694306.00  27013400.25\n",
      "6  2025-08-07 09:15:02 AM  386.95    741    286729.95  27300130.20\n",
      "7  2025-08-07 09:15:03 AM  386.85      0         0.00  27300130.20\n",
      "8  2025-08-07 09:15:03 AM  386.50      0         0.00  27300130.20\n",
      "9  2025-08-07 09:15:03 AM  386.90   2717   1051207.30  28351337.50\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== LAST 10 ROWS ===\n",
      "                         date   price   qty       trnvr     cum_trnvr\n",
      "18240  2025-08-07 03:29:31 PM  388.25   226    87744.50  4.446928e+09\n",
      "18241  2025-08-07 03:29:31 PM  388.10     0        0.00  4.446928e+09\n",
      "18242  2025-08-07 03:29:37 PM  388.25  2075   805618.75  4.447734e+09\n",
      "18243  2025-08-07 03:29:39 PM  388.30  1157   449263.10  4.448183e+09\n",
      "18244  2025-08-07 03:29:41 PM  388.10     0        0.00  4.448183e+09\n",
      "18245  2025-08-07 03:29:44 PM  388.25  1183   459299.75  4.448643e+09\n",
      "18246  2025-08-07 03:29:46 PM  388.25   958   371943.50  4.449015e+09\n",
      "18247  2025-08-07 03:29:51 PM  388.25  5331  2069760.75  4.451084e+09\n",
      "18248  2025-08-07 03:29:52 PM  388.25   539   209266.75  4.451294e+09\n",
      "18249  2025-08-07 03:29:58 PM  388.25  1740   675555.00  4.451969e+09\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== CHRONOLOGICAL ORDER CHECK ===\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "✓ Data is in CHRONOLOGICAL order (ascending)\n",
      "  - First row: Earliest time\n",
      "  - Last row: Latest time\n",
      "\n",
      "Total time range: 0 days 06:14:58\n"
     ]
    }
   ],
   "source": [
    "# Preview first and last 10 rows to check ordering\n",
    "print(\"=== FIRST 10 ROWS ===\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"=== LAST 10 ROWS ===\")\n",
    "print(df.tail(10))\n",
    "\n",
    "# Check if data is in chronological order\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"=== CHRONOLOGICAL ORDER CHECK ===\")\n",
    "\n",
    "# Convert date column to datetime if not already\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Check first and last timestamps\n",
    "first_time = df['date'].iloc[0]\n",
    "last_time = df['date'].iloc[-1]\n",
    "\n",
    "print(f\"First timestamp: {first_time}\")\n",
    "print(f\"Last timestamp: {last_time}\")\n",
    "\n",
    "# Check if chronological (ascending) or reverse chronological (descending)\n",
    "if first_time < last_time:\n",
    "    print(\"✓ Data is in CHRONOLOGICAL order (ascending)\")\n",
    "    print(\"  - First row: Earliest time\")\n",
    "    print(\"  - Last row: Latest time\")\n",
    "else:\n",
    "    print(\"✗ Data is in REVERSE CHRONOLOGICAL order (descending)\")\n",
    "    print(\"  - First row: Latest time\")\n",
    "    print(\"  - Last row: Earliest time\")\n",
    "\n",
    "# Show time range\n",
    "time_range = last_time - first_time\n",
    "print(f\"\\nTotal time range: {time_range}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17543f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATETIME CONVERSION AND FEATURE EXTRACTION ===\n",
      "New datetime features added:\n",
      "  - date_only: object\n",
      "  - time: object\n",
      "  - hour: int32\n",
      "  - minute: int32\n",
      "  - second: int32\n",
      "\n",
      "=== SAMPLE DATA WITH NEW FEATURES ===\n",
      "                 date   date_only      time  hour  minute  second   price  \\\n",
      "0 2025-08-07 09:15:00  2025-08-07  09:15:00     9      15       0  386.85   \n",
      "1 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.65   \n",
      "2 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.30   \n",
      "3 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.30   \n",
      "4 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.75   \n",
      "5 2025-08-07 09:15:02  2025-08-07  09:15:02     9      15       2  386.80   \n",
      "6 2025-08-07 09:15:02  2025-08-07  09:15:02     9      15       2  386.95   \n",
      "7 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.85   \n",
      "8 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.50   \n",
      "9 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.90   \n",
      "\n",
      "     qty  \n",
      "0  65740  \n",
      "1      0  \n",
      "2      0  \n",
      "3    895  \n",
      "4   1401  \n",
      "5   1795  \n",
      "6    741  \n",
      "7      0  \n",
      "8      0  \n",
      "9   2717  \n",
      "\n",
      "=== DATETIME VERIFICATION ===\n",
      "Original date column dtype: datetime64[ns]\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "Total unique dates: 1\n",
      "Date range: 2025-08-07 to 2025-08-07\n"
     ]
    }
   ],
   "source": [
    "# Convert date to datetime64[ns] and extract datetime features\n",
    "print(\"=== DATETIME CONVERSION AND FEATURE EXTRACTION ===\")\n",
    "\n",
    "# Convert date column to datetime64[ns]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract additional datetime features\n",
    "df['date_only'] = df['date'].dt.date\n",
    "df['time'] = df['date'].dt.time\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "df['second'] = df['date'].dt.second\n",
    "\n",
    "# Display the new datetime features\n",
    "print(\"New datetime features added:\")\n",
    "print(f\"  - date_only: {df['date_only'].dtype}\")\n",
    "print(f\"  - time: {df['time'].dtype}\")\n",
    "print(f\"  - hour: {df['hour'].dtype}\")\n",
    "print(f\"  - minute: {df['minute'].dtype}\")\n",
    "print(f\"  - second: {df['second'].dtype}\")\n",
    "\n",
    "# Show sample of the enhanced dataframe\n",
    "print(\"\\n=== SAMPLE DATA WITH NEW FEATURES ===\")\n",
    "print(df[['date', 'date_only', 'time', 'hour', 'minute', 'second', 'price', 'qty']].head(10))\n",
    "\n",
    "# Verify datetime conversion\n",
    "print(f\"\\n=== DATETIME VERIFICATION ===\")\n",
    "print(f\"Original date column dtype: {df['date'].dtype}\")\n",
    "print(f\"First timestamp: {df['date'].iloc[0]}\")\n",
    "print(f\"Last timestamp: {df['date'].iloc[-1]}\")\n",
    "print(f\"Total unique dates: {df['date_only'].nunique()}\")\n",
    "print(f\"Date range: {df['date_only'].min()} to {df['date_only'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2229a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HANDLING ZERO-QUANTITY TRADES ===\n",
      "Original data shape: (18250, 10)\n",
      "Rows with zero quantity: 7294\n",
      "Percentage of zero qty rows: 39.97%\n",
      "\n",
      "=== SAMPLE OF ZERO QTY ROWS (BEFORE REMOVAL) ===\n",
      "                  date   price  qty  trnvr    cum_trnvr\n",
      "1  2025-08-07 09:15:01  386.65    0    0.0  25431519.00\n",
      "2  2025-08-07 09:15:01  386.30    0    0.0  25431519.00\n",
      "7  2025-08-07 09:15:03  386.85    0    0.0  27300130.20\n",
      "8  2025-08-07 09:15:03  386.50    0    0.0  27300130.20\n",
      "13 2025-08-07 09:15:05  386.45    0    0.0  32995767.85\n",
      "\n",
      "=== AFTER CLEANING ===\n",
      "Cleaned data shape: (10956, 10)\n",
      "Rows removed: 7294\n",
      "Remaining rows: 10956\n",
      "\n",
      "=== SAMPLE OF CLEANED DATA ===\n",
      "                 date   price    qty        trnvr    cum_trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30    895    345738.50  25777257.50\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75  26319094.25\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00  27013400.25\n",
      "4 2025-08-07 09:15:02  386.95    741    286729.95  27300130.20\n",
      "5 2025-08-07 09:15:03  386.90   2717   1051207.30  28351337.50\n",
      "6 2025-08-07 09:15:03  386.80   9068   3507502.40  31858839.90\n",
      "7 2025-08-07 09:15:04  386.75   1141    441281.75  32300121.65\n",
      "8 2025-08-07 09:15:04  386.90   1798    695646.20  32995767.85\n",
      "9 2025-08-07 09:15:05  386.65   2092    808871.80  33804639.65\n",
      "\n",
      "Zero qty rows remaining: 0\n",
      "\n",
      "✓ Main dataframe 'df' now contains 10956 rows with non-zero quantities\n"
     ]
    }
   ],
   "source": [
    "# Handle zero-quantity trades - remove rows with 0 qty\n",
    "print(\"=== HANDLING ZERO-QUANTITY TRADES ===\")\n",
    "\n",
    "# Check current data shape and zero qty count\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "zero_qty_count = (df['qty'] == 0).sum()\n",
    "print(f\"Rows with zero quantity: {zero_qty_count}\")\n",
    "print(f\"Percentage of zero qty rows: {(zero_qty_count/len(df)*100):.2f}%\")\n",
    "\n",
    "# Show sample of zero qty rows before removal\n",
    "print(\"\\n=== SAMPLE OF ZERO QTY ROWS (BEFORE REMOVAL) ===\")\n",
    "zero_qty_sample = df[df['qty'] == 0][['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(5)\n",
    "print(zero_qty_sample)\n",
    "\n",
    "# Remove rows with zero quantity\n",
    "df_clean = df[df['qty'] > 0].copy()\n",
    "\n",
    "# Reset index after filtering\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "# Display results after cleaning\n",
    "print(f\"\\n=== AFTER CLEANING ===\")\n",
    "print(f\"Cleaned data shape: {df_clean.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")\n",
    "print(f\"Remaining rows: {len(df_clean)}\")\n",
    "\n",
    "# Show sample of cleaned data\n",
    "print(\"\\n=== SAMPLE OF CLEANED DATA ===\")\n",
    "print(df_clean[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(10))\n",
    "\n",
    "# Verify no zero qty rows remain\n",
    "remaining_zero_qty = (df_clean['qty'] == 0).sum()\n",
    "print(f\"\\nZero qty rows remaining: {remaining_zero_qty}\")\n",
    "\n",
    "# Update the main dataframe reference\n",
    "df = df_clean\n",
    "print(f\"\\n✓ Main dataframe 'df' now contains {len(df)} rows with non-zero quantities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73b099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NUMERIC COLUMN VALIDATION ===\n",
      "=== NEGATIVE VALUE CHECK ===\n",
      "price: 0 negative values\n",
      "qty: 0 negative values\n",
      "trnvr: 0 negative values\n",
      "cum_trnvr: 0 negative values\n",
      "\n",
      "=== ZERO VALUE CHECK ===\n",
      "price: 0 zero values\n",
      "qty: 0 zero values\n",
      "trnvr: 0 zero values\n",
      "cum_trnvr: 0 zero values\n",
      "\n",
      "=== STATISTICAL SUMMARY ===\n",
      "              price            qty         trnvr     cum_trnvr\n",
      "count  10956.000000   10956.000000  1.095600e+04  1.095600e+04\n",
      "mean     386.561094    1050.581508  4.063499e+05  2.377823e+09\n",
      "std        1.574324    3357.505716  1.299189e+06  1.165181e+09\n",
      "min      383.500000       1.000000  3.836000e+02  2.543152e+07\n",
      "25%      385.150000      26.000000  1.003177e+04  1.490814e+09\n",
      "50%      386.450000     200.000000  7.732500e+04  2.355502e+09\n",
      "75%      387.950000     799.000000  3.085895e+05  3.321858e+09\n",
      "max      390.200000  153858.000000  5.955074e+07  4.451969e+09\n",
      "\n",
      "=== OUTLIER DETECTION (IQR METHOD) ===\n",
      "\n",
      "price:\n",
      "  Q1: 385.15, Q3: 387.95, IQR: 2.80\n",
      "  Lower bound: 380.95, Upper bound: 392.15\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 0\n",
      "\n",
      "qty:\n",
      "  Q1: 26.00, Q3: 799.00, IQR: 773.00\n",
      "  Lower bound: -1133.50, Upper bound: 1958.50\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 1337\n",
      "\n",
      "trnvr:\n",
      "  Q1: 10031.77, Q3: 308589.53, IQR: 298557.75\n",
      "  Lower bound: -437804.85, Upper bound: 756426.15\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 1340\n",
      "\n",
      "cum_trnvr:\n",
      "  Q1: 1490814230.85, Q3: 3321857538.50, IQR: 1831043307.65\n",
      "  Lower bound: -1255750730.62, Upper bound: 6068422499.97\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 0\n",
      "\n",
      "=== EXTREME VALUE CHECK (3 STD DEV) ===\n",
      "\n",
      "price:\n",
      "  Mean: 386.56, Std: 1.57\n",
      "  Lower 3σ: 381.84, Upper 3σ: 391.28\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 0\n",
      "\n",
      "qty:\n",
      "  Mean: 1050.58, Std: 3357.51\n",
      "  Lower 3σ: -9021.94, Upper 3σ: 11123.10\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 148\n",
      "\n",
      "trnvr:\n",
      "  Mean: 406349.86, Std: 1299188.95\n",
      "  Lower 3σ: -3491216.99, Upper 3σ: 4303916.71\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 149\n",
      "\n",
      "cum_trnvr:\n",
      "  Mean: 2377822586.83, Std: 1165180692.88\n",
      "  Lower 3σ: -1117719491.81, Upper 3σ: 5873364665.46\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 0\n",
      "\n",
      "=== SAMPLE OF POTENTIAL OUTLIERS ===\n",
      "\n",
      "qty outliers (top 5):\n",
      "                  date    qty    qty        trnvr\n",
      "0  2025-08-07 09:15:00  65740  65740  25431519.00\n",
      "5  2025-08-07 09:15:03   2717   2717   1051207.30\n",
      "6  2025-08-07 09:15:03   9068   9068   3507502.40\n",
      "9  2025-08-07 09:15:05   2092   2092    808871.80\n",
      "11 2025-08-07 09:15:06   4519   4519   1747271.35\n",
      "\n",
      "trnvr outliers (top 5):\n",
      "                  date        trnvr    qty        trnvr\n",
      "0  2025-08-07 09:15:00  25431519.00  65740  25431519.00\n",
      "5  2025-08-07 09:15:03   1051207.30   2717   1051207.30\n",
      "6  2025-08-07 09:15:03   3507502.40   9068   3507502.40\n",
      "9  2025-08-07 09:15:05    808871.80   2092    808871.80\n",
      "11 2025-08-07 09:15:06   1747271.35   4519   1747271.35\n",
      "\n",
      "=== DATA QUALITY SUMMARY ===\n",
      "Total rows: 10956\n",
      "Columns with potential issues:\n",
      "  price: ✓ clean\n",
      "  qty: ✓ clean\n",
      "  trnvr: ✓ clean\n",
      "  cum_trnvr: ✓ clean\n"
     ]
    }
   ],
   "source": [
    "# Validate numeric columns for negatives or outliers\n",
    "print(\"=== NUMERIC COLUMN VALIDATION ===\")\n",
    "\n",
    "# List of numeric columns to validate\n",
    "numeric_cols = ['price', 'qty', 'trnvr', 'cum_trnvr']\n",
    "\n",
    "# Check for negative values\n",
    "print(\"=== NEGATIVE VALUE CHECK ===\")\n",
    "for col in numeric_cols:\n",
    "    negative_count = (df[col] < 0).sum()\n",
    "    print(f\"{col}: {negative_count} negative values\")\n",
    "\n",
    "# Check for zero values (after qty cleaning)\n",
    "print(\"\\n=== ZERO VALUE CHECK ===\")\n",
    "for col in numeric_cols:\n",
    "    zero_count = (df[col] == 0).sum()\n",
    "    print(f\"{col}: {zero_count} zero values\")\n",
    "\n",
    "# Statistical summary for outlier detection\n",
    "print(\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Outlier detection using IQR method\n",
    "print(\"\\n=== OUTLIER DETECTION (IQR METHOD) ===\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_lower = (df[col] < lower_bound).sum()\n",
    "    outliers_upper = (df[col] > upper_bound).sum()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "    print(f\"  Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
    "    print(f\"  Outliers below lower bound: {outliers_lower}\")\n",
    "    print(f\"  Outliers above upper bound: {outliers_upper}\")\n",
    "\n",
    "# Check for extreme values (beyond 3 standard deviations)\n",
    "print(\"\\n=== EXTREME VALUE CHECK (3 STD DEV) ===\")\n",
    "for col in numeric_cols:\n",
    "    mean_val = df[col].mean()\n",
    "    std_val = df[col].std()\n",
    "    \n",
    "    lower_3std = mean_val - 3 * std_val\n",
    "    upper_3std = mean_val + 3 * std_val\n",
    "    \n",
    "    extreme_lower = (df[col] < lower_3std).sum()\n",
    "    extreme_upper = (df[col] > upper_3std).sum()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {mean_val:.2f}, Std: {std_val:.2f}\")\n",
    "    print(f\"  Lower 3σ: {lower_3std:.2f}, Upper 3σ: {upper_3std:.2f}\")\n",
    "    print(f\"  Extreme values below: {extreme_lower}\")\n",
    "    print(f\"  Extreme values above: {extreme_upper}\")\n",
    "\n",
    "# Show sample of potential outliers\n",
    "print(\"\\n=== SAMPLE OF POTENTIAL OUTLIERS ===\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[df[col] > upper_bound]\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"\\n{col} outliers (top 5):\")\n",
    "        print(outliers[['date', col, 'qty', 'trnvr']].head())\n",
    "\n",
    "# Data quality summary\n",
    "print(\"\\n=== DATA QUALITY SUMMARY ===\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Columns with potential issues:\")\n",
    "for col in numeric_cols:\n",
    "    issues = []\n",
    "    if (df[col] < 0).any():\n",
    "        issues.append(\"negative values\")\n",
    "    if (df[col] == 0).any() and col != 'qty':  # qty can legitimately be 0\n",
    "        issues.append(\"zero values\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"  {col}: {', '.join(issues)}\")\n",
    "    else:\n",
    "        print(f\"  {col}: ✓ clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fe8c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TIME-SERIES INTEGRITY CHECK AND SORTING ===\n",
      "=== CURRENT SORTING STATUS ===\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "Data is already sorted chronologically: True\n",
      "Duplicate timestamps: 1961\n",
      "\n",
      "=== DUPLICATE TIMESTAMP ANALYSIS ===\n",
      "Sample duplicate timestamps:\n",
      "                  date   price   qty       trnvr\n",
      "1  2025-08-07 09:15:01  386.30   895   345738.50\n",
      "2  2025-08-07 09:15:01  386.75  1401   541836.75\n",
      "3  2025-08-07 09:15:02  386.80  1795   694306.00\n",
      "4  2025-08-07 09:15:02  386.95   741   286729.95\n",
      "5  2025-08-07 09:15:03  386.90  2717  1051207.30\n",
      "6  2025-08-07 09:15:03  386.80  9068  3507502.40\n",
      "7  2025-08-07 09:15:04  386.75  1141   441281.75\n",
      "8  2025-08-07 09:15:04  386.90  1798   695646.20\n",
      "9  2025-08-07 09:15:05  386.65  2092   808871.80\n",
      "10 2025-08-07 09:15:05  386.75  1679   649353.25\n",
      "\n",
      "=== SORTING DATA BY DATETIME ===\n",
      "Data is now sorted chronologically: True\n",
      "\n",
      "=== SORTING VERIFICATION ===\n",
      "First 5 rows after sorting:\n",
      "                 date   price    qty        trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30    895    345738.50\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00\n",
      "4 2025-08-07 09:15:02  386.95    741    286729.95\n",
      "\n",
      "Last 5 rows after sorting:\n",
      "                     date   price   qty       trnvr\n",
      "10951 2025-08-07 15:29:44  388.25  1183   459299.75\n",
      "10952 2025-08-07 15:29:46  388.25   958   371943.50\n",
      "10953 2025-08-07 15:29:51  388.25  5331  2069760.75\n",
      "10954 2025-08-07 15:29:52  388.25   539   209266.75\n",
      "10955 2025-08-07 15:29:58  388.25  1740   675555.00\n",
      "\n",
      "=== TIME SERIES CONTINUITY CHECK ===\n",
      "Time differences between consecutive rows:\n",
      "  Min: 0 days 00:00:00\n",
      "  Max: 0 days 00:00:12\n",
      "  Mean: 0 days 00:00:02.053674121\n",
      "  Most common: 0 days 00:00:01\n",
      "\n",
      "✓ Main dataframe 'df' is now properly sorted chronologically\n",
      "✓ Total rows: 10956\n",
      "✓ Time range: 2025-08-07 09:15:00 to 2025-08-07 15:29:58\n",
      "\n",
      "=== FINAL VERIFICATION ===\n",
      "✓ Data is sorted chronologically\n",
      "✓ Index is reset and sequential\n",
      "✓ Ready for time-series analysis\n"
     ]
    }
   ],
   "source": [
    "# Ensure sorting by datetime for time-series integrity\n",
    "print(\"=== TIME-SERIES INTEGRITY CHECK AND SORTING ===\")\n",
    "\n",
    "# Check current sorting status\n",
    "print(\"=== CURRENT SORTING STATUS ===\")\n",
    "print(f\"First timestamp: {df['date'].iloc[0]}\")\n",
    "print(f\"Last timestamp: {df['date'].iloc[-1]}\")\n",
    "\n",
    "# Check if data is already sorted\n",
    "is_sorted = df['date'].is_monotonic_increasing\n",
    "print(f\"Data is already sorted chronologically: {is_sorted}\")\n",
    "\n",
    "# Check for any duplicate timestamps\n",
    "duplicate_timestamps = df['date'].duplicated().sum()\n",
    "print(f\"Duplicate timestamps: {duplicate_timestamps}\")\n",
    "\n",
    "if duplicate_timestamps > 0:\n",
    "    print(\"\\n=== DUPLICATE TIMESTAMP ANALYSIS ===\")\n",
    "    duplicate_samples = df[df['date'].duplicated(keep=False)].sort_values('date')\n",
    "    print(\"Sample duplicate timestamps:\")\n",
    "    print(duplicate_samples[['date', 'price', 'qty', 'trnvr']].head(10))\n",
    "\n",
    "# Sort the dataframe by datetime\n",
    "print(\"\\n=== SORTING DATA BY DATETIME ===\")\n",
    "df_sorted = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Verify sorting\n",
    "is_now_sorted = df_sorted['date'].is_monotonic_increasing\n",
    "print(f\"Data is now sorted chronologically: {is_now_sorted}\")\n",
    "\n",
    "# Display sorting verification\n",
    "print(f\"\\n=== SORTING VERIFICATION ===\")\n",
    "print(\"First 5 rows after sorting:\")\n",
    "print(df_sorted[['date', 'price', 'qty', 'trnvr']].head())\n",
    "print(f\"\\nLast 5 rows after sorting:\")\n",
    "print(df_sorted[['date', 'price', 'qty', 'trnvr']].tail())\n",
    "\n",
    "# Check for any time gaps or irregularities\n",
    "print(f\"\\n=== TIME SERIES CONTINUITY CHECK ===\")\n",
    "time_diffs = df_sorted['date'].diff().dropna()\n",
    "print(f\"Time differences between consecutive rows:\")\n",
    "print(f\"  Min: {time_diffs.min()}\")\n",
    "print(f\"  Max: {time_diffs.max()}\")\n",
    "print(f\"  Mean: {time_diffs.mean()}\")\n",
    "print(f\"  Most common: {time_diffs.mode().iloc[0] if len(time_diffs.mode()) > 0 else 'N/A'}\")\n",
    "\n",
    "# Check for any large time gaps\n",
    "large_gaps = time_diffs[time_diffs > pd.Timedelta(minutes=5)]\n",
    "if len(large_gaps) > 0:\n",
    "    print(f\"\\n⚠️  Found {len(large_gaps)} time gaps larger than 5 minutes:\")\n",
    "    gap_indices = time_diffs[time_diffs > pd.Timedelta(minutes=5)].index\n",
    "    for idx in gap_indices[:5]:  # Show first 5 gaps\n",
    "        gap_start = df_sorted.loc[idx-1, 'date']\n",
    "        gap_end = df_sorted.loc[idx, 'date']\n",
    "        gap_duration = gap_end - gap_start\n",
    "        print(f\"  Gap: {gap_start} to {gap_end} (Duration: {gap_duration})\")\n",
    "\n",
    "# Update the main dataframe with sorted version\n",
    "df = df_sorted\n",
    "print(f\"\\n✓ Main dataframe 'df' is now properly sorted chronologically\")\n",
    "print(f\"✓ Total rows: {len(df)}\")\n",
    "print(f\"✓ Time range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "# Final verification\n",
    "print(f\"\\n=== FINAL VERIFICATION ===\")\n",
    "print(\"✓ Data is sorted chronologically\")\n",
    "print(\"✓ Index is reset and sequential\")\n",
    "print(\"✓ Ready for time-series analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64545d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE DESCRIPTIVE STATISTICS ===\n",
      "=== BASIC DESCRIPTIVE STATISTICS ===\n",
      "                                date         price            qty  \\\n",
      "count                          10956  10956.000000   10956.000000   \n",
      "mean   2025-08-07 12:40:58.929810176    386.561094    1050.581508   \n",
      "min              2025-08-07 09:15:00    383.500000       1.000000   \n",
      "25%       2025-08-07 11:06:26.500000    385.150000      26.000000   \n",
      "50%              2025-08-07 12:45:14    386.450000     200.000000   \n",
      "75%    2025-08-07 14:26:31.249999872    387.950000     799.000000   \n",
      "max              2025-08-07 15:29:58    390.200000  153858.000000   \n",
      "std                              NaN      1.574324    3357.505716   \n",
      "\n",
      "              trnvr     cum_trnvr          hour        minute        second  \n",
      "count  1.095600e+04  1.095600e+04  10956.000000  10956.000000  10956.000000  \n",
      "mean   4.063499e+05  2.377823e+09     12.209383     27.926798     29.543173  \n",
      "min    3.836000e+02  2.543152e+07      9.000000      0.000000      0.000000  \n",
      "25%    1.003177e+04  1.490814e+09     11.000000     13.000000     15.000000  \n",
      "50%    7.732500e+04  2.355502e+09     12.000000     26.000000     30.000000  \n",
      "75%    3.085895e+05  3.321858e+09     14.000000     43.000000     45.000000  \n",
      "max    5.955074e+07  4.451969e+09     15.000000     59.000000     59.000000  \n",
      "std    1.299189e+06  1.165181e+09      1.916078     17.252424     17.315855  \n",
      "\n",
      "============================================================\n",
      "=== DETAILED STATISTICS BY COLUMN ===\n",
      "\n",
      "--- PRICE ---\n",
      "Count: 10,956\n",
      "Mean: 386.56\n",
      "Std: 1.57\n",
      "Min: 383.50\n",
      "25%: 385.15\n",
      "50% (Median): 386.45\n",
      "75%: 387.95\n",
      "Max: 390.20\n",
      "Range: 6.70\n",
      "IQR: 2.80\n",
      "Coefficient of Variation: 0.41%\n",
      "\n",
      "--- QTY ---\n",
      "Count: 10,956\n",
      "Mean: 1,050.58\n",
      "Std: 3,357.51\n",
      "Min: 1.00\n",
      "25%: 26.00\n",
      "50% (Median): 200.00\n",
      "75%: 799.00\n",
      "Max: 153,858.00\n",
      "Range: 153,857.00\n",
      "IQR: 773.00\n",
      "Coefficient of Variation: 319.59%\n",
      "\n",
      "--- TRNVR ---\n",
      "Count: 10,956\n",
      "Mean: 406,349.86\n",
      "Std: 1,299,188.95\n",
      "Min: 383.60\n",
      "25%: 10,031.77\n",
      "50% (Median): 77,325.00\n",
      "75%: 308,589.53\n",
      "Max: 59,550,738.90\n",
      "Range: 59,550,355.30\n",
      "IQR: 298,557.75\n",
      "Coefficient of Variation: 319.72%\n",
      "\n",
      "--- CUM_TRNVR ---\n",
      "Count: 10,956\n",
      "Mean: 2,377,822,586.83\n",
      "Std: 1,165,180,692.88\n",
      "Min: 25,431,519.00\n",
      "25%: 1,490,814,230.85\n",
      "50% (Median): 2,355,501,798.67\n",
      "75%: 3,321,857,538.50\n",
      "Max: 4,451,969,111.70\n",
      "Range: 4,426,537,592.70\n",
      "IQR: 1,831,043,307.65\n",
      "Coefficient of Variation: 49.00%\n",
      "\n",
      "============================================================\n",
      "=== DATETIME FEATURE STATISTICS ===\n",
      "\n",
      "--- HOUR DISTRIBUTION ---\n",
      "hour\n",
      "9     1047\n",
      "10    1476\n",
      "11    1653\n",
      "12    1807\n",
      "13    1679\n",
      "14    1521\n",
      "15    1773\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- MINUTE DISTRIBUTION (Sample) ---\n",
      "minute\n",
      "0     165\n",
      "1     239\n",
      "2     221\n",
      "3     264\n",
      "4     115\n",
      "5     108\n",
      "6     111\n",
      "7     219\n",
      "8     280\n",
      "9     258\n",
      "10    271\n",
      "11    260\n",
      "12    114\n",
      "13    118\n",
      "14    120\n",
      "15    305\n",
      "16    208\n",
      "17    209\n",
      "18    228\n",
      "19    249\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "=== TIME PERIOD ANALYSIS ===\n",
      "Trades during market hours (9 AM - 3 PM): 10,956\n",
      "Trades outside market hours: 0\n",
      "\n",
      "--- PRICE ANALYSIS ---\n",
      "Price range: ₹383.50 to ₹390.20\n",
      "Price spread: ₹6.70\n",
      "\n",
      "--- VOLUME ANALYSIS ---\n",
      "Total volume traded: 11,510,171\n",
      "Average trade size: 1051\n",
      "Largest single trade: 153,858\n",
      "\n",
      "--- TURNOVER ANALYSIS ---\n",
      "Total turnover: ₹4,451,969,111.70\n",
      "Average trade value: ₹406,349.86\n",
      "Largest single trade value: ₹59,550,738.90\n",
      "\n",
      "============================================================\n",
      "=== SUMMARY TABLE ===\n",
      "        Metric                Value\n",
      "    Total Rows               10,956\n",
      "   Price Range    ₹383.50 - ₹390.20\n",
      "  Total Volume           11,510,171\n",
      "Total Turnover    ₹4,451,969,111.70\n",
      "    Time Range 09:15:00 to 15:29:58\n"
     ]
    }
   ],
   "source": [
    "# Get comprehensive descriptive statistics for numeric fields\n",
    "print(\"=== COMPREHENSIVE DESCRIPTIVE STATISTICS ===\")\n",
    "\n",
    "# Get basic describe() for all numeric columns\n",
    "print(\"=== BASIC DESCRIPTIVE STATISTICS ===\")\n",
    "print(df.describe())\n",
    "\n",
    "# Get detailed statistics for each numeric column\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== DETAILED STATISTICS BY COLUMN ===\")\n",
    "\n",
    "numeric_cols = ['price', 'qty', 'trnvr', 'cum_trnvr']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    col_stats = df[col].describe()\n",
    "    \n",
    "    print(f\"Count: {col_stats['count']:,.0f}\")\n",
    "    print(f\"Mean: {col_stats['mean']:,.2f}\")\n",
    "    print(f\"Std: {col_stats['std']:,.2f}\")\n",
    "    print(f\"Min: {col_stats['min']:,.2f}\")\n",
    "    print(f\"25%: {col_stats['25%']:,.2f}\")\n",
    "    print(f\"50% (Median): {col_stats['50%']:,.2f}\")\n",
    "    print(f\"75%: {col_stats['75%']:,.2f}\")\n",
    "    print(f\"Max: {col_stats['max']:,.2f}\")\n",
    "    \n",
    "    # Additional useful statistics\n",
    "    print(f\"Range: {col_stats['max'] - col_stats['min']:,.2f}\")\n",
    "    print(f\"IQR: {col_stats['75%'] - col_stats['25%']:,.2f}\")\n",
    "    print(f\"Coefficient of Variation: {(col_stats['std']/col_stats['mean']*100):,.2f}%\")\n",
    "\n",
    "# Get statistics for datetime features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== DATETIME FEATURE STATISTICS ===\")\n",
    "\n",
    "print(\"\\n--- HOUR DISTRIBUTION ---\")\n",
    "hour_counts = df['hour'].value_counts().sort_index()\n",
    "print(hour_counts)\n",
    "\n",
    "print(\"\\n--- MINUTE DISTRIBUTION (Sample) ---\")\n",
    "minute_counts = df['minute'].value_counts().sort_index().head(20)\n",
    "print(minute_counts)\n",
    "\n",
    "# Get statistics for specific time periods\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== TIME PERIOD ANALYSIS ===\")\n",
    "\n",
    "# Market hours analysis (assuming 9:15 AM to 3:30 PM)\n",
    "market_hours = df[(df['hour'] >= 9) & (df['hour'] <= 15)]\n",
    "print(f\"Trades during market hours (9 AM - 3 PM): {len(market_hours):,}\")\n",
    "print(f\"Trades outside market hours: {len(df) - len(market_hours):,}\")\n",
    "\n",
    "# Price range analysis\n",
    "print(f\"\\n--- PRICE ANALYSIS ---\")\n",
    "print(f\"Price range: ₹{df['price'].min():.2f} to ₹{df['price'].max():.2f}\")\n",
    "print(f\"Price spread: ₹{df['price'].max() - df['price'].min():.2f}\")\n",
    "\n",
    "# Volume analysis\n",
    "print(f\"\\n--- VOLUME ANALYSIS ---\")\n",
    "print(f\"Total volume traded: {df['qty'].sum():,}\")\n",
    "print(f\"Average trade size: {df['qty'].mean():.0f}\")\n",
    "print(f\"Largest single trade: {df['qty'].max():,}\")\n",
    "\n",
    "# Turnover analysis\n",
    "print(f\"\\n--- TURNOVER ANALYSIS ---\")\n",
    "print(f\"Total turnover: ₹{df['trnvr'].sum():,.2f}\")\n",
    "print(f\"Average trade value: ₹{df['trnvr'].mean():,.2f}\")\n",
    "print(f\"Largest single trade value: ₹{df['trnvr'].max():,.2f}\")\n",
    "\n",
    "# Display summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== SUMMARY TABLE ===\")\n",
    "summary_data = {\n",
    "    'Metric': ['Total Rows', 'Price Range', 'Total Volume', 'Total Turnover', 'Time Range'],\n",
    "    'Value': [\n",
    "        f\"{len(df):,}\",\n",
    "        f\"₹{df['price'].min():.2f} - ₹{df['price'].max():.2f}\",\n",
    "        f\"{df['qty'].sum():,}\",\n",
    "        f\"₹{df['trnvr'].sum():,.2f}\",\n",
    "        f\"{df['date'].min().strftime('%H:%M:%S')} to {df['date'].max().strftime('%H:%M:%S')}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffcd6431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADING DAYS ANALYSIS ===\n",
      "Total unique trading days: 1\n",
      "\n",
      "=== ALL TRADING DATES ===\n",
      " 1. 2025-08-07\n",
      "\n",
      "Trading date range: 2025-08-07 to 2025-08-07\n",
      "\n",
      "=== DATE ANALYSIS ===\n",
      "Single trading day data\n",
      "Date: 2025-08-07\n",
      "\n",
      "=== DATA CONSISTENCY CHECK ===\n",
      "Total rows in dataset: 10,956\n",
      "Average rows per trading day: 10956.0\n",
      "\n",
      "=== SUMMARY ===\n",
      "✓ Total unique trading days: 1\n",
      "✓ Date range: 2025-08-07 to 2025-08-07\n",
      "✓ Ready for daily analysis and aggregation\n"
     ]
    }
   ],
   "source": [
    "# Count total unique trading days\n",
    "print(\"=== TRADING DAYS ANALYSIS ===\")\n",
    "\n",
    "# Extract unique dates from the datetime column\n",
    "unique_dates = df['date_only'].unique()\n",
    "total_trading_days = len(unique_dates)\n",
    "\n",
    "print(f\"Total unique trading days: {total_trading_days}\")\n",
    "\n",
    "# Display all unique trading dates\n",
    "print(f\"\\n=== ALL TRADING DATES ===\")\n",
    "for i, date in enumerate(sorted(unique_dates), 1):\n",
    "    print(f\"{i:2d}. {date}\")\n",
    "\n",
    "# Get date range\n",
    "date_range = f\"{min(unique_dates)} to {max(unique_dates)}\"\n",
    "print(f\"\\nTrading date range: {date_range}\")\n",
    "\n",
    "# Check if all dates are from the same month/year\n",
    "print(f\"\\n=== DATE ANALYSIS ===\")\n",
    "if total_trading_days == 1:\n",
    "    print(\"Single trading day data\")\n",
    "    print(f\"Date: {unique_dates[0]}\")\n",
    "    # Initialize these variables for single day to avoid errors\n",
    "    months = {unique_dates[0].month}\n",
    "    years = {unique_dates[0].year}\n",
    "elif total_trading_days > 1:\n",
    "    # Check month and year consistency\n",
    "    months = set(date.month for date in unique_dates)\n",
    "    years = set(date.year for date in unique_dates)\n",
    "    \n",
    "    print(f\"Multiple trading days: {total_trading_days}\")\n",
    "    print(f\"Months covered: {sorted(months)}\")\n",
    "    print(f\"Years covered: {sorted(years)}\")\n",
    "    \n",
    "    if len(months) == 1:\n",
    "        month_name = pd.Timestamp(unique_dates[0]).strftime('%B')\n",
    "        print(f\"All dates are from: {month_name} {list(years)[0]}\")\n",
    "    \n",
    "    if len(years) == 1:\n",
    "        print(f\"All dates are from year: {list(years)[0]}\")\n",
    "\n",
    "# Trading days by month (if multiple months)\n",
    "if len(months) > 1:\n",
    "    print(f\"\\n=== TRADING DAYS BY MONTH ===\")\n",
    "    monthly_counts = {}\n",
    "    for date in unique_dates:\n",
    "        month_key = f\"{date.year}-{date.month:02d}\"\n",
    "        monthly_counts[month_key] = monthly_counts.get(month_key, 0) + 1\n",
    "    \n",
    "    for month_key in sorted(monthly_counts.keys()):\n",
    "        year, month = month_key.split('-')\n",
    "        month_name = pd.Timestamp(f\"{year}-{month}-01\").strftime('%B %Y')\n",
    "        print(f\"{month_name}: {monthly_counts[month_key]} trading days\")\n",
    "\n",
    "# Verify data consistency\n",
    "print(f\"\\n=== DATA CONSISTENCY CHECK ===\")\n",
    "print(f\"Total rows in dataset: {len(df):,}\")\n",
    "print(f\"Average rows per trading day: {len(df)/total_trading_days:.1f}\")\n",
    "\n",
    "# Check for any missing dates in sequence (if multiple days)\n",
    "if total_trading_days > 1:\n",
    "    sorted_dates = sorted(unique_dates)\n",
    "    date_diffs = []\n",
    "    for i in range(1, len(sorted_dates)):\n",
    "        diff = (sorted_dates[i] - sorted_dates[i-1]).days\n",
    "        date_diffs.append(diff)\n",
    "    \n",
    "    if any(diff > 1 for diff in date_diffs):\n",
    "        print(f\"\\n⚠️  Gaps detected in trading days:\")\n",
    "        for i, diff in enumerate(date_diffs):\n",
    "            if diff > 1:\n",
    "                gap_start = sorted_dates[i-1]\n",
    "                gap_end = sorted_dates[i]\n",
    "                print(f\"  Gap: {gap_start} to {gap_end} ({diff-1} missing days)\")\n",
    "    else:\n",
    "        print(f\"\\n✓ No gaps in trading days - consecutive trading days\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"✓ Total unique trading days: {total_trading_days}\")\n",
    "print(f\"✓ Date range: {date_range}\")\n",
    "print(f\"✓ Ready for daily analysis and aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6881a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TIMESTAMP RANGE ANALYSIS ===\n",
      "Earliest timestamp: 2025-08-07 09:15:00\n",
      "Latest timestamp: 2025-08-07 15:29:58\n",
      "Total time duration: 0 days 06:14:58\n",
      "Duration in hours: 6.25 hours\n",
      "Duration in minutes: 375 minutes\n",
      "\n",
      "=== EARLIEST TIMESTAMP ROW ===\n",
      "               date  price   qty      trnvr  cum_trnvr\n",
      "2025-08-07 09:15:00 386.85 65740 25431519.0 25431519.0\n",
      "\n",
      "=== LATEST TIMESTAMP ROW ===\n",
      "               date  price  qty    trnvr    cum_trnvr\n",
      "2025-08-07 15:29:58 388.25 1740 675555.0 4.451969e+09\n",
      "\n",
      "=== TIME PERIOD ANALYSIS ===\n",
      "Earliest: 09:15\n",
      "Latest: 15:29\n",
      "\n",
      "Market hours: 09:15:00 to 15:30:00\n",
      "Data coverage:\n",
      "\n",
      "=== TIME SERIES CONTINUITY ===\n",
      "Minimum time difference between consecutive rows: 0 days 00:00:00\n",
      "Maximum time difference between consecutive rows: 0 days 00:00:12\n",
      "\n",
      "=== SUMMARY ===\n",
      "✓ Data spans: 2025-08-07 09:15:00 to 2025-08-07 15:29:58\n",
      "✓ Total duration: 6.25 hours (375 minutes)\n",
      "✓ Total rows: 10,956\n",
      "✓ Average frequency: 1753.1 ticks per hour\n"
     ]
    }
   ],
   "source": [
    "# Identify earliest and latest timestamps\n",
    "print(\"=== TIMESTAMP RANGE ANALYSIS ===\")\n",
    "\n",
    "# Get earliest and latest timestamps\n",
    "earliest_timestamp = df['date'].min()\n",
    "latest_timestamp = df['date'].max()\n",
    "\n",
    "print(f\"Earliest timestamp: {earliest_timestamp}\")\n",
    "print(f\"Latest timestamp: {latest_timestamp}\")\n",
    "\n",
    "# Calculate total time duration\n",
    "total_duration = latest_timestamp - earliest_timestamp\n",
    "print(f\"Total time duration: {total_duration}\")\n",
    "\n",
    "# Convert duration to more readable format\n",
    "duration_hours = total_duration.total_seconds() / 3600\n",
    "duration_minutes = total_duration.total_seconds() / 60\n",
    "\n",
    "print(f\"Duration in hours: {duration_hours:.2f} hours\")\n",
    "print(f\"Duration in minutes: {duration_minutes:.0f} minutes\")\n",
    "\n",
    "# Display the actual rows with earliest and latest timestamps\n",
    "print(f\"\\n=== EARLIEST TIMESTAMP ROW ===\")\n",
    "earliest_row = df[df['date'] == earliest_timestamp]\n",
    "print(earliest_row[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== LATEST TIMESTAMP ROW ===\")\n",
    "latest_row = df[df['date'] == latest_timestamp]\n",
    "print(latest_row[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].to_string(index=False))\n",
    "\n",
    "# Check if timestamps span across different time periods\n",
    "print(f\"\\n=== TIME PERIOD ANALYSIS ===\")\n",
    "earliest_hour = earliest_timestamp.hour\n",
    "earliest_minute = earliest_timestamp.minute\n",
    "latest_hour = latest_timestamp.hour\n",
    "latest_minute = latest_timestamp.minute\n",
    "\n",
    "print(f\"Earliest: {earliest_hour:02d}:{earliest_minute:02d}\")\n",
    "print(f\"Latest: {latest_hour:02d}:{latest_minute:02d}\")\n",
    "\n",
    "# Market hours analysis (assuming 9:15 AM to 3:30 PM)\n",
    "market_start = pd.Timestamp('2025-08-07 09:15:00')\n",
    "market_end = pd.Timestamp('2025-08-07 15:30:00')\n",
    "\n",
    "print(f\"\\nMarket hours: 09:15:00 to 15:30:00\")\n",
    "print(f\"Data coverage:\")\n",
    "\n",
    "if earliest_timestamp < market_start:\n",
    "    pre_market_duration = market_start - earliest_timestamp\n",
    "    print(f\"  Pre-market: {earliest_timestamp.strftime('%H:%M:%S')} to {market_start.strftime('%H:%M:%S')} ({pre_market_duration})\")\n",
    "\n",
    "if earliest_timestamp <= market_start and latest_timestamp >= market_end:\n",
    "    market_duration = market_end - market_start\n",
    "    print(f\"  Market hours: {market_start.strftime('%H:%M:%S')} to {market_end.strftime('%H:%M:%S')} ({market_duration})\")\n",
    "\n",
    "if latest_timestamp > market_end:\n",
    "    post_market_duration = latest_timestamp - market_end\n",
    "    print(f\"  Post-market: {market_end.strftime('%H:%M:%S')} to {latest_timestamp.strftime('%H:%M:%S')} ({post_market_duration})\")\n",
    "\n",
    "# Check for any gaps in the time series\n",
    "print(f\"\\n=== TIME SERIES CONTINUITY ===\")\n",
    "time_diffs = df['date'].diff().dropna()\n",
    "min_time_diff = time_diffs.min()\n",
    "max_time_diff = time_diffs.max()\n",
    "\n",
    "print(f\"Minimum time difference between consecutive rows: {min_time_diff}\")\n",
    "print(f\"Maximum time difference between consecutive rows: {max_time_diff}\")\n",
    "\n",
    "# Identify any unusually large time gaps\n",
    "large_gaps = time_diffs[time_diffs > pd.Timedelta(minutes=1)]\n",
    "if len(large_gaps) > 0:\n",
    "    print(f\"\\n⚠️  Found {len(large_gaps)} time gaps larger than 1 minute:\")\n",
    "    gap_indices = large_gaps.index[:5]  # Show first 5 gaps\n",
    "    for idx in gap_indices:\n",
    "        gap_start = df.loc[idx-1, 'date']\n",
    "        gap_end = df.loc[idx, 'date']\n",
    "        gap_duration = gap_end - gap_start\n",
    "        print(f\"  Gap: {gap_start.strftime('%H:%M:%S')} to {gap_end.strftime('%H:%M:%S')} (Duration: {gap_duration})\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"✓ Data spans: {earliest_timestamp.strftime('%Y-%m-%d %H:%M:%S')} to {latest_timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"✓ Total duration: {duration_hours:.2f} hours ({duration_minutes:.0f} minutes)\")\n",
    "print(f\"✓ Total rows: {len(df):,}\")\n",
    "print(f\"✓ Average frequency: {len(df)/duration_hours:.1f} ticks per hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a43503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VOLUME AND TURNOVER ANALYSIS ===\n",
      "Total traded volume: 11,510,171\n",
      "Total turnover: ₹4,451,969,111.70\n",
      "\n",
      "=== DETAILED METRICS ===\n",
      "--- VOLUME ANALYSIS ---\n",
      "Average trade size: 1,051\n",
      "Median trade size: 200\n",
      "Largest single trade: 153,858\n",
      "Smallest single trade: 1\n",
      "\n",
      "--- TURNOVER ANALYSIS ---\n",
      "Average trade value: ₹406,349.86\n",
      "Median trade value: ₹77,325.00\n",
      "Largest single trade value: ₹59,550,738.90\n",
      "Smallest single trade value: ₹383.60\n",
      "\n",
      "--- PRICE ANALYSIS ---\n",
      "Simple average price: ₹386.56\n",
      "Weighted average price (by volume): ₹386.79\n",
      "Price range: ₹6.70\n",
      "\n",
      "--- VOLUME-WEIGHTED METRICS ---\n",
      "Volume Weighted Average Price (VWAP): ₹386.79\n",
      "\n",
      "--- EFFICIENCY METRICS ---\n",
      "Total number of trades: 10,956\n",
      "Average volume per trade: 1,051\n",
      "Average turnover per trade: ₹406,349.86\n",
      "\n",
      "=== TIME-BASED ANALYSIS ===\n",
      "Trading duration: 6.25 hours\n",
      "Volume per hour: 1,841,791\n",
      "Turnover per hour: ₹712,378,380.39\n",
      "\n",
      "--- MARKET ACTIVITY INTENSITY ---\n",
      "Trades per hour: 1753.1\n",
      "Volume per trade: 1,051\n",
      "Turnover per trade: ₹406,349.86\n",
      "\n",
      "============================================================\n",
      "=== SUMMARY TABLE ===\n",
      "         Metric             Value\n",
      "   Total Volume        11,510,171\n",
      " Total Turnover ₹4,451,969,111.70\n",
      "   Total Trades            10,956\n",
      " Avg Trade Size             1,051\n",
      "Avg Trade Value       ₹406,349.86\n",
      "           VWAP           ₹386.79\n",
      "\n",
      "=== KEY INSIGHTS ===\n",
      "✓ Total volume traded: 11,510,171 shares\n",
      "✓ Total market value: ₹4,451,969,111.70\n",
      "✓ Market activity: 10,956 individual trades\n",
      "✓ Trading efficiency: ₹386.79 per share\n"
     ]
    }
   ],
   "source": [
    "# Calculate total traded volume and total turnover\n",
    "print(\"=== VOLUME AND TURNOVER ANALYSIS ===\")\n",
    "\n",
    "# Calculate totals\n",
    "total_volume = df['qty'].sum()\n",
    "total_turnover = df['trnvr'].sum()\n",
    "\n",
    "print(f\"Total traded volume: {total_volume:,}\")\n",
    "print(f\"Total turnover: ₹{total_turnover:,.2f}\")\n",
    "\n",
    "# Additional volume and turnover metrics\n",
    "print(f\"\\n=== DETAILED METRICS ===\")\n",
    "\n",
    "# Volume analysis\n",
    "print(\"--- VOLUME ANALYSIS ---\")\n",
    "avg_trade_size = df['qty'].mean()\n",
    "median_trade_size = df['qty'].median()\n",
    "max_trade_size = df['qty'].max()\n",
    "min_trade_size = df['qty'].min()\n",
    "\n",
    "print(f\"Average trade size: {avg_trade_size:,.0f}\")\n",
    "print(f\"Median trade size: {median_trade_size:,.0f}\")\n",
    "print(f\"Largest single trade: {max_trade_size:,}\")\n",
    "print(f\"Smallest single trade: {min_trade_size:,}\")\n",
    "\n",
    "# Turnover analysis\n",
    "print(f\"\\n--- TURNOVER ANALYSIS ---\")\n",
    "avg_trade_value = df['trnvr'].mean()\n",
    "median_trade_value = df['trnvr'].median()\n",
    "max_trade_value = df['trnvr'].max()\n",
    "min_trade_value = df['trnvr'].min()\n",
    "\n",
    "print(f\"Average trade value: ₹{avg_trade_value:,.2f}\")\n",
    "print(f\"Median trade value: ₹{median_trade_value:,.2f}\")\n",
    "print(f\"Largest single trade value: ₹{max_trade_value:,.2f}\")\n",
    "print(f\"Smallest single trade value: ₹{min_trade_value:,.2f}\")\n",
    "\n",
    "# Price analysis\n",
    "print(f\"\\n--- PRICE ANALYSIS ---\")\n",
    "avg_price = df['price'].mean()\n",
    "weighted_avg_price = (df['price'] * df['qty']).sum() / df['qty'].sum()\n",
    "price_range = df['price'].max() - df['price'].min()\n",
    "\n",
    "print(f\"Simple average price: ₹{avg_price:.2f}\")\n",
    "print(f\"Weighted average price (by volume): ₹{weighted_avg_price:.2f}\")\n",
    "print(f\"Price range: ₹{price_range:.2f}\")\n",
    "\n",
    "# Volume-weighted metrics\n",
    "print(f\"\\n--- VOLUME-WEIGHTED METRICS ---\")\n",
    "vwap = (df['price'] * df['qty']).sum() / df['qty'].sum()\n",
    "print(f\"Volume Weighted Average Price (VWAP): ₹{vwap:.2f}\")\n",
    "\n",
    "# Efficiency metrics\n",
    "print(f\"\\n--- EFFICIENCY METRICS ---\")\n",
    "trades_count = len(df)\n",
    "print(f\"Total number of trades: {trades_count:,}\")\n",
    "print(f\"Average volume per trade: {total_volume/trades_count:,.0f}\")\n",
    "print(f\"Average turnover per trade: ₹{total_turnover/trades_count:,.2f}\")\n",
    "\n",
    "# Time-based analysis\n",
    "print(f\"\\n=== TIME-BASED ANALYSIS ===\")\n",
    "earliest_time = df['date'].min()\n",
    "latest_time = df['date'].max()\n",
    "duration_hours = (latest_time - earliest_time).total_seconds() / 3600\n",
    "\n",
    "print(f\"Trading duration: {duration_hours:.2f} hours\")\n",
    "print(f\"Volume per hour: {total_volume/duration_hours:,.0f}\")\n",
    "print(f\"Turnover per hour: ₹{total_turnover/duration_hours:,.2f}\")\n",
    "\n",
    "# Market activity intensity\n",
    "print(f\"\\n--- MARKET ACTIVITY INTENSITY ---\")\n",
    "print(f\"Trades per hour: {trades_count/duration_hours:.1f}\")\n",
    "print(f\"Volume per trade: {total_volume/trades_count:,.0f}\")\n",
    "print(f\"Turnover per trade: ₹{total_turnover/trades_count:,.2f}\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"=== SUMMARY TABLE ===\")\n",
    "summary_data = {\n",
    "    'Metric': ['Total Volume', 'Total Turnover', 'Total Trades', 'Avg Trade Size', 'Avg Trade Value', 'VWAP'],\n",
    "    'Value': [\n",
    "        f\"{total_volume:,}\",\n",
    "        f\"₹{total_turnover:,.2f}\",\n",
    "        f\"{trades_count:,}\",\n",
    "        f\"{avg_trade_size:,.0f}\",\n",
    "        f\"₹{avg_trade_value:,.2f}\",\n",
    "        f\"₹{vwap:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== KEY INSIGHTS ===\")\n",
    "print(f\"✓ Total volume traded: {total_volume:,} shares\")\n",
    "print(f\"✓ Total market value: ₹{total_turnover:,.2f}\")\n",
    "print(f\"✓ Market activity: {trades_count:,} individual trades\")\n",
    "print(f\"✓ Trading efficiency: ₹{total_turnover/total_volume:.2f} per share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e17d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADE TYPE ANALYSIS ===\n",
      "Total records in dataset: 10,956\n",
      "Actual trades (qty > 0): 10,956\n",
      "Zero-quantity updates (qty = 0): 0\n",
      "\n",
      "=== PERCENTAGE BREAKDOWN ===\n",
      "Actual trades: 100.00%\n",
      "Zero-quantity updates: 0.00%\n",
      "\n",
      "=== DATA COMPOSITION ANALYSIS ===\n",
      "✓ Dataset contains only actual trades (all qty > 0)\n",
      "\n",
      "=== SAMPLE OF ACTUAL TRADES (qty > 0) ===\n",
      "                 date   price    qty        trnvr    cum_trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30    895    345738.50  25777257.50\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75  26319094.25\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00  27013400.25\n",
      "4 2025-08-07 09:15:02  386.95    741    286729.95  27300130.20\n",
      "5 2025-08-07 09:15:03  386.90   2717   1051207.30  28351337.50\n",
      "6 2025-08-07 09:15:03  386.80   9068   3507502.40  31858839.90\n",
      "7 2025-08-07 09:15:04  386.75   1141    441281.75  32300121.65\n",
      "8 2025-08-07 09:15:04  386.90   1798    695646.20  32995767.85\n",
      "9 2025-08-07 09:15:05  386.75   1679    649353.25  34453992.90\n",
      "\n",
      "=== CHARACTERISTICS ANALYSIS ===\n",
      "--- ACTUAL TRADES (qty > 0) ---\n",
      "  Total volume: 11,510,171\n",
      "  Total turnover: ₹4,451,969,111.70\n",
      "  Average trade size: 1,051\n",
      "  Average trade value: ₹406,349.86\n",
      "  Price range: ₹383.50 - ₹390.20\n",
      "\n",
      "=== DATA QUALITY IMPLICATIONS ===\n",
      "✓ Clean dataset with only actual trades\n",
      "\n",
      "=== RECOMMENDATIONS ===\n",
      "  ✓ Dataset is ready for all types of analysis\n",
      "\n",
      "=== SUMMARY ===\n",
      "✓ Total records: 10,956\n",
      "✓ Actual trades: 10,956 (100.0%)\n",
      "✓ Zero-qty updates: 0 (0.0%)\n",
      "✓ Data type: Pure trades only\n"
     ]
    }
   ],
   "source": [
    "# Check number of trades with qty > 0 (actual trades vs. zero-qty updates)\n",
    "print(\"=== TRADE TYPE ANALYSIS ===\")\n",
    "\n",
    "# Count different types of records\n",
    "total_records = len(df)\n",
    "actual_trades = (df['qty'] > 0).sum()\n",
    "zero_qty_updates = (df['qty'] == 0).sum()\n",
    "\n",
    "print(f\"Total records in dataset: {total_records:,}\")\n",
    "print(f\"Actual trades (qty > 0): {actual_trades:,}\")\n",
    "print(f\"Zero-quantity updates (qty = 0): {zero_qty_updates:,}\")\n",
    "\n",
    "# Calculate percentages\n",
    "actual_trades_pct = (actual_trades / total_records) * 100\n",
    "zero_qty_pct = (zero_qty_updates / total_records) * 100\n",
    "\n",
    "print(f\"\\n=== PERCENTAGE BREAKDOWN ===\")\n",
    "print(f\"Actual trades: {actual_trades_pct:.2f}%\")\n",
    "print(f\"Zero-quantity updates: {zero_qty_pct:.2f}%\")\n",
    "\n",
    "# Analyze the data composition\n",
    "print(f\"\\n=== DATA COMPOSITION ANALYSIS ===\")\n",
    "if zero_qty_updates > 0:\n",
    "    print(\"⚠️  Dataset contains both actual trades and zero-quantity updates\")\n",
    "    print(\"   This suggests the data includes bid-ask spread updates\")\n",
    "else:\n",
    "    print(\"✓ Dataset contains only actual trades (all qty > 0)\")\n",
    "\n",
    "# Show sample of actual trades\n",
    "print(f\"\\n=== SAMPLE OF ACTUAL TRADES (qty > 0) ===\")\n",
    "actual_trades_df = df[df['qty'] > 0]\n",
    "print(actual_trades_df[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(10))\n",
    "\n",
    "# Show sample of zero-quantity updates (if any exist)\n",
    "if zero_qty_updates > 0:\n",
    "    print(f\"\\n=== SAMPLE OF ZERO-QUANTITY UPDATES (qty = 0) ===\")\n",
    "    zero_qty_df = df[df['qty'] == 0]\n",
    "    print(zero_qty_df[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(10))\n",
    "\n",
    "# Analyze characteristics of each type\n",
    "print(f\"\\n=== CHARACTERISTICS ANALYSIS ===\")\n",
    "\n",
    "# Actual trades characteristics\n",
    "if actual_trades > 0:\n",
    "    print(\"--- ACTUAL TRADES (qty > 0) ---\")\n",
    "    actual_trades_data = df[df['qty'] > 0]\n",
    "    print(f\"  Total volume: {actual_trades_data['qty'].sum():,}\")\n",
    "    print(f\"  Total turnover: ₹{actual_trades_data['trnvr'].sum():,.2f}\")\n",
    "    print(f\"  Average trade size: {actual_trades_data['qty'].mean():,.0f}\")\n",
    "    print(f\"  Average trade value: ₹{actual_trades_data['trnvr'].mean():,.2f}\")\n",
    "    print(f\"  Price range: ₹{actual_trades_data['price'].min():.2f} - ₹{actual_trades_data['price'].max():.2f}\")\n",
    "\n",
    "# Zero-quantity updates characteristics (if any exist)\n",
    "if zero_qty_updates > 0:\n",
    "    print(f\"\\n--- ZERO-QUANTITY UPDATES (qty = 0) ---\")\n",
    "    zero_qty_data = df[df['qty'] == 0]\n",
    "    print(f\"  Total records: {len(zero_qty_data):,}\")\n",
    "    print(f\"  Price range: ₹{zero_qty_data['price'].min():.2f} - ₹{zero_qty_data['price'].max():.2f}\")\n",
    "    print(f\"  Average price: ₹{zero_qty_data['price'].mean():.2f}\")\n",
    "    \n",
    "    # Check if these are bid-ask spread updates\n",
    "    if zero_qty_data['trnvr'].sum() == 0:\n",
    "        print(f\"  All have zero turnover (typical bid-ask updates)\")\n",
    "    else:\n",
    "        print(f\"  Some have non-zero turnover (data quality issue)\")\n",
    "\n",
    "# Data quality implications\n",
    "print(f\"\\n=== DATA QUALITY IMPLICATIONS ===\")\n",
    "if zero_qty_updates > 0:\n",
    "    print(\"⚠️  Mixed data types detected:\")\n",
    "    print(\"   - Actual trades: Use for volume, turnover, and price analysis\")\n",
    "    print(\"   - Zero-qty updates: Use for bid-ask spread analysis only\")\n",
    "    print(\"   - Consider filtering by qty > 0 for trade-based analysis\")\n",
    "else:\n",
    "    print(\"✓ Clean dataset with only actual trades\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\n=== RECOMMENDATIONS ===\")\n",
    "if zero_qty_updates > 0:\n",
    "    print(\"For different types of analysis:\")\n",
    "    print(\"  📊 Volume/Turnover analysis: Use df[df['qty'] > 0]\")\n",
    "    print(\"  📈 Price movement analysis: Use df[df['qty'] > 0]\")\n",
    "    print(\"  🔍 Bid-ask spread analysis: Use df[df['qty'] == 0]\")\n",
    "    print(\"  📋 Complete market picture: Use full dataset\")\n",
    "else:\n",
    "    print(\"  ✓ Dataset is ready for all types of analysis\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"✓ Total records: {total_records:,}\")\n",
    "print(f\"✓ Actual trades: {actual_trades:,} ({actual_trades_pct:.1f}%)\")\n",
    "print(f\"✓ Zero-qty updates: {zero_qty_updates:,} ({zero_qty_pct:.1f}%)\")\n",
    "print(f\"✓ Data type: {'Mixed (trades + updates)' if zero_qty_updates > 0 else 'Pure trades only'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01afc28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRICE CHANGE CALCULATION ===\n",
      "=== SAMPLE DATA WITH PRICE CHANGE ===\n",
      "                 date   price  price_change    qty        trnvr\n",
      "0 2025-08-07 09:15:00  386.85           NaN  65740  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30         -0.55    895    345738.50\n",
      "2 2025-08-07 09:15:01  386.75          0.45   1401    541836.75\n",
      "3 2025-08-07 09:15:02  386.80          0.05   1795    694306.00\n",
      "4 2025-08-07 09:15:02  386.95          0.15    741    286729.95\n",
      "5 2025-08-07 09:15:03  386.90         -0.05   2717   1051207.30\n",
      "6 2025-08-07 09:15:03  386.80         -0.10   9068   3507502.40\n",
      "7 2025-08-07 09:15:04  386.75         -0.05   1141    441281.75\n",
      "8 2025-08-07 09:15:04  386.90          0.15   1798    695646.20\n",
      "9 2025-08-07 09:15:05  386.75         -0.15   1679    649353.25\n",
      "\n",
      "=== PRICE CHANGE STATISTICS ===\n",
      "Total price changes calculated: 10955\n",
      "First price change: -0.55\n",
      "Last price change: 0.00\n",
      "\n",
      "=== PRICE CHANGE DESCRIPTIVE STATISTICS ===\n",
      "count    10955.000000\n",
      "mean         0.000128\n",
      "std          0.083893\n",
      "min         -0.650000\n",
      "25%         -0.050000\n",
      "50%          0.000000\n",
      "75%          0.050000\n",
      "max          0.750000\n",
      "Name: price_change, dtype: float64\n",
      "\n",
      "=== PRICE CHANGE DISTRIBUTION ANALYSIS ===\n",
      "Positive price changes: 3,216 (29.36%)\n",
      "Negative price changes: 3,299 (30.11%)\n",
      "No price changes: 4,440 (40.53%)\n",
      "\n",
      "=== PRICE CHANGE MAGNITUDE ANALYSIS ===\n",
      "Average absolute price change: ₹0.05\n",
      "Median absolute price change: ₹0.05\n",
      "Largest price increase: ₹0.75\n",
      "Largest price decrease: ₹-0.65\n",
      "\n",
      "=== EXAMPLES OF PRICE CHANGES ===\n",
      "Top 5 largest price increases:\n",
      "               date  price  price_change   qty\n",
      "2025-08-07 09:15:16 386.55          0.75  5645\n",
      "2025-08-07 09:18:55 389.05          0.60 17196\n",
      "2025-08-07 09:20:49 389.85          0.55 43873\n",
      "2025-08-07 09:15:11 386.20          0.50  1962\n",
      "2025-08-07 14:45:13 386.55          0.50   579\n",
      "\n",
      "Top 5 largest price decreases:\n",
      "               date  price  price_change   qty\n",
      "2025-08-07 09:18:47 388.45         -0.65 17426\n",
      "2025-08-07 09:15:01 386.30         -0.55   895\n",
      "2025-08-07 09:15:26 385.90         -0.45  2839\n",
      "2025-08-07 09:16:20 387.15         -0.45 11997\n",
      "2025-08-07 09:15:15 385.80         -0.45  3449\n",
      "\n",
      "Sample of rows with no price change:\n",
      "               date  price  price_change  qty\n",
      "2025-08-07 09:15:06 386.65           0.0 4519\n",
      "2025-08-07 09:15:09 386.00           0.0 1904\n",
      "2025-08-07 09:15:10 386.00           0.0 6328\n",
      "2025-08-07 09:15:12 386.00           0.0 1803\n",
      "2025-08-07 09:15:13 385.75           0.0 8471\n",
      "\n",
      "=== PRICE CHANGE PATTERNS ===\n",
      "Price changes per hour: 1753.0\n",
      "Average price change frequency: 1.00 changes per tick\n",
      "\n",
      "=== CALCULATION VERIFICATION ===\n",
      "✓ Price change column created successfully\n",
      "✓ First row price_change is NaN (no previous price to compare)\n",
      "✓ Total rows: 10,956\n",
      "✓ Price changes calculated: 10,955\n",
      "✓ Ready for price movement analysis\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change']\n",
      "Shape: (10956, 11)\n",
      "Data types:\n",
      "date            datetime64[ns]\n",
      "price                  float64\n",
      "qty                      int64\n",
      "trnvr                  float64\n",
      "cum_trnvr              float64\n",
      "date_only               object\n",
      "time                    object\n",
      "hour                     int32\n",
      "minute                   int32\n",
      "second                   int32\n",
      "price_change           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create price_change = current price - previous price\n",
    "print(\"=== PRICE CHANGE CALCULATION ===\")\n",
    "\n",
    "# Calculate price change (current price - previous price)\n",
    "df['price_change'] = df['price'].diff()\n",
    "\n",
    "# Display the first few rows to verify the calculation\n",
    "print(\"=== SAMPLE DATA WITH PRICE CHANGE ===\")\n",
    "print(df[['date', 'price', 'price_change', 'qty', 'trnvr']].head(10))\n",
    "\n",
    "# Basic statistics of price changes\n",
    "print(f\"\\n=== PRICE CHANGE STATISTICS ===\")\n",
    "print(f\"Total price changes calculated: {len(df['price_change'].dropna())}\")\n",
    "print(f\"First price change: {df['price_change'].iloc[1]:.2f}\")  # First change is at index 1\n",
    "print(f\"Last price change: {df['price_change'].iloc[-1]:.2f}\")\n",
    "\n",
    "# Statistical summary of price changes\n",
    "print(f\"\\n=== PRICE CHANGE DESCRIPTIVE STATISTICS ===\")\n",
    "price_change_stats = df['price_change'].describe()\n",
    "print(price_change_stats)\n",
    "\n",
    "# Analyze price change distribution\n",
    "print(f\"\\n=== PRICE CHANGE DISTRIBUTION ANALYSIS ===\")\n",
    "positive_changes = (df['price_change'] > 0).sum()\n",
    "negative_changes = (df['price_change'] < 0).sum()\n",
    "zero_changes = (df['price_change'] == 0).sum()\n",
    "total_changes = len(df['price_change'].dropna())\n",
    "\n",
    "print(f\"Positive price changes: {positive_changes:,} ({(positive_changes/total_changes*100):.2f}%)\")\n",
    "print(f\"Negative price changes: {negative_changes:,} ({(negative_changes/total_changes*100):.2f}%)\")\n",
    "print(f\"No price changes: {zero_changes:,} ({(zero_changes/total_changes*100):.2f}%)\")\n",
    "\n",
    "# Price change magnitude analysis\n",
    "print(f\"\\n=== PRICE CHANGE MAGNITUDE ANALYSIS ===\")\n",
    "abs_price_changes = df['price_change'].abs()\n",
    "print(f\"Average absolute price change: ₹{abs_price_changes.mean():.2f}\")\n",
    "print(f\"Median absolute price change: ₹{abs_price_changes.median():.2f}\")\n",
    "print(f\"Largest price increase: ₹{df['price_change'].max():.2f}\")\n",
    "print(f\"Largest price decrease: ₹{df['price_change'].min():.2f}\")\n",
    "\n",
    "# Show examples of different types of price changes\n",
    "print(f\"\\n=== EXAMPLES OF PRICE CHANGES ===\")\n",
    "\n",
    "# Largest price increases\n",
    "print(\"Top 5 largest price increases:\")\n",
    "largest_increases = df.nlargest(5, 'price_change')[['date', 'price', 'price_change', 'qty']]\n",
    "print(largest_increases.to_string(index=False))\n",
    "\n",
    "# Largest price decreases\n",
    "print(f\"\\nTop 5 largest price decreases:\")\n",
    "largest_decreases = df.nsmallest(5, 'price_change')[['date', 'price', 'price_change', 'qty']]\n",
    "print(largest_decreases.to_string(index=False))\n",
    "\n",
    "# No change examples\n",
    "if zero_changes > 0:\n",
    "    print(f\"\\nSample of rows with no price change:\")\n",
    "    no_change_sample = df[df['price_change'] == 0][['date', 'price', 'price_change', 'qty']].head(5)\n",
    "    print(no_change_sample.to_string(index=False))\n",
    "\n",
    "# Price change patterns\n",
    "print(f\"\\n=== PRICE CHANGE PATTERNS ===\")\n",
    "print(f\"Price changes per hour: {total_changes / ((df['date'].max() - df['date'].min()).total_seconds() / 3600):.1f}\")\n",
    "print(f\"Average price change frequency: {total_changes / len(df):.2f} changes per tick\")\n",
    "\n",
    "# Verify calculation integrity\n",
    "print(f\"\\n=== CALCULATION VERIFICATION ===\")\n",
    "print(f\"✓ Price change column created successfully\")\n",
    "print(f\"✓ First row price_change is NaN (no previous price to compare)\")\n",
    "print(f\"✓ Total rows: {len(df):,}\")\n",
    "print(f\"✓ Price changes calculated: {total_changes:,}\")\n",
    "print(f\"✓ Ready for price movement analysis\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ee472b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIRECTION COLUMN CREATION ===\n",
      "=== SAMPLE DATA WITH DIRECTION ===\n",
      "                 date   price  price_change  direction    qty        trnvr\n",
      "0 2025-08-07 09:15:00  386.85           NaN  No change  65740  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30         -0.55       Down    895    345738.50\n",
      "2 2025-08-07 09:15:01  386.75          0.45         Up   1401    541836.75\n",
      "3 2025-08-07 09:15:02  386.80          0.05         Up   1795    694306.00\n",
      "4 2025-08-07 09:15:02  386.95          0.15         Up    741    286729.95\n",
      "5 2025-08-07 09:15:03  386.90         -0.05       Down   2717   1051207.30\n",
      "6 2025-08-07 09:15:03  386.80         -0.10       Down   9068   3507502.40\n",
      "7 2025-08-07 09:15:04  386.75         -0.05       Down   1141    441281.75\n",
      "8 2025-08-07 09:15:04  386.90          0.15         Up   1798    695646.20\n",
      "9 2025-08-07 09:15:05  386.75         -0.15       Down   1679    649353.25\n",
      "\n",
      "=== DIRECTION DISTRIBUTION ===\n",
      "direction\n",
      "No change    4441\n",
      "Down         3299\n",
      "Up           3216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== DIRECTION PERCENTAGES ===\n",
      "No change: 4,441 (40.53%)\n",
      "Down: 3,299 (30.11%)\n",
      "Up: 3,216 (29.35%)\n",
      "\n",
      "=== DIRECTION PATTERN ANALYSIS ===\n",
      "Direction sequence analysis:\n",
      "Maximum consecutive 'Up' movements: 7\n",
      "Maximum consecutive 'Down' movements: 5\n",
      "Maximum consecutive 'No change': 13\n",
      "\n",
      "=== DIRECTION BY TIME PERIODS ===\n",
      "Direction distribution by hour:\n",
      "direction  Down  No change   Up\n",
      "hour                           \n",
      "9           348        363  336\n",
      "10          478        531  467\n",
      "11          538        630  485\n",
      "12          565        698  544\n",
      "13          473        751  455\n",
      "14          428        643  450\n",
      "15          469        825  479\n",
      "\n",
      "=== DIRECTION TRANSITIONS ===\n",
      "Most common direction transitions:\n",
      "  No change → No change: 2,073 times\n",
      "  Down → Up: 1,789 times\n",
      "  Up → Down: 1,434 times\n",
      "  No change → Down: 1,382 times\n",
      "  Up → No change: 1,340 times\n",
      "  Down → No change: 1,027 times\n",
      "  No change → Up: 985 times\n",
      "  Down → Down: 483 times\n",
      "  Up → Up: 442 times\n",
      "\n",
      "=== DIRECTION WITH VOLUME ANALYSIS ===\n",
      "Volume analysis by direction:\n",
      "               sum         mean  count\n",
      "direction                             \n",
      "Down       3889213  1178.906638   3299\n",
      "No change  2923497   658.297005   4441\n",
      "Up         4697461  1460.653296   3216\n",
      "\n",
      "=== DIRECTION WITH PRICE CHANGE MAGNITUDE ===\n",
      "Price change magnitude by direction:\n",
      "               mean       std   min   max\n",
      "direction                                \n",
      "Down      -0.091103  0.055096 -0.65 -0.05\n",
      "No change  0.000000  0.000000  0.00  0.00\n",
      "Up         0.093890  0.059423  0.05  0.75\n",
      "\n",
      "=== EXAMPLES OF EACH DIRECTION ===\n",
      "Sample 'Up' movements:\n",
      "               date  price  price_change  qty\n",
      "2025-08-07 09:15:01 386.75          0.45 1401\n",
      "2025-08-07 09:15:02 386.80          0.05 1795\n",
      "2025-08-07 09:15:02 386.95          0.15  741\n",
      "\n",
      "Sample 'Down' movements:\n",
      "               date  price  price_change  qty\n",
      "2025-08-07 09:15:01  386.3         -0.55  895\n",
      "2025-08-07 09:15:03  386.9         -0.05 2717\n",
      "2025-08-07 09:15:03  386.8         -0.10 9068\n",
      "\n",
      "Sample 'No change':\n",
      "               date  price  price_change   qty\n",
      "2025-08-07 09:15:00 386.85           NaN 65740\n",
      "2025-08-07 09:15:06 386.65           0.0  4519\n",
      "2025-08-07 09:15:09 386.00           0.0  1904\n",
      "\n",
      "=== DIRECTION SUMMARY ===\n",
      "✓ Direction column created successfully\n",
      "✓ Total rows: 10,956\n",
      "✓ Up movements: 3,216\n",
      "✓ Down movements: 3,299\n",
      "✓ No change: 4,441\n",
      "✓ Most common direction: No change\n",
      "✓ Ready for directional analysis and pattern recognition\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change', 'direction']\n",
      "Shape: (10956, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create direction column: \"Up\", \"Down\", \"No change\"\n",
    "print(\"=== DIRECTION COLUMN CREATION ===\")\n",
    "\n",
    "# Create direction column based on price_change\n",
    "df['direction'] = df['price_change'].apply(lambda x: \n",
    "    'Up' if x > 0 else \n",
    "    'Down' if x < 0 else \n",
    "    'No change'\n",
    ")\n",
    "\n",
    "# Display the first few rows to verify the direction column\n",
    "print(\"=== SAMPLE DATA WITH DIRECTION ===\")\n",
    "print(df[['date', 'price', 'price_change', 'direction', 'qty', 'trnvr']].head(10))\n",
    "\n",
    "# Count the occurrences of each direction\n",
    "print(f\"\\n=== DIRECTION DISTRIBUTION ===\")\n",
    "direction_counts = df['direction'].value_counts()\n",
    "print(direction_counts)\n",
    "\n",
    "# Calculate percentages\n",
    "total_rows = len(df)\n",
    "print(f\"\\n=== DIRECTION PERCENTAGES ===\")\n",
    "for direction, count in direction_counts.items():\n",
    "    percentage = (count / total_rows) * 100\n",
    "    print(f\"{direction}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "# Analyze direction patterns\n",
    "print(f\"\\n=== DIRECTION PATTERN ANALYSIS ===\")\n",
    "\n",
    "# Check for consecutive directions\n",
    "print(\"Direction sequence analysis:\")\n",
    "consecutive_up = 0\n",
    "consecutive_down = 0\n",
    "consecutive_no_change = 0\n",
    "max_consecutive_up = 0\n",
    "max_consecutive_down = 0\n",
    "max_consecutive_no_change = 0\n",
    "\n",
    "current_up = 0\n",
    "current_down = 0\n",
    "current_no_change = 0\n",
    "\n",
    "for direction in df['direction']:\n",
    "    if direction == 'Up':\n",
    "        current_up += 1\n",
    "        current_down = 0\n",
    "        current_no_change = 0\n",
    "        max_consecutive_up = max(max_consecutive_up, current_up)\n",
    "    elif direction == 'Down':\n",
    "        current_down += 1\n",
    "        current_up = 0\n",
    "        current_no_change = 0\n",
    "        max_consecutive_down = max(max_consecutive_down, current_down)\n",
    "    else:  # No change\n",
    "        current_no_change += 1\n",
    "        current_up = 0\n",
    "        current_down = 0\n",
    "        max_consecutive_no_change = max(max_consecutive_no_change, current_no_change)\n",
    "\n",
    "print(f\"Maximum consecutive 'Up' movements: {max_consecutive_up}\")\n",
    "print(f\"Maximum consecutive 'Down' movements: {max_consecutive_down}\")\n",
    "print(f\"Maximum consecutive 'No change': {max_consecutive_no_change}\")\n",
    "\n",
    "# Direction by time periods\n",
    "print(f\"\\n=== DIRECTION BY TIME PERIODS ===\")\n",
    "df['hour'] = df['date'].dt.hour\n",
    "hourly_direction = df.groupby('hour')['direction'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "print(\"Direction distribution by hour:\")\n",
    "print(hourly_direction)\n",
    "\n",
    "# Direction transitions (what follows what)\n",
    "print(f\"\\n=== DIRECTION TRANSITIONS ===\")\n",
    "transitions = []\n",
    "for i in range(1, len(df)):\n",
    "    prev_direction = df['direction'].iloc[i-1]\n",
    "    curr_direction = df['direction'].iloc[i]\n",
    "    transitions.append((prev_direction, curr_direction))\n",
    "\n",
    "transition_counts = pd.Series(transitions).value_counts().head(10)\n",
    "print(\"Most common direction transitions:\")\n",
    "for transition, count in transition_counts.items():\n",
    "    print(f\"  {transition[0]} → {transition[1]}: {count:,} times\")\n",
    "\n",
    "# Direction with volume analysis\n",
    "print(f\"\\n=== DIRECTION WITH VOLUME ANALYSIS ===\")\n",
    "direction_volume = df.groupby('direction')['qty'].agg(['sum', 'mean', 'count'])\n",
    "print(\"Volume analysis by direction:\")\n",
    "print(direction_volume)\n",
    "\n",
    "# Direction with price change magnitude\n",
    "print(f\"\\n=== DIRECTION WITH PRICE CHANGE MAGNITUDE ===\")\n",
    "direction_magnitude = df.groupby('direction')['price_change'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(\"Price change magnitude by direction:\")\n",
    "print(direction_magnitude)\n",
    "\n",
    "# Show examples of each direction\n",
    "print(f\"\\n=== EXAMPLES OF EACH DIRECTION ===\")\n",
    "\n",
    "# Up movements\n",
    "up_examples = df[df['direction'] == 'Up'][['date', 'price', 'price_change', 'qty']].head(3)\n",
    "print(\"Sample 'Up' movements:\")\n",
    "print(up_examples.to_string(index=False))\n",
    "\n",
    "# Down movements\n",
    "down_examples = df[df['direction'] == 'Down'][['date', 'price', 'price_change', 'qty']].head(3)\n",
    "print(f\"\\nSample 'Down' movements:\")\n",
    "print(down_examples.to_string(index=False))\n",
    "\n",
    "# No change\n",
    "no_change_examples = df[df['direction'] == 'No change'][['date', 'price', 'price_change', 'qty']].head(3)\n",
    "print(f\"\\nSample 'No change':\")\n",
    "print(no_change_examples.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== DIRECTION SUMMARY ===\")\n",
    "print(f\"✓ Direction column created successfully\")\n",
    "print(f\"✓ Total rows: {total_rows:,}\")\n",
    "print(f\"✓ Up movements: {direction_counts.get('Up', 0):,}\")\n",
    "print(f\"✓ Down movements: {direction_counts.get('Down', 0):,}\")\n",
    "print(f\"✓ No change: {direction_counts.get('No change', 0):,}\")\n",
    "print(f\"✓ Most common direction: {direction_counts.index[0]}\")\n",
    "print(f\"✓ Ready for directional analysis and pattern recognition\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6864362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ROLLING AVERAGE CALCULATION ===\n",
      "Calculating rolling averages...\n",
      "=== SAMPLE DATA WITH ROLLING AVERAGES ===\n",
      "                  date   price  price_1min_avg  price_5min_avg  \\\n",
      "0  2025-08-07 09:15:00  386.85      386.850000      386.850000   \n",
      "1  2025-08-07 09:15:01  386.30      386.575000      386.575000   \n",
      "2  2025-08-07 09:15:01  386.75      386.633333      386.633333   \n",
      "3  2025-08-07 09:15:02  386.80      386.675000      386.675000   \n",
      "4  2025-08-07 09:15:02  386.95      386.730000      386.730000   \n",
      "5  2025-08-07 09:15:03  386.90      386.758333      386.758333   \n",
      "6  2025-08-07 09:15:03  386.80      386.764286      386.764286   \n",
      "7  2025-08-07 09:15:04  386.75      386.762500      386.762500   \n",
      "8  2025-08-07 09:15:04  386.90      386.777778      386.777778   \n",
      "9  2025-08-07 09:15:05  386.65      386.765000      386.765000   \n",
      "10 2025-08-07 09:15:05  386.75      386.763636      386.763636   \n",
      "11 2025-08-07 09:15:06  386.65      386.754167      386.754167   \n",
      "12 2025-08-07 09:15:06  386.55      386.738462      386.738462   \n",
      "13 2025-08-07 09:15:07  386.40      386.714286      386.714286   \n",
      "14 2025-08-07 09:15:07  386.10      386.673333      386.673333   \n",
      "\n",
      "    price_15min_avg    qty  \n",
      "0        386.850000  65740  \n",
      "1        386.575000    895  \n",
      "2        386.633333   1401  \n",
      "3        386.675000   1795  \n",
      "4        386.730000    741  \n",
      "5        386.758333   2717  \n",
      "6        386.764286   9068  \n",
      "7        386.762500   1141  \n",
      "8        386.777778   1798  \n",
      "9        386.765000   2092  \n",
      "10       386.763636   1679  \n",
      "11       386.754167   4519  \n",
      "12       386.738462   1316  \n",
      "13       386.714286   2858  \n",
      "14       386.673333    640  \n",
      "\n",
      "=== ROLLING AVERAGE STATISTICS ===\n",
      "\n",
      "price_1min_avg:\n",
      "  Min: ₹383.55\n",
      "  Max: ₹383.55\n",
      "  Mean: ₹386.55\n",
      "  Std: ₹1.56\n",
      "\n",
      "price_5min_avg:\n",
      "  Min: ₹383.68\n",
      "  Max: ₹383.68\n",
      "  Mean: ₹386.52\n",
      "  Std: ₹1.52\n",
      "\n",
      "price_15min_avg:\n",
      "  Min: ₹383.76\n",
      "  Max: ₹383.76\n",
      "  Mean: ₹386.49\n",
      "  Std: ₹1.45\n",
      "\n",
      "=== PRICE VS ROLLING AVERAGES ANALYSIS ===\n",
      "Price differences from rolling averages:\n",
      "  vs 1-min avg: Mean=0.01, Std=0.16\n",
      "  vs 5-min avg: Mean=0.04, Std=0.36\n",
      "  vs 15-min avg: Mean=0.08, Std=0.51\n",
      "\n",
      "=== MOVING AVERAGE CROSSOVER ANALYSIS ===\n",
      "Price above 1-min average: 5,353 times (48.9%)\n",
      "Price above 5-min average: 5,648 times (51.6%)\n",
      "Price above 15-min average: 5,863 times (53.5%)\n",
      "\n",
      "=== MOVING AVERAGE CROSSOVER SIGNALS ===\n",
      "1-min vs 5-min crossovers:\n",
      "  Bullish (1-min crosses above 5-min): 58\n",
      "  Bearish (1-min crosses below 5-min): 58\n",
      "\n",
      "5-min vs 15-min crossovers:\n",
      "  Bullish (5-min crosses above 15-min): 15\n",
      "  Bearish (5-min crosses below 15-min): 14\n",
      "\n",
      "=== SAMPLE CROSSOVER SIGNALS ===\n",
      "Recent 1-min vs 5-min crossovers:\n",
      "               date  price  price_1min_avg  price_5min_avg  ma_1min_5min_signal\n",
      "2025-08-07 09:15:00 386.85      386.850000      386.850000                  NaN\n",
      "2025-08-07 09:16:30 387.10      386.335149      386.333333                  1.0\n",
      "2025-08-07 09:24:03 389.00      389.454167      389.521384                 -1.0\n",
      "2025-08-07 09:31:32 389.05      388.816667      388.760656                  1.0\n",
      "2025-08-07 09:35:27 389.25      389.260000      389.283019                 -1.0\n",
      "2025-08-07 09:38:39 389.20      389.045833      389.041935                  1.0\n",
      "2025-08-07 09:42:04 389.15      389.200000      389.208824                 -1.0\n",
      "2025-08-07 09:46:33 389.00      388.833333      388.809848                  1.0\n",
      "2025-08-07 09:49:52 388.80      388.925000      388.947458                 -1.0\n",
      "2025-08-07 09:52:57 388.95      388.917647      388.917188                  1.0\n",
      "\n",
      "=== ROLLING AVERAGE TRENDS ===\n",
      "1-min moving average trends:\n",
      "  Upward trending periods: 5,275\n",
      "  Downward trending periods: 5,396\n",
      "\n",
      "=== ROLLING AVERAGE SUMMARY ===\n",
      "✓ 1-minute rolling average calculated\n",
      "✓ 5-minute rolling average calculated\n",
      "✓ 15-minute rolling average calculated\n",
      "✓ Crossover signals identified\n",
      "✓ Trend analysis completed\n",
      "✓ Ready for technical analysis and trading signals\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change', 'direction', 'price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'price_vs_1min', 'price_vs_5min', 'price_vs_15min', 'above_1min', 'above_5min', 'above_15min', 'ma_1min_5min_cross', 'ma_1min_5min_signal', 'ma_5min_15min_cross', 'ma_5min_15min_signal', 'ma_1min_slope', 'ma_5min_slope', 'ma_15min_slope']\n",
      "Shape: (10956, 28)\n",
      "New columns added:\n",
      "  ✓ price_1min_avg\n",
      "  ✓ price_5min_avg\n",
      "  ✓ price_15min_avg\n",
      "  ✓ price_vs_1min\n",
      "  ✓ price_vs_5min\n",
      "  ✓ price_vs_15min\n",
      "  ✓ above_1min\n",
      "  ✓ above_5min\n",
      "  ✓ above_15min\n",
      "  ✓ ma_1min_5min_cross\n",
      "  ✓ ma_1min_5min_signal\n",
      "  ✓ ma_5min_15min_cross\n",
      "  ✓ ma_5min_15min_signal\n",
      "  ✓ ma_1min_slope\n",
      "  ✓ ma_5min_slope\n",
      "  ✓ ma_15min_slope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3402582214.py:14: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['price_1min_avg'] = df_temp['price'].rolling(window='1T', min_periods=1).mean()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3402582214.py:17: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['price_5min_avg'] = df_temp['price'].rolling(window='5T', min_periods=1).mean()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3402582214.py:20: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['price_15min_avg'] = df_temp['price'].rolling(window='15T', min_periods=1).mean()\n"
     ]
    }
   ],
   "source": [
    "# Calculate rolling averages (1 min, 5 min, 15 min) for price\n",
    "print(\"=== ROLLING AVERAGE CALCULATION ===\")\n",
    "\n",
    "# First, ensure the dataframe is sorted by datetime\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Set datetime as index for time-based rolling operations\n",
    "df_temp = df.set_index('date')\n",
    "\n",
    "# Calculate rolling averages at different time intervals\n",
    "print(\"Calculating rolling averages...\")\n",
    "\n",
    "# 1-minute rolling average\n",
    "df_temp['price_1min_avg'] = df_temp['price'].rolling(window='1T', min_periods=1).mean()\n",
    "\n",
    "# 5-minute rolling average\n",
    "df_temp['price_5min_avg'] = df_temp['price'].rolling(window='5T', min_periods=1).mean()\n",
    "\n",
    "# 15-minute rolling average\n",
    "df_temp['price_15min_avg'] = df_temp['price'].rolling(window='15T', min_periods=1).mean()\n",
    "\n",
    "# Reset index to get back to normal dataframe format\n",
    "df = df_temp.reset_index()\n",
    "\n",
    "# Display sample data with rolling averages\n",
    "print(\"=== SAMPLE DATA WITH ROLLING AVERAGES ===\")\n",
    "print(df[['date', 'price', 'price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'qty']].head(15))\n",
    "\n",
    "# Basic statistics of rolling averages\n",
    "print(f\"\\n=== ROLLING AVERAGE STATISTICS ===\")\n",
    "rolling_cols = ['price_1min_avg', 'price_5min_avg', 'price_15min_avg']\n",
    "\n",
    "for col in rolling_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: ₹{df[col].min():.2f}\")\n",
    "    print(f\"  Max: ₹{df[col].min():.2f}\")\n",
    "    print(f\"  Mean: ₹{df[col].mean():.2f}\")\n",
    "    print(f\"  Std: ₹{df[col].std():.2f}\")\n",
    "\n",
    "# Compare current price vs rolling averages\n",
    "print(f\"\\n=== PRICE VS ROLLING AVERAGES ANALYSIS ===\")\n",
    "\n",
    "# Calculate differences from rolling averages\n",
    "df['price_vs_1min'] = df['price'] - df['price_1min_avg']\n",
    "df['price_vs_5min'] = df['price'] - df['price_5min_avg']\n",
    "df['price_vs_15min'] = df['price'] - df['price_15min_avg']\n",
    "\n",
    "# Show statistics of these differences\n",
    "print(\"Price differences from rolling averages:\")\n",
    "print(f\"  vs 1-min avg: Mean={df['price_vs_1min'].mean():.2f}, Std={df['price_vs_1min'].std():.2f}\")\n",
    "print(f\"  vs 5-min avg: Mean={df['price_vs_5min'].mean():.2f}, Std={df['price_vs_5min'].std():.2f}\")\n",
    "print(f\"  vs 15-min avg: Mean={df['price_vs_15min'].mean():.2f}, Std={df['price_vs_15min'].std():.2f}\")\n",
    "\n",
    "# Identify when price is above/below each moving average\n",
    "print(f\"\\n=== MOVING AVERAGE CROSSOVER ANALYSIS ===\")\n",
    "\n",
    "# Price position relative to moving averages\n",
    "df['above_1min'] = df['price'] > df['price_1min_avg']\n",
    "df['above_5min'] = df['price'] > df['price_5min_avg']\n",
    "df['above_15min'] = df['price'] > df['price_15min_avg']\n",
    "\n",
    "# Count how many times price is above each moving average\n",
    "above_1min_count = df['above_1min'].sum()\n",
    "above_5min_count = df['above_5min'].sum()\n",
    "above_15min_count = df['above_15min'].sum()\n",
    "\n",
    "print(f\"Price above 1-min average: {above_1min_count:,} times ({(above_1min_count/len(df)*100):.1f}%)\")\n",
    "print(f\"Price above 5-min average: {above_5min_count:,} times ({(above_5min_count/len(df)*100):.1f}%)\")\n",
    "print(f\"Price above 15-min average: {above_15min_count:,} times ({(above_15min_count/len(df)*100):.1f}%)\")\n",
    "\n",
    "# Moving average crossover signals\n",
    "print(f\"\\n=== MOVING AVERAGE CROSSOVER SIGNALS ===\")\n",
    "\n",
    "# 1-min vs 5-min crossover\n",
    "df['ma_1min_5min_cross'] = (df['price_1min_avg'] > df['price_5min_avg']).astype(int)\n",
    "df['ma_1min_5min_signal'] = df['ma_1min_5min_cross'].diff()\n",
    "\n",
    "# 5-min vs 15-min crossover\n",
    "df['ma_5min_15min_cross'] = (df['price_5min_avg'] > df['price_15min_avg']).astype(int)\n",
    "df['ma_5min_15min_signal'] = df['ma_5min_15min_cross'].diff()\n",
    "\n",
    "# Count crossover signals\n",
    "bullish_1min_5min = (df['ma_1min_5min_signal'] == 1).sum()\n",
    "bearish_1min_5min = (df['ma_1min_5min_signal'] == -1).sum()\n",
    "\n",
    "bullish_5min_15min = (df['ma_5min_15min_signal'] == 1).sum()\n",
    "bearish_5min_15min = (df['ma_5min_15min_signal'] == -1).sum()\n",
    "\n",
    "print(f\"1-min vs 5-min crossovers:\")\n",
    "print(f\"  Bullish (1-min crosses above 5-min): {bullish_1min_5min}\")\n",
    "print(f\"  Bearish (1-min crosses below 5-min): {bearish_1min_5min}\")\n",
    "\n",
    "print(f\"\\n5-min vs 15-min crossovers:\")\n",
    "print(f\"  Bullish (5-min crosses above 15-min): {bullish_5min_15min}\")\n",
    "print(f\"  Bearish (5-min crosses below 15-min): {bearish_5min_15min}\")\n",
    "\n",
    "# Show sample of crossover signals\n",
    "print(f\"\\n=== SAMPLE CROSSOVER SIGNALS ===\")\n",
    "crossover_sample = df[df['ma_1min_5min_signal'] != 0][['date', 'price', 'price_1min_avg', 'price_5min_avg', 'ma_1min_5min_signal']].head(10)\n",
    "print(\"Recent 1-min vs 5-min crossovers:\")\n",
    "print(crossover_sample.to_string(index=False))\n",
    "\n",
    "# Rolling average trends\n",
    "print(f\"\\n=== ROLLING AVERAGE TRENDS ===\")\n",
    "\n",
    "# Calculate the slope of each moving average (trend direction)\n",
    "df['ma_1min_slope'] = df['price_1min_avg'].diff()\n",
    "df['ma_5min_slope'] = df['price_5min_avg'].diff()\n",
    "df['ma_15min_slope'] = df['price_15min_avg'].diff()\n",
    "\n",
    "# Count trending periods\n",
    "trending_1min_up = (df['ma_1min_slope'] > 0).sum()\n",
    "trending_1min_down = (df['ma_1min_slope'] < 0).sum()\n",
    "\n",
    "print(f\"1-min moving average trends:\")\n",
    "print(f\"  Upward trending periods: {trending_1min_up:,}\")\n",
    "print(f\"  Downward trending periods: {trending_1min_down:,}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== ROLLING AVERAGE SUMMARY ===\")\n",
    "print(f\"✓ 1-minute rolling average calculated\")\n",
    "print(f\"✓ 5-minute rolling average calculated\")\n",
    "print(f\"✓ 15-minute rolling average calculated\")\n",
    "print(f\"✓ Crossover signals identified\")\n",
    "print(f\"✓ Trend analysis completed\")\n",
    "print(f\"✓ Ready for technical analysis and trading signals\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"New columns added:\")\n",
    "new_cols = ['price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'price_vs_1min', \n",
    "            'price_vs_5min', 'price_vs_15min', 'above_1min', 'above_5min', 'above_15min',\n",
    "            'ma_1min_5min_cross', 'ma_1min_5min_signal', 'ma_5min_15min_cross', \n",
    "            'ma_5min_15min_signal', 'ma_1min_slope', 'ma_5min_slope', 'ma_15min_slope']\n",
    "for col in new_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  ✓ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3afb2c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ROLLING VOLUME SUM CALCULATION ===\n",
      "Calculating rolling volume sums...\n",
      "=== SAMPLE DATA WITH ROLLING VOLUME SUMS ===\n",
      "                  date    qty  volume_1min_sum  volume_5min_sum  \\\n",
      "0  2025-08-07 09:15:00  65740          65740.0          65740.0   \n",
      "1  2025-08-07 09:15:01    895          66635.0          66635.0   \n",
      "2  2025-08-07 09:15:01   1401          68036.0          68036.0   \n",
      "3  2025-08-07 09:15:02   1795          69831.0          69831.0   \n",
      "4  2025-08-07 09:15:02    741          70572.0          70572.0   \n",
      "5  2025-08-07 09:15:03   2717          73289.0          73289.0   \n",
      "6  2025-08-07 09:15:03   9068          82357.0          82357.0   \n",
      "7  2025-08-07 09:15:04   1141          83498.0          83498.0   \n",
      "8  2025-08-07 09:15:04   1798          85296.0          85296.0   \n",
      "9  2025-08-07 09:15:05   2092          87388.0          87388.0   \n",
      "10 2025-08-07 09:15:05   1679          89067.0          89067.0   \n",
      "11 2025-08-07 09:15:06   4519          93586.0          93586.0   \n",
      "12 2025-08-07 09:15:06   1316          94902.0          94902.0   \n",
      "13 2025-08-07 09:15:07   2858          97760.0          97760.0   \n",
      "14 2025-08-07 09:15:07    640          98400.0          98400.0   \n",
      "\n",
      "    volume_15min_sum  volume_30min_sum  \n",
      "0            65740.0           65740.0  \n",
      "1            66635.0           66635.0  \n",
      "2            68036.0           68036.0  \n",
      "3            69831.0           69831.0  \n",
      "4            70572.0           70572.0  \n",
      "5            73289.0           73289.0  \n",
      "6            82357.0           82357.0  \n",
      "7            83498.0           83498.0  \n",
      "8            85296.0           85296.0  \n",
      "9            87388.0           87388.0  \n",
      "10           89067.0           89067.0  \n",
      "11           93586.0           93586.0  \n",
      "12           94902.0           94902.0  \n",
      "13           97760.0           97760.0  \n",
      "14           98400.0           98400.0  \n",
      "\n",
      "=== ROLLING VOLUME SUM STATISTICS ===\n",
      "\n",
      "volume_1min_sum:\n",
      "  Min: 3,271\n",
      "  Max: 240,694\n",
      "  Mean: 41,775\n",
      "  Std: 40,998\n",
      "\n",
      "volume_5min_sum:\n",
      "  Min: 44,608\n",
      "  Max: 751,790\n",
      "  Mean: 183,460\n",
      "  Std: 118,364\n",
      "\n",
      "volume_15min_sum:\n",
      "  Min: 65,740\n",
      "  Max: 1,421,831\n",
      "  Mean: 479,341\n",
      "  Std: 213,644\n",
      "\n",
      "volume_30min_sum:\n",
      "  Min: 65,740\n",
      "  Max: 1,828,633\n",
      "  Mean: 897,923\n",
      "  Std: 342,277\n",
      "\n",
      "=== VOLUME ANALYSIS BY TIME WINDOWS ===\n",
      "Volume comparison across timeframes:\n",
      "  1-min average: 41,775\n",
      "  5-min average: 183,460\n",
      "  15-min average: 479,341\n",
      "  30-min average: 897,923\n",
      "\n",
      "=== VOLUME INTENSITY ANALYSIS ===\n",
      "Volume per minute for each window:\n",
      "  1-min window: 41,775 per minute\n",
      "  5-min window: 36,692 per minute\n",
      "  15-min window: 31,956 per minute\n",
      "  30-min window: 29,931 per minute\n",
      "\n",
      "=== VOLUME SPIKE DETECTION ===\n",
      "volume_1min_sum: 629 periods above 123,771 (2σ threshold)\n",
      "volume_5min_sum: 374 periods above 420,188 (2σ threshold)\n",
      "volume_15min_sum: 334 periods above 906,628 (2σ threshold)\n",
      "volume_30min_sum: 726 periods above 1,582,477 (2σ threshold)\n",
      "\n",
      "=== EXAMPLES OF VOLUME SPIKES ===\n",
      "\n",
      "volume_1min_sum spikes (top 3):\n",
      "               date  volume_1min_sum  qty  price\n",
      "2025-08-07 09:15:09         123896.0 1904  386.0\n",
      "2025-08-07 09:15:10         124376.0  480  385.7\n",
      "2025-08-07 09:15:10         130704.0 6328  386.0\n",
      "\n",
      "volume_5min_sum spikes (top 3):\n",
      "               date  volume_5min_sum   qty  price\n",
      "2025-08-07 09:17:00         424009.0  6377 387.60\n",
      "2025-08-07 09:17:08         441708.0 17699 387.60\n",
      "2025-08-07 09:17:09         446868.0  5160 387.55\n",
      "\n",
      "volume_15min_sum spikes (top 3):\n",
      "               date  volume_15min_sum   qty  price\n",
      "2025-08-07 09:20:49          932902.0 43873 389.85\n",
      "2025-08-07 09:21:01          966465.0 33563 389.65\n",
      "2025-08-07 09:21:01          967610.0  1145 389.55\n",
      "\n",
      "volume_30min_sum spikes (top 3):\n",
      "               date  volume_30min_sum  qty  price\n",
      "2025-08-07 09:35:12         1583813.0 4419 389.25\n",
      "2025-08-07 09:35:19         1583994.0  181 389.20\n",
      "2025-08-07 09:35:27         1586242.0 2248 389.25\n",
      "\n",
      "=== VOLUME TREND ANALYSIS ===\n",
      "Volume 1Min:\n",
      "  Increasing: 7,218 periods\n",
      "  Decreasing: 3,706 periods\n",
      "Volume 5Min:\n",
      "  Increasing: 7,590 periods\n",
      "  Decreasing: 3,342 periods\n",
      "Volume 15Min:\n",
      "  Increasing: 7,651 periods\n",
      "  Decreasing: 3,280 periods\n",
      "Volume 30Min:\n",
      "  Increasing: 7,952 periods\n",
      "  Decreasing: 2,980 periods\n",
      "\n",
      "=== VOLUME-PRICE CORRELATION ===\n",
      "volume_1min_sum vs Price correlation: 0.1923\n",
      "volume_5min_sum vs Price correlation: 0.4227\n",
      "volume_15min_sum vs Price correlation: 0.5060\n",
      "volume_30min_sum vs Price correlation: 0.4976\n",
      "\n",
      "Volume vs Price Change correlation:\n",
      "volume_1min_sum vs Price Change correlation: 0.0107\n",
      "volume_5min_sum vs Price Change correlation: 0.0141\n",
      "volume_15min_sum vs Price Change correlation: 0.0065\n",
      "volume_30min_sum vs Price Change correlation: 0.0019\n",
      "\n",
      "=== TIME-BASED VOLUME ANALYSIS ===\n",
      "Total volume by hour:\n",
      "  09:00 - 09:59: 2,164,111\n",
      "  10:00 - 10:59: 1,436,774\n",
      "  11:00 - 11:59: 1,340,606\n",
      "  12:00 - 12:59: 1,462,840\n",
      "  13:00 - 13:59: 1,428,015\n",
      "  14:00 - 14:59: 1,985,212\n",
      "  15:00 - 15:59: 1,692,613\n",
      "\n",
      "=== ROLLING VS CUMULATIVE VOLUME ===\n",
      "Final cumulative volume: 11,466,759\n",
      "Final 30-min rolling volume: 1,692,613\n",
      "Rolling volume as % of total: 14.8%\n",
      "\n",
      "=== ROLLING VOLUME SUMMARY ===\n",
      "✓ 1-minute rolling volume sum calculated\n",
      "✓ 5-minute rolling volume sum calculated\n",
      "✓ 15-minute rolling volume sum calculated\n",
      "✓ 30-minute rolling volume sum calculated\n",
      "✓ Volume intensity analysis completed\n",
      "✓ Volume spike detection implemented\n",
      "✓ Volume-price correlation analyzed\n",
      "✓ Ready for volume-based analysis and trading signals\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change', 'direction', 'price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'price_vs_1min', 'price_vs_5min', 'price_vs_15min', 'above_1min', 'above_5min', 'above_15min', 'ma_1min_5min_cross', 'ma_1min_5min_signal', 'ma_5min_15min_cross', 'ma_5min_15min_signal', 'ma_1min_slope', 'ma_5min_slope', 'ma_15min_slope', 'volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum', 'volume_1min_per_min', 'volume_5min_per_min', 'volume_15min_per_min', 'volume_30min_per_min', 'volume_1min_trend', 'volume_5min_trend', 'volume_15min_trend', 'volume_30min_trend']\n",
      "Shape: (10956, 40)\n",
      "New volume columns added:\n",
      "  ✓ volume_1min_sum\n",
      "  ✓ volume_5min_sum\n",
      "  ✓ volume_15min_sum\n",
      "  ✓ volume_30min_sum\n",
      "  ✓ volume_1min_per_min\n",
      "  ✓ volume_5min_per_min\n",
      "  ✓ volume_15min_per_min\n",
      "  ✓ volume_30min_per_min\n",
      "  ✓ volume_1min_trend\n",
      "  ✓ volume_5min_trend\n",
      "  ✓ volume_15min_trend\n",
      "  ✓ volume_30min_trend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\559120730.py:11: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['volume_1min_sum'] = df_temp['qty'].rolling(window='1T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\559120730.py:14: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['volume_5min_sum'] = df_temp['qty'].rolling(window='5T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\559120730.py:17: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['volume_15min_sum'] = df_temp['qty'].rolling(window='15T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\559120730.py:20: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['volume_30min_sum'] = df_temp['qty'].rolling(window='30T', min_periods=1).sum()\n"
     ]
    }
   ],
   "source": [
    "# Calculate rolling sum of volume over time windows\n",
    "print(\"=== ROLLING VOLUME SUM CALCULATION ===\")\n",
    "\n",
    "# Ensure the dataframe is sorted by datetime and has datetime index\n",
    "df_temp = df.set_index('date')\n",
    "\n",
    "# Calculate rolling sum of volume at different time intervals\n",
    "print(\"Calculating rolling volume sums...\")\n",
    "\n",
    "# 1-minute rolling volume sum\n",
    "df_temp['volume_1min_sum'] = df_temp['qty'].rolling(window='1T', min_periods=1).sum()\n",
    "\n",
    "# 5-minute rolling volume sum\n",
    "df_temp['volume_5min_sum'] = df_temp['qty'].rolling(window='5T', min_periods=1).sum()\n",
    "\n",
    "# 15-minute rolling volume sum\n",
    "df_temp['volume_15min_sum'] = df_temp['qty'].rolling(window='15T', min_periods=1).sum()\n",
    "\n",
    "# 30-minute rolling volume sum\n",
    "df_temp['volume_30min_sum'] = df_temp['qty'].rolling(window='30T', min_periods=1).sum()\n",
    "\n",
    "# Reset index to get back to normal dataframe format\n",
    "df = df_temp.reset_index()\n",
    "\n",
    "# Display sample data with rolling volume sums\n",
    "print(\"=== SAMPLE DATA WITH ROLLING VOLUME SUMS ===\")\n",
    "print(df[['date', 'qty', 'volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum']].head(15))\n",
    "\n",
    "# Basic statistics of rolling volume sums\n",
    "print(f\"\\n=== ROLLING VOLUME SUM STATISTICS ===\")\n",
    "volume_sum_cols = ['volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum']\n",
    "\n",
    "for col in volume_sum_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: {df[col].min():,.0f}\")\n",
    "    print(f\"  Max: {df[col].max():,.0f}\")\n",
    "    print(f\"  Mean: {df[col].mean():,.0f}\")\n",
    "    print(f\"  Std: {df[col].std():,.0f}\")\n",
    "\n",
    "# Volume analysis by time windows\n",
    "print(f\"\\n=== VOLUME ANALYSIS BY TIME WINDOWS ===\")\n",
    "\n",
    "# Compare volume across different timeframes\n",
    "print(\"Volume comparison across timeframes:\")\n",
    "print(f\"  1-min average: {df['volume_1min_sum'].mean():,.0f}\")\n",
    "print(f\"  5-min average: {df['volume_5min_sum'].mean():,.0f}\")\n",
    "print(f\"  15-min average: {df['volume_15min_sum'].mean():,.0f}\")\n",
    "print(f\"  30-min average: {df['volume_30min_sum'].mean():,.0f}\")\n",
    "\n",
    "# Volume intensity analysis\n",
    "print(f\"\\n=== VOLUME INTENSITY ANALYSIS ===\")\n",
    "\n",
    "# Calculate volume per minute for each window\n",
    "df['volume_1min_per_min'] = df['volume_1min_sum'] / 1\n",
    "df['volume_5min_per_min'] = df['volume_5min_sum'] / 5\n",
    "df['volume_15min_per_min'] = df['volume_15min_sum'] / 15\n",
    "df['volume_30min_per_min'] = df['volume_30min_sum'] / 30\n",
    "\n",
    "print(\"Volume per minute for each window:\")\n",
    "print(f\"  1-min window: {df['volume_1min_per_min'].mean():,.0f} per minute\")\n",
    "print(f\"  5-min window: {df['volume_5min_per_min'].mean():,.0f} per minute\")\n",
    "print(f\"  15-min window: {df['volume_15min_per_min'].mean():,.0f} per minute\")\n",
    "print(f\"  30-min window: {df['volume_30min_per_min'].mean():,.0f} per minute\")\n",
    "\n",
    "# Volume spikes detection\n",
    "print(f\"\\n=== VOLUME SPIKE DETECTION ===\")\n",
    "\n",
    "# Find periods of unusually high volume (above 2 standard deviations)\n",
    "for col in volume_sum_cols:\n",
    "    mean_vol = df[col].mean()\n",
    "    std_vol = df[col].std()\n",
    "    threshold = mean_vol + 2 * std_vol\n",
    "    \n",
    "    high_volume_periods = (df[col] > threshold).sum()\n",
    "    print(f\"{col}: {high_volume_periods} periods above {threshold:,.0f} (2σ threshold)\")\n",
    "\n",
    "# Show examples of volume spikes\n",
    "print(f\"\\n=== EXAMPLES OF VOLUME SPIKES ===\")\n",
    "for col in volume_sum_cols:\n",
    "    mean_vol = df[col].mean()\n",
    "    std_vol = df[col].std()\n",
    "    threshold = mean_vol + 2 * std_vol\n",
    "    \n",
    "    spikes = df[df[col] > threshold][['date', col, 'qty', 'price']].head(3)\n",
    "    if len(spikes) > 0:\n",
    "        print(f\"\\n{col} spikes (top 3):\")\n",
    "        print(spikes.to_string(index=False))\n",
    "\n",
    "# Volume trend analysis\n",
    "print(f\"\\n=== VOLUME TREND ANALYSIS ===\")\n",
    "\n",
    "# Calculate volume trends (slopes) for each window\n",
    "df['volume_1min_trend'] = df['volume_1min_sum'].diff()\n",
    "df['volume_5min_trend'] = df['volume_5min_sum'].diff()\n",
    "df['volume_15min_trend'] = df['volume_15min_sum'].diff()\n",
    "df['volume_30min_trend'] = df['volume_30min_sum'].diff()\n",
    "\n",
    "# Count increasing vs decreasing volume periods\n",
    "for col in ['volume_1min_trend', 'volume_5min_trend', 'volume_15min_trend', 'volume_30min_trend']:\n",
    "    increasing = (df[col] > 0).sum()\n",
    "    decreasing = (df[col] < 0).sum()\n",
    "    window_name = col.replace('_trend', '').replace('_', ' ').title()\n",
    "    print(f\"{window_name}:\")\n",
    "    print(f\"  Increasing: {increasing:,} periods\")\n",
    "    print(f\"  Decreasing: {decreasing:,} periods\")\n",
    "\n",
    "# Volume vs Price correlation\n",
    "print(f\"\\n=== VOLUME-PRICE CORRELATION ===\")\n",
    "\n",
    "# Calculate correlation between volume and price for each timeframe\n",
    "for col in volume_sum_cols:\n",
    "    correlation = df[col].corr(df['price'])\n",
    "    print(f\"{col} vs Price correlation: {correlation:.4f}\")\n",
    "\n",
    "# Volume vs Price change correlation\n",
    "print(f\"\\nVolume vs Price Change correlation:\")\n",
    "for col in volume_sum_cols:\n",
    "    correlation = df[col].corr(df['price_change'])\n",
    "    print(f\"{col} vs Price Change correlation: {correlation:.4f}\")\n",
    "\n",
    "# Time-based volume analysis\n",
    "print(f\"\\n=== TIME-BASED VOLUME ANALYSIS ===\")\n",
    "\n",
    "# Volume by hour of the day\n",
    "df['hour'] = df['date'].dt.hour\n",
    "hourly_volume = df.groupby('hour')['qty'].sum()\n",
    "print(\"Total volume by hour:\")\n",
    "for hour, volume in hourly_volume.items():\n",
    "    print(f\"  {hour:02d}:00 - {hour:02d}:59: {volume:,}\")\n",
    "\n",
    "# Rolling volume vs cumulative volume comparison\n",
    "print(f\"\\n=== ROLLING VS CUMULATIVE VOLUME ===\")\n",
    "print(f\"Final cumulative volume: {df['cum_trnvr'].iloc[-1]/df['price'].iloc[-1]:,.0f}\")\n",
    "print(f\"Final 30-min rolling volume: {df['volume_30min_sum'].iloc[-1]:,.0f}\")\n",
    "print(f\"Rolling volume as % of total: {(df['volume_30min_sum'].iloc[-1]/(df['cum_trnvr'].iloc[-1]/df['price'].iloc[-1])*100):.1f}%\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== ROLLING VOLUME SUMMARY ===\")\n",
    "print(f\"✓ 1-minute rolling volume sum calculated\")\n",
    "print(f\"✓ 5-minute rolling volume sum calculated\")\n",
    "print(f\"✓ 15-minute rolling volume sum calculated\")\n",
    "print(f\"✓ 30-minute rolling volume sum calculated\")\n",
    "print(f\"✓ Volume intensity analysis completed\")\n",
    "print(f\"✓ Volume spike detection implemented\")\n",
    "print(f\"✓ Volume-price correlation analyzed\")\n",
    "print(f\"✓ Ready for volume-based analysis and trading signals\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"New volume columns added:\")\n",
    "volume_new_cols = ['volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum',\n",
    "                   'volume_1min_per_min', 'volume_5min_per_min', 'volume_15min_per_min', 'volume_30min_per_min',\n",
    "                   'volume_1min_trend', 'volume_5min_trend', 'volume_15min_trend', 'volume_30min_trend']\n",
    "for col in volume_new_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  ✓ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c267ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VWAP CALCULATION ===\n",
      "Calculating VWAP...\n",
      "=== OVERALL VWAP ===\n",
      "Total volume: 11,510,171\n",
      "Total price × volume: ₹4,451,969,111.70\n",
      "Overall VWAP: ₹386.79\n",
      "\n",
      "=== ROLLING VWAP CALCULATION ===\n",
      "=== SAMPLE DATA WITH VWAP VALUES ===\n",
      "                  date   price    qty   vwap_1min   vwap_5min  vwap_15min  \\\n",
      "0  2025-08-07 09:15:00  386.85  65740  386.850000  386.850000  386.850000   \n",
      "1  2025-08-07 09:15:01  386.30    895  386.842613  386.842613  386.842613   \n",
      "2  2025-08-07 09:15:01  386.75   1401  386.840706  386.840706  386.840706   \n",
      "3  2025-08-07 09:15:02  386.80   1795  386.839659  386.839659  386.839659   \n",
      "4  2025-08-07 09:15:02  386.95    741  386.840818  386.840818  386.840818   \n",
      "5  2025-08-07 09:15:03  386.90   2717  386.843012  386.843012  386.843012   \n",
      "6  2025-08-07 09:15:03  386.80   9068  386.838276  386.838276  386.838276   \n",
      "7  2025-08-07 09:15:04  386.75   1141  386.837070  386.837070  386.837070   \n",
      "8  2025-08-07 09:15:04  386.90   1798  386.838396  386.838396  386.838396   \n",
      "9  2025-08-07 09:15:05  386.65   2092  386.833886  386.833886  386.833886   \n",
      "10 2025-08-07 09:15:05  386.75   1679  386.832305  386.832305  386.832305   \n",
      "11 2025-08-07 09:15:06  386.65   4519  386.823502  386.823502  386.823502   \n",
      "12 2025-08-07 09:15:06  386.55   1316  386.819709  386.819709  386.819709   \n",
      "13 2025-08-07 09:15:07  386.40   2858  386.807439  386.807439  386.807439   \n",
      "14 2025-08-07 09:15:07  386.10    640  386.802838  386.802838  386.802838   \n",
      "\n",
      "    vwap_30min  \n",
      "0   386.850000  \n",
      "1   386.842613  \n",
      "2   386.840706  \n",
      "3   386.839659  \n",
      "4   386.840818  \n",
      "5   386.843012  \n",
      "6   386.838276  \n",
      "7   386.837070  \n",
      "8   386.838396  \n",
      "9   386.833886  \n",
      "10  386.832305  \n",
      "11  386.823502  \n",
      "12  386.819709  \n",
      "13  386.807439  \n",
      "14  386.802838  \n",
      "\n",
      "=== VWAP STATISTICS ===\n",
      "\n",
      "vwap_1min:\n",
      "  Min: ₹383.54\n",
      "  Max: ₹383.54\n",
      "  Mean: ₹386.55\n",
      "  Std: ₹1.56\n",
      "\n",
      "vwap_5min:\n",
      "  Min: ₹383.66\n",
      "  Max: ₹383.66\n",
      "  Mean: ₹386.52\n",
      "  Std: ₹1.50\n",
      "\n",
      "vwap_15min:\n",
      "  Min: ₹383.79\n",
      "  Max: ₹383.79\n",
      "  Mean: ₹386.48\n",
      "  Std: ₹1.42\n",
      "\n",
      "vwap_30min:\n",
      "  Min: ₹384.00\n",
      "  Max: ₹384.00\n",
      "  Mean: ₹386.47\n",
      "  Std: ₹1.38\n",
      "\n",
      "=== PRICE VS VWAP ANALYSIS ===\n",
      "Price position relative to VWAP:\n",
      "\n",
      "  1min VWAP:\n",
      "    Above: 5,375 times (49.1%)\n",
      "    Below: 5,580 times (50.9%)\n",
      "    Equal: 1 times (0.0%)\n",
      "\n",
      "  5min VWAP:\n",
      "    Above: 5,725 times (52.3%)\n",
      "    Below: 5,230 times (47.7%)\n",
      "    Equal: 1 times (0.0%)\n",
      "\n",
      "  15min VWAP:\n",
      "    Above: 5,933 times (54.2%)\n",
      "    Below: 5,022 times (45.8%)\n",
      "    Equal: 1 times (0.0%)\n",
      "\n",
      "  30min VWAP:\n",
      "    Above: 5,696 times (52.0%)\n",
      "    Below: 5,259 times (48.0%)\n",
      "    Equal: 1 times (0.0%)\n",
      "\n",
      "=== VWAP AS SUPPORT/RESISTANCE ===\n",
      "1min VWAP: 10,780 times price within 0.1% of VWAP\n",
      "5min VWAP: 9,278 times price within 0.1% of VWAP\n",
      "15min VWAP: 6,740 times price within 0.1% of VWAP\n",
      "30min VWAP: 4,183 times price within 0.1% of VWAP\n",
      "\n",
      "=== VWAP CROSSOVER ANALYSIS ===\n",
      "1min VWAP crossovers:\n",
      "  Bullish (price crosses above): 932\n",
      "  Bearish (price crosses below): 931\n",
      "5min VWAP crossovers:\n",
      "  Bullish (price crosses above): 427\n",
      "  Bearish (price crosses below): 427\n",
      "15min VWAP crossovers:\n",
      "  Bullish (price crosses above): 215\n",
      "  Bearish (price crosses below): 214\n",
      "30min VWAP crossovers:\n",
      "  Bullish (price crosses above): 135\n",
      "  Bearish (price crosses below): 134\n",
      "\n",
      "=== VWAP TREND ANALYSIS ===\n",
      "1min VWAP trends:\n",
      "  Upward: 5,522 periods\n",
      "  Downward: 5,430 periods\n",
      "5min VWAP trends:\n",
      "  Upward: 5,691 periods\n",
      "  Downward: 5,264 periods\n",
      "15min VWAP trends:\n",
      "  Upward: 5,766 periods\n",
      "  Downward: 5,188 periods\n",
      "30min VWAP trends:\n",
      "  Upward: 5,418 periods\n",
      "  Downward: 5,537 periods\n",
      "\n",
      "=== VWAP VS SIMPLE MOVING AVERAGE ===\n",
      "VWAP vs Simple Price Average:\n",
      "  Overall VWAP: ₹386.79\n",
      "  Simple Price Average: ₹386.56\n",
      "  Difference: ₹0.22\n",
      "  vwap_1min vs Price correlation: 0.9949\n",
      "  vwap_5min vs Price correlation: 0.9767\n",
      "  vwap_15min vs Price correlation: 0.9531\n",
      "  vwap_30min vs Price correlation: 0.9216\n",
      "\n",
      "=== VWAP TRADING SIGNALS ===\n",
      "VWAP-based trading signals (using 15-min VWAP):\n",
      "  Buy: 5,933 times (54.2%)\n",
      "  Sell: 5,022 times (45.8%)\n",
      "  Hold: 1 times (0.0%)\n",
      "\n",
      "=== VWAP SUMMARY ===\n",
      "✓ Overall VWAP: ₹386.79\n",
      "✓ Rolling VWAP calculated for 1min, 5min, 15min, 30min windows\n",
      "✓ Price vs VWAP analysis completed\n",
      "✓ VWAP crossover signals generated\n",
      "✓ VWAP trend analysis completed\n",
      "✓ Trading signals based on VWAP generated\n",
      "✓ Ready for VWAP-based trading strategies\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change', 'direction', 'price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'price_vs_1min', 'price_vs_5min', 'price_vs_15min', 'above_1min', 'above_5min', 'above_15min', 'ma_1min_5min_cross', 'ma_1min_5min_signal', 'ma_5min_15min_cross', 'ma_5min_15min_signal', 'ma_1min_slope', 'ma_5min_slope', 'ma_15min_slope', 'volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum', 'volume_1min_per_min', 'volume_5min_per_min', 'volume_15min_per_min', 'volume_30min_per_min', 'volume_1min_trend', 'volume_5min_trend', 'volume_15min_trend', 'volume_30min_trend', 'vwap_1min', 'vwap_5min', 'vwap_15min', 'vwap_30min', 'price_vs_vwap_1min', 'price_vs_vwap_5min', 'price_vs_vwap_15min', 'price_vs_vwap_30min', 'above_vwap_1min', 'vwap_1min_cross', 'vwap_1min_signal', 'above_vwap_5min', 'vwap_5min_cross', 'vwap_5min_signal', 'above_vwap_15min', 'vwap_15min_cross', 'vwap_15min_signal', 'above_vwap_30min', 'vwap_30min_cross', 'vwap_30min_signal', 'vwap_1min_trend', 'vwap_5min_trend', 'vwap_15min_trend', 'vwap_30min_trend', 'vwap_signal']\n",
      "Shape: (10956, 65)\n",
      "New VWAP columns added:\n",
      "  ✓ vwap_1min\n",
      "  ✓ vwap_5min\n",
      "  ✓ vwap_15min\n",
      "  ✓ vwap_30min\n",
      "  ✓ price_vs_vwap_1min\n",
      "  ✓ price_vs_vwap_5min\n",
      "  ✓ price_vs_vwap_15min\n",
      "  ✓ price_vs_vwap_30min\n",
      "  ✓ above_vwap_1min\n",
      "  ✓ above_vwap_5min\n",
      "  ✓ above_vwap_15min\n",
      "  ✓ above_vwap_30min\n",
      "  ✓ vwap_1min_cross\n",
      "  ✓ vwap_5min_cross\n",
      "  ✓ vwap_15min_cross\n",
      "  ✓ vwap_30min_cross\n",
      "  ✓ vwap_1min_signal\n",
      "  ✓ vwap_5min_signal\n",
      "  ✓ vwap_15min_signal\n",
      "  ✓ vwap_30min_signal\n",
      "  ✓ vwap_1min_trend\n",
      "  ✓ vwap_5min_trend\n",
      "  ✓ vwap_15min_trend\n",
      "  ✓ vwap_30min_trend\n",
      "  ✓ vwap_signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3292836047.py:24: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['vwap_1min'] = (df_temp['price'] * df_temp['qty']).rolling(window='1T', min_periods=1).sum() / df_temp['qty'].rolling(window='1T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3292836047.py:26: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['vwap_5min'] = (df_temp['price'] * df_temp['qty']).rolling(window='5T', min_periods=1).sum() / df_temp['qty'].rolling(window='5T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3292836047.py:28: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['vwap_15min'] = (df_temp['price'] * df_temp['qty']).rolling(window='15T', min_periods=1).sum() / df_temp['qty'].rolling(window='15T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3292836047.py:30: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['vwap_30min'] = (df_temp['price'] * df_temp['qty']).rolling(window='30T', min_periods=1).sum() / df_temp['qty'].rolling(window='30T', min_periods=1).sum()\n"
     ]
    }
   ],
   "source": [
    "# Compute VWAP (Volume Weighted Average Price)\n",
    "print(\"=== VWAP CALCULATION ===\")\n",
    "\n",
    "# Calculate VWAP for the entire dataset\n",
    "print(\"Calculating VWAP...\")\n",
    "\n",
    "# Method 1: Simple VWAP for entire dataset\n",
    "total_volume = df['qty'].sum()\n",
    "total_price_volume = (df['price'] * df['qty']).sum()\n",
    "vwap_total = total_price_volume / total_volume\n",
    "\n",
    "print(f\"=== OVERALL VWAP ===\")\n",
    "print(f\"Total volume: {total_volume:,}\")\n",
    "print(f\"Total price × volume: ₹{total_price_volume:,.2f}\")\n",
    "print(f\"Overall VWAP: ₹{vwap_total:.2f}\")\n",
    "\n",
    "# Method 2: Rolling VWAP over different time windows\n",
    "print(f\"\\n=== ROLLING VWAP CALCULATION ===\")\n",
    "\n",
    "# Ensure datetime index for time-based rolling\n",
    "df_temp = df.set_index('date')\n",
    "\n",
    "# Calculate rolling VWAP for different time windows\n",
    "df_temp['vwap_1min'] = (df_temp['price'] * df_temp['qty']).rolling(window='1T', min_periods=1).sum() / df_temp['qty'].rolling(window='1T', min_periods=1).sum()\n",
    "\n",
    "df_temp['vwap_5min'] = (df_temp['price'] * df_temp['qty']).rolling(window='5T', min_periods=1).sum() / df_temp['qty'].rolling(window='5T', min_periods=1).sum()\n",
    "\n",
    "df_temp['vwap_15min'] = (df_temp['price'] * df_temp['qty']).rolling(window='15T', min_periods=1).sum() / df_temp['qty'].rolling(window='15T', min_periods=1).sum()\n",
    "\n",
    "df_temp['vwap_30min'] = (df_temp['price'] * df_temp['qty']).rolling(window='30T', min_periods=1).sum() / df_temp['qty'].rolling(window='30T', min_periods=1).sum()\n",
    "\n",
    "# Reset index\n",
    "df = df_temp.reset_index()\n",
    "\n",
    "# Display sample data with VWAP values\n",
    "print(\"=== SAMPLE DATA WITH VWAP VALUES ===\")\n",
    "print(df[['date', 'price', 'qty', 'vwap_1min', 'vwap_5min', 'vwap_15min', 'vwap_30min']].head(15))\n",
    "\n",
    "# VWAP Statistics\n",
    "print(f\"\\n=== VWAP STATISTICS ===\")\n",
    "vwap_cols = ['vwap_1min', 'vwap_5min', 'vwap_15min', 'vwap_30min']\n",
    "\n",
    "for col in vwap_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: ₹{df[col].min():.2f}\")\n",
    "    print(f\"  Max: ₹{df[col].min():.2f}\")\n",
    "    print(f\"  Mean: ₹{df[col].mean():.2f}\")\n",
    "    print(f\"  Std: ₹{df[col].std():.2f}\")\n",
    "\n",
    "# Price vs VWAP Analysis\n",
    "print(f\"\\n=== PRICE VS VWAP ANALYSIS ===\")\n",
    "\n",
    "# Calculate price position relative to each VWAP\n",
    "df['price_vs_vwap_1min'] = df['price'] - df['vwap_1min']\n",
    "df['price_vs_vwap_5min'] = df['price'] - df['vwap_5min']\n",
    "df['price_vs_vwap_15min'] = df['price'] - df['vwap_15min']\n",
    "df['price_vs_vwap_30min'] = df['price'] - df['vwap_30min']\n",
    "\n",
    "# Count how many times price is above/below each VWAP\n",
    "print(\"Price position relative to VWAP:\")\n",
    "for i, vwap_type in enumerate(['1min', '5min', '15min', '30min']):\n",
    "    col = f'price_vs_vwap_{vwap_type}'\n",
    "    above_count = (df[col] > 0).sum()\n",
    "    below_count = (df[col] < 0).sum()\n",
    "    equal_count = (df[col] == 0).sum()\n",
    "    \n",
    "    print(f\"\\n  {vwap_type} VWAP:\")\n",
    "    print(f\"    Above: {above_count:,} times ({(above_count/len(df)*100):.1f}%)\")\n",
    "    print(f\"    Below: {below_count:,} times ({(below_count/len(df)*100):.1f}%)\")\n",
    "    print(f\"    Equal: {equal_count:,} times ({(equal_count/len(df)*100):.1f}%)\")\n",
    "\n",
    "# VWAP as Support/Resistance\n",
    "print(f\"\\n=== VWAP AS SUPPORT/RESISTANCE ===\")\n",
    "\n",
    "# Find periods when price bounces off VWAP\n",
    "for i, vwap_type in enumerate(['1min', '5min', '15min', '30min']):\n",
    "    vwap_col = f'vwap_{vwap_type}'\n",
    "    price_vs_col = f'price_vs_vwap_{vwap_type}'\n",
    "    \n",
    "    # Find when price is very close to VWAP (within 0.1%)\n",
    "    close_to_vwap = (abs(df[price_vs_col]) / df[vwap_col] * 100) < 0.1\n",
    "    close_count = close_to_vwap.sum()\n",
    "    \n",
    "    print(f\"{vwap_type} VWAP: {close_count:,} times price within 0.1% of VWAP\")\n",
    "\n",
    "# VWAP Crossover Analysis\n",
    "print(f\"\\n=== VWAP CROSSOVER ANALYSIS ===\")\n",
    "\n",
    "# Price crossing above/below VWAP\n",
    "for i, vwap_type in enumerate(['1min', '5min', '15min', '30min']):\n",
    "    price_vs_col = f'price_vs_vwap_{vwap_type}'\n",
    "    \n",
    "    # Create crossover signals\n",
    "    df[f'above_vwap_{vwap_type}'] = df[price_vs_col] > 0\n",
    "    df[f'vwap_{vwap_type}_cross'] = df[f'above_vwap_{vwap_type}'].astype(int)\n",
    "    df[f'vwap_{vwap_type}_signal'] = df[f'vwap_{vwap_type}_cross'].diff()\n",
    "    \n",
    "    # Count crossovers\n",
    "    bullish_crosses = (df[f'vwap_{vwap_type}_signal'] == 1).sum()\n",
    "    bearish_crosses = (df[f'vwap_{vwap_type}_signal'] == -1).sum()\n",
    "    \n",
    "    print(f\"{vwap_type} VWAP crossovers:\")\n",
    "    print(f\"  Bullish (price crosses above): {bullish_crosses}\")\n",
    "    print(f\"  Bearish (price crosses below): {bearish_crosses}\")\n",
    "\n",
    "# VWAP Trend Analysis\n",
    "print(f\"\\n=== VWAP TREND ANALYSIS ===\")\n",
    "\n",
    "# Calculate VWAP trends (slopes)\n",
    "df['vwap_1min_trend'] = df['vwap_1min'].diff()\n",
    "df['vwap_5min_trend'] = df['vwap_5min'].diff()\n",
    "df['vwap_15min_trend'] = df['vwap_15min'].diff()\n",
    "df['vwap_30min_trend'] = df['vwap_30min'].diff()\n",
    "\n",
    "# Count trending periods\n",
    "for i, vwap_type in enumerate(['1min', '5min', '15min', '30min']):\n",
    "    trend_col = f'vwap_{vwap_type}_trend'\n",
    "    up_trend = (df[trend_col] > 0).sum()\n",
    "    down_trend = (df[trend_col] < 0).sum()\n",
    "    \n",
    "    print(f\"{vwap_type} VWAP trends:\")\n",
    "    print(f\"  Upward: {up_trend:,} periods\")\n",
    "    print(f\"  Downward: {down_trend:,} periods\")\n",
    "\n",
    "# VWAP vs Simple Moving Average Comparison\n",
    "print(f\"\\n=== VWAP VS SIMPLE MOVING AVERAGE ===\")\n",
    "\n",
    "# Compare VWAP with price averages\n",
    "print(\"VWAP vs Simple Price Average:\")\n",
    "print(f\"  Overall VWAP: ₹{vwap_total:.2f}\")\n",
    "print(f\"  Simple Price Average: ₹{df['price'].mean():.2f}\")\n",
    "print(f\"  Difference: ₹{vwap_total - df['price'].mean():.2f}\")\n",
    "\n",
    "# Show correlation between VWAP and price\n",
    "for col in vwap_cols:\n",
    "    correlation = df[col].corr(df['price'])\n",
    "    print(f\"  {col} vs Price correlation: {correlation:.4f}\")\n",
    "\n",
    "# Trading Signals based on VWAP\n",
    "print(f\"\\n=== VWAP TRADING SIGNALS ===\")\n",
    "\n",
    "# Generate basic trading signals\n",
    "df['vwap_signal'] = 'Hold'\n",
    "df.loc[df['price'] > df['vwap_15min'], 'vwap_signal'] = 'Buy'\n",
    "df.loc[df['price'] < df['vwap_15min'], 'vwap_signal'] = 'Sell'\n",
    "\n",
    "signal_counts = df['vwap_signal'].value_counts()\n",
    "print(\"VWAP-based trading signals (using 15-min VWAP):\")\n",
    "for signal, count in signal_counts.items():\n",
    "    print(f\"  {signal}: {count:,} times ({(count/len(df)*100):.1f}%)\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== VWAP SUMMARY ===\")\n",
    "print(f\"✓ Overall VWAP: ₹{vwap_total:.2f}\")\n",
    "print(f\"✓ Rolling VWAP calculated for 1min, 5min, 15min, 30min windows\")\n",
    "print(f\"✓ Price vs VWAP analysis completed\")\n",
    "print(f\"✓ VWAP crossover signals generated\")\n",
    "print(f\"✓ VWAP trend analysis completed\")\n",
    "print(f\"✓ Trading signals based on VWAP generated\")\n",
    "print(f\"✓ Ready for VWAP-based trading strategies\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"New VWAP columns added:\")\n",
    "vwap_new_cols = ['vwap_1min', 'vwap_5min', 'vwap_15min', 'vwap_30min',\n",
    "                  'price_vs_vwap_1min', 'price_vs_vwap_5min', 'price_vs_vwap_15min', 'price_vs_vwap_30min',\n",
    "                  'above_vwap_1min', 'above_vwap_5min', 'above_vwap_15min', 'above_vwap_30min',\n",
    "                  'vwap_1min_cross', 'vwap_5min_cross', 'vwap_15min_cross', 'vwap_30min_cross',\n",
    "                  'vwap_1min_signal', 'vwap_5min_signal', 'vwap_15min_signal', 'vwap_30min_signal',\n",
    "                  'vwap_1min_trend', 'vwap_5min_trend', 'vwap_15min_trend', 'vwap_30min_trend',\n",
    "                  'vwap_signal']\n",
    "for col in vwap_new_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  ✓ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a5adb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MINUTE-BY-MINUTE TRADE AGGREGATION ===\n",
      "Aggregating trades by minute...\n",
      "Original aggregation columns: [('price', 'mean'), ('price', 'min'), ('price', 'max'), ('price', 'first'), ('price', 'last'), ('qty', 'sum'), ('qty', 'count'), ('trnvr', 'sum')]\n",
      "Column levels: 2\n",
      "=== MINUTE-BY-MINUTE AGGREGATED DATA ===\n",
      "Total minutes with trades: 375\n",
      "Time range: 2025-08-07 09:15:00 to 2025-08-07 15:29:00\n",
      "\n",
      "=== FIRST 15 MINUTES ===\n",
      "             minute  avg_price  min_price  max_price  open_price  close_price  total_qty  trade_count  total_trnvr\n",
      "2025-08-07 09:15:00     386.24     385.70     386.95      386.85       386.00     240694          116  93007031.40\n",
      "2025-08-07 09:16:00     387.07     385.60     387.75      386.00       387.60     176938           94  68447339.50\n",
      "2025-08-07 09:17:00     388.06     387.55     388.55      387.60       388.55     109071           15  42309419.75\n",
      "2025-08-07 09:18:00     389.00     388.45     389.45      388.85       389.00     140751           14  54755417.20\n",
      "2025-08-07 09:19:00     389.09     388.80     389.25      388.95       389.10      84336           96  32813758.65\n",
      "2025-08-07 09:20:00     389.14     388.90     389.85      389.05       389.85     181112           13  70514549.40\n",
      "2025-08-07 09:21:00     389.57     389.35     390.05      389.65       390.05     118951           94  46347599.65\n",
      "2025-08-07 09:22:00     389.89     389.50     390.20      390.00       389.60      61831          105  24107901.00\n",
      "2025-08-07 09:23:00     389.56     389.10     389.85      389.80       389.15      47476           14  18486095.00\n",
      "2025-08-07 09:24:00     388.79     388.60     389.00      389.00       388.65      36466           15  14179668.45\n",
      "2025-08-07 09:25:00     388.73     388.55     388.95      388.95       388.55      48755           14  18956429.90\n",
      "2025-08-07 09:26:00     388.82     388.55     389.10      388.55       389.10      61235           12  23813078.30\n",
      "2025-08-07 09:27:00     388.89     388.75     389.10      389.10       388.75      28115           12  10933185.80\n",
      "2025-08-07 09:28:00     388.73     388.60     388.85      388.75       388.75      35201           14  13684971.50\n",
      "2025-08-07 09:29:00     388.67     388.35     389.00      389.00       388.65      50899           13  19778802.05\n",
      "\n",
      "=== LAST 15 MINUTES ===\n",
      "             minute  avg_price  min_price  max_price  open_price  close_price  total_qty  trade_count  total_trnvr\n",
      "2025-08-07 15:15:00     387.65     387.60     387.70      387.65       387.65      37128           14  14392381.10\n",
      "2025-08-07 15:16:00     387.59     387.40     387.70      387.65       387.55      62291           14  24142605.80\n",
      "2025-08-07 15:17:00     387.84     387.60     388.05      387.65       387.95      97099           94  37662171.75\n",
      "2025-08-07 15:18:00     387.98     387.85     388.15      388.00       387.95      53970           93  20939667.55\n",
      "2025-08-07 15:19:00     387.86     387.75     387.95      387.95       387.80      39053           62  15146003.50\n",
      "2025-08-07 15:20:00     387.93     387.75     388.10      387.80       388.10      79031           12  30656893.05\n",
      "2025-08-07 15:21:00     388.16     388.00     388.45      388.10       388.40      74877           92  29068703.85\n",
      "2025-08-07 15:22:00     388.59     388.30     388.75      388.45       388.50      48699           90  18924501.55\n",
      "2025-08-07 15:23:00     388.51     388.40     388.60      388.40       388.55      31765           98  12340817.95\n",
      "2025-08-07 15:24:00     388.47     388.30     388.55      388.50       388.45      39660           91  15407011.65\n",
      "2025-08-07 15:25:00     388.40     388.25     388.50      388.40       388.50      44664           92  17349093.45\n",
      "2025-08-07 15:26:00     388.50     388.35     388.65      388.45       388.45      44340           96  17225461.25\n",
      "2025-08-07 15:27:00     388.38     388.20     388.55      388.55       388.25      48761           89  18936710.55\n",
      "2025-08-07 15:28:00     388.28     388.25     388.30      388.30       388.30      74245           17  28827043.95\n",
      "2025-08-07 15:29:00     388.19     387.90     388.30      388.25       388.25      47555           17  18457526.00\n",
      "\n",
      "=== AGGREGATED DATA STATISTICS ===\n",
      "Price Statistics:\n",
      "  Average price range: ₹383.55 - ₹389.89\n",
      "  Overall average price: ₹386.58\n",
      "  Price volatility (std): ₹1.61\n",
      "\n",
      "Volume Statistics:\n",
      "  Total volume across all minutes: 11,510,171\n",
      "  Average volume per minute: 30,694\n",
      "  Highest volume minute: 240,694\n",
      "  Lowest volume minute: 3,927\n",
      "\n",
      "Turnover Statistics:\n",
      "  Total turnover across all minutes: ₹4,451,969,111.70\n",
      "  Average turnover per minute: ₹11,871,917.63\n",
      "  Highest turnover minute: ₹93,007,031.40\n",
      "  Lowest turnover minute: ₹1,521,495.85\n",
      "\n",
      "Trade Count Statistics:\n",
      "  Total trades across all minutes: 10,956\n",
      "  Average trades per minute: 29.2\n",
      "  Busiest minute: 116 trades\n",
      "  Quietest minute: 9 trades\n",
      "\n",
      "=== MINUTE-BY-MINUTE ANALYSIS ===\n",
      "Highest volume minute:\n",
      "  Time: 2025-08-07 09:15:00\n",
      "  Volume: 240,694\n",
      "  Turnover: ₹93,007,031.40\n",
      "  Avg Price: ₹386.24\n",
      "  Trades: 116\n",
      "\n",
      "Lowest volume minute:\n",
      "  Time: 2025-08-07 11:21:00\n",
      "  Volume: 3,927\n",
      "  Turnover: ₹1,521,495.85\n",
      "  Avg Price: ₹387.43\n",
      "  Trades: 15\n",
      "\n",
      "Highest turnover minute:\n",
      "  Time: 2025-08-07 09:15:00\n",
      "  Turnover: ₹93,007,031.40\n",
      "  Volume: 240,694\n",
      "  Avg Price: ₹386.24\n",
      "\n",
      "=== TIME-BASED PATTERNS ===\n",
      "Total volume by hour:\n",
      "  09:00 - 09:59: 2,164,111\n",
      "  10:00 - 10:59: 1,436,774\n",
      "  11:00 - 11:59: 1,340,606\n",
      "  12:00 - 12:59: 1,462,840\n",
      "  13:00 - 13:59: 1,428,015\n",
      "  14:00 - 14:59: 1,985,212\n",
      "  15:00 - 15:59: 1,692,613\n",
      "\n",
      "Total turnover by hour:\n",
      "  09:00 - 09:59: ₹840,800,983.15\n",
      "  10:00 - 10:59: ₹557,748,903.30\n",
      "  11:00 - 11:59: ₹518,188,746.40\n",
      "  12:00 - 12:59: ₹563,482,164.95\n",
      "  13:00 - 13:59: ₹548,979,275.10\n",
      "  14:00 - 14:59: ₹766,416,677.25\n",
      "  15:00 - 15:59: ₹656,352,361.55\n",
      "\n",
      "=== PRICE MOVEMENT ANALYSIS PER MINUTE ===\n",
      "Minute-to-minute price changes:\n",
      "  Average change: ₹-0.00\n",
      "  Average change %: -0.00%\n",
      "  Largest increase: ₹1.60\n",
      "  Largest decrease: ₹-0.85\n",
      "\n",
      "=== VOLUME-WEIGHTED ANALYSIS ===\n",
      "VWAP vs Average Price analysis:\n",
      "  Average difference: ₹0.00\n",
      "  Max difference: ₹0.31\n",
      "  Min difference: ₹-0.24\n",
      "\n",
      "=== TRADING INTENSITY ANALYSIS ===\n",
      "Volume per trade analysis:\n",
      "  Average volume per trade: 1,385\n",
      "  Highest volume per trade: 13,932\n",
      "  Lowest volume per trade: 104\n",
      "\n",
      "================================================================================\n",
      "=== SUMMARY TABLE ===\n",
      "          Metric             Value\n",
      "   Total Minutes               375\n",
      "    Total Volume        11,510,171\n",
      "  Total Turnover ₹4,451,969,111.70\n",
      "    Total Trades            10,956\n",
      "       Avg Price           ₹386.58\n",
      "  Avg Volume/Min            30,694\n",
      "Avg Turnover/Min    ₹11,871,917.63\n",
      "\n",
      "=== DATA EXPORT ===\n",
      "✓ Minute-by-minute aggregation completed\n",
      "✓ 375 minutes of aggregated data\n",
      "✓ Ready for time-series analysis and visualization\n",
      "✓ Data can be exported to CSV for further analysis\n",
      "\n",
      "=== AGGREGATED DATAFRAME INFO ===\n",
      "Columns: ['minute', 'avg_price', 'min_price', 'max_price', 'open_price', 'close_price', 'total_qty', 'trade_count', 'total_trnvr', 'hour', 'price_change', 'price_change_pct', 'minute_vwap', 'vwap_vs_avg_diff', 'volume_per_trade']\n",
      "Shape: (375, 15)\n",
      "Data types:\n",
      "minute              datetime64[ns]\n",
      "avg_price                  float64\n",
      "min_price                  float64\n",
      "max_price                  float64\n",
      "open_price                 float64\n",
      "close_price                float64\n",
      "total_qty                    int64\n",
      "trade_count                  int64\n",
      "total_trnvr                float64\n",
      "hour                         int32\n",
      "price_change               float64\n",
      "price_change_pct           float64\n",
      "minute_vwap                float64\n",
      "vwap_vs_avg_diff           float64\n",
      "volume_per_trade           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Aggregate trades per minute: avg price, total qty, total trnvr\n",
    "print(\"=== MINUTE-BY-MINUTE TRADE AGGREGATION ===\")\n",
    "\n",
    "# Create minute-level aggregation\n",
    "print(\"Aggregating trades by minute...\")\n",
    "\n",
    "# Extract minute from datetime for grouping (using 'min' instead of 'T')\n",
    "df['minute_key'] = df['date'].dt.floor('1min')  # Floor to nearest minute\n",
    "\n",
    "# Group by minute and aggregate\n",
    "minute_agg = df.groupby('minute_key').agg({\n",
    "    'price': ['mean', 'min', 'max', 'first', 'last'],  # Price statistics\n",
    "    'qty': ['sum', 'count'],                           # Total quantity and trade count\n",
    "    'trnvr': 'sum'                                     # Total turnover\n",
    "}).round(2)\n",
    "\n",
    "# Check the actual column structure before flattening\n",
    "print(f\"Original aggregation columns: {minute_agg.columns.tolist()}\")\n",
    "print(f\"Column levels: {minute_agg.columns.nlevels}\")\n",
    "\n",
    "# Flatten column names correctly\n",
    "minute_agg.columns = ['avg_price', 'min_price', 'max_price', 'open_price', 'close_price', \n",
    "                      'total_qty', 'trade_count', 'total_trnvr']\n",
    "\n",
    "# Reset index to make minute_key a column\n",
    "minute_agg = minute_agg.reset_index()\n",
    "minute_agg.rename(columns={'minute_key': 'minute'}, inplace=True)\n",
    "\n",
    "# Display the aggregated data\n",
    "print(\"=== MINUTE-BY-MINUTE AGGREGATED DATA ===\")\n",
    "print(f\"Total minutes with trades: {len(minute_agg)}\")\n",
    "print(f\"Time range: {minute_agg['minute'].min()} to {minute_agg['minute'].max()}\")\n",
    "\n",
    "# Show first 15 rows\n",
    "print(f\"\\n=== FIRST 15 MINUTES ===\")\n",
    "print(minute_agg.head(15).to_string(index=False))\n",
    "\n",
    "# Show last 15 rows\n",
    "print(f\"\\n=== LAST 15 MINUTES ===\")\n",
    "print(minute_agg.tail(15).to_string(index=False))\n",
    "\n",
    "# Basic statistics of aggregated data\n",
    "print(f\"\\n=== AGGREGATED DATA STATISTICS ===\")\n",
    "print(\"Price Statistics:\")\n",
    "print(f\"  Average price range: ₹{minute_agg['avg_price'].min():.2f} - ₹{minute_agg['avg_price'].max():.2f}\")\n",
    "print(f\"  Overall average price: ₹{minute_agg['avg_price'].mean():.2f}\")\n",
    "print(f\"  Price volatility (std): ₹{minute_agg['avg_price'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nVolume Statistics:\")\n",
    "print(f\"  Total volume across all minutes: {minute_agg['total_qty'].sum():,}\")\n",
    "print(f\"  Average volume per minute: {minute_agg['total_qty'].mean():,.0f}\")\n",
    "print(f\"  Highest volume minute: {minute_agg['total_qty'].max():,}\")\n",
    "print(f\"  Lowest volume minute: {minute_agg['total_qty'].min():,}\")\n",
    "\n",
    "print(f\"\\nTurnover Statistics:\")\n",
    "print(f\"  Total turnover across all minutes: ₹{minute_agg['total_trnvr'].sum():,.2f}\")\n",
    "print(f\"  Average turnover per minute: ₹{minute_agg['total_trnvr'].mean():,.2f}\")\n",
    "print(f\"  Highest turnover minute: ₹{minute_agg['total_trnvr'].max():,.2f}\")\n",
    "print(f\"  Lowest turnover minute: ₹{minute_agg['total_trnvr'].min():,.2f}\")\n",
    "\n",
    "print(f\"\\nTrade Count Statistics:\")\n",
    "print(f\"  Total trades across all minutes: {minute_agg['trade_count'].sum():,}\")\n",
    "print(f\"  Average trades per minute: {minute_agg['trade_count'].mean():.1f}\")\n",
    "print(f\"  Busiest minute: {minute_agg['trade_count'].max():,} trades\")\n",
    "print(f\"  Quietest minute: {minute_agg['trade_count'].min():,} trades\")\n",
    "\n",
    "# Minute-by-minute analysis\n",
    "print(f\"\\n=== MINUTE-BY-MINUTE ANALYSIS ===\")\n",
    "\n",
    "# Find highest and lowest volume minutes\n",
    "highest_volume_minute = minute_agg.loc[minute_agg['total_qty'].idxmax()]\n",
    "lowest_volume_minute = minute_agg.loc[minute_agg['total_qty'].idxmin()]\n",
    "\n",
    "print(\"Highest volume minute:\")\n",
    "print(f\"  Time: {highest_volume_minute['minute']}\")\n",
    "print(f\"  Volume: {highest_volume_minute['total_qty']:,}\")\n",
    "print(f\"  Turnover: ₹{highest_volume_minute['total_trnvr']:,.2f}\")\n",
    "print(f\"  Avg Price: ₹{highest_volume_minute['avg_price']:.2f}\")\n",
    "print(f\"  Trades: {highest_volume_minute['trade_count']}\")\n",
    "\n",
    "print(f\"\\nLowest volume minute:\")\n",
    "print(f\"  Time: {lowest_volume_minute['minute']}\")\n",
    "print(f\"  Volume: {lowest_volume_minute['total_qty']:,}\")\n",
    "print(f\"  Turnover: ₹{lowest_volume_minute['total_trnvr']:,.2f}\")\n",
    "print(f\"  Avg Price: ₹{lowest_volume_minute['avg_price']:.2f}\")\n",
    "print(f\"  Trades: {lowest_volume_minute['trade_count']}\")\n",
    "\n",
    "# Find highest and lowest turnover minutes\n",
    "highest_turnover_minute = minute_agg.loc[minute_agg['total_trnvr'].idxmax()]\n",
    "lowest_turnover_minute = minute_agg.loc[minute_agg['total_trnvr'].idxmin()]\n",
    "\n",
    "print(f\"\\nHighest turnover minute:\")\n",
    "print(f\"  Time: {highest_turnover_minute['minute']}\")\n",
    "print(f\"  Turnover: ₹{highest_turnover_minute['total_trnvr']:,.2f}\")\n",
    "print(f\"  Volume: {highest_turnover_minute['total_qty']:,}\")\n",
    "print(f\"  Avg Price: ₹{highest_turnover_minute['avg_price']:.2f}\")\n",
    "\n",
    "# Time-based patterns\n",
    "print(f\"\\n=== TIME-BASED PATTERNS ===\")\n",
    "\n",
    "# Add hour column for hourly analysis\n",
    "minute_agg['hour'] = minute_agg['minute'].dt.hour\n",
    "\n",
    "# Hourly volume analysis\n",
    "hourly_volume = minute_agg.groupby('hour')['total_qty'].sum()\n",
    "print(\"Total volume by hour:\")\n",
    "for hour, volume in hourly_volume.items():\n",
    "    print(f\"  {hour:02d}:00 - {hour:02d}:59: {volume:,}\")\n",
    "\n",
    "# Hourly turnover analysis\n",
    "hourly_turnover = minute_agg.groupby('hour')['total_trnvr'].sum()\n",
    "print(f\"\\nTotal turnover by hour:\")\n",
    "for hour, turnover in hourly_turnover.items():\n",
    "    print(f\"  {hour:02d}:00 - {hour:02d}:59: ₹{turnover:,.2f}\")\n",
    "\n",
    "# Price movement analysis per minute\n",
    "print(f\"\\n=== PRICE MOVEMENT ANALYSIS PER MINUTE ===\")\n",
    "\n",
    "# Calculate minute-to-minute price changes\n",
    "minute_agg['price_change'] = minute_agg['close_price'] - minute_agg['open_price']\n",
    "minute_agg['price_change_pct'] = (minute_agg['price_change'] / minute_agg['open_price']) * 100\n",
    "\n",
    "# Price change statistics\n",
    "print(f\"Minute-to-minute price changes:\")\n",
    "print(f\"  Average change: ₹{minute_agg['price_change'].mean():.2f}\")\n",
    "print(f\"  Average change %: {minute_agg['price_change_pct'].mean():.2f}%\")\n",
    "print(f\"  Largest increase: ₹{minute_agg['price_change'].max():.2f}\")\n",
    "print(f\"  Largest decrease: ₹{minute_agg['price_change'].min():.2f}\")\n",
    "\n",
    "# Volume-weighted price analysis\n",
    "print(f\"\\n=== VOLUME-WEIGHTED ANALYSIS ===\")\n",
    "\n",
    "# Calculate VWAP for each minute\n",
    "minute_agg['minute_vwap'] = minute_agg['total_trnvr'] / minute_agg['total_qty']\n",
    "\n",
    "# Compare VWAP with average price\n",
    "minute_agg['vwap_vs_avg_diff'] = minute_agg['minute_vwap'] - minute_agg['avg_price']\n",
    "print(f\"VWAP vs Average Price analysis:\")\n",
    "print(f\"  Average difference: ₹{minute_agg['vwap_vs_avg_diff'].mean():.2f}\")\n",
    "print(f\"  Max difference: ₹{minute_agg['vwap_vs_avg_diff'].max():.2f}\")\n",
    "print(f\"  Min difference: ₹{minute_agg['vwap_vs_avg_diff'].min():.2f}\")\n",
    "\n",
    "# Trading intensity analysis\n",
    "print(f\"\\n=== TRADING INTENSITY ANALYSIS ===\")\n",
    "\n",
    "# Calculate volume per trade for each minute\n",
    "minute_agg['volume_per_trade'] = minute_agg['total_qty'] / minute_agg['trade_count']\n",
    "\n",
    "print(f\"Volume per trade analysis:\")\n",
    "print(f\"  Average volume per trade: {minute_agg['volume_per_trade'].mean():,.0f}\")\n",
    "print(f\"  Highest volume per trade: {minute_agg['volume_per_trade'].max():,.0f}\")\n",
    "print(f\"  Lowest volume per trade: {minute_agg['volume_per_trade'].min():,.0f}\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"=== SUMMARY TABLE ===\")\n",
    "summary_data = {\n",
    "    'Metric': ['Total Minutes', 'Total Volume', 'Total Turnover', 'Total Trades', 'Avg Price', 'Avg Volume/Min', 'Avg Turnover/Min'],\n",
    "    'Value': [\n",
    "        f\"{len(minute_agg):,}\",\n",
    "        f\"{minute_agg['total_qty'].sum():,}\",\n",
    "        f\"₹{minute_agg['total_trnvr'].sum():,.2f}\",\n",
    "        f\"{minute_agg['trade_count'].sum():,}\",\n",
    "        f\"₹{minute_agg['avg_price'].mean():.2f}\",\n",
    "        f\"{minute_agg['total_qty'].mean():,.0f}\",\n",
    "        f\"₹{minute_agg['total_trnvr'].mean():,.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save aggregated data\n",
    "print(f\"\\n=== DATA EXPORT ===\")\n",
    "print(f\"✓ Minute-by-minute aggregation completed\")\n",
    "print(f\"✓ {len(minute_agg)} minutes of aggregated data\")\n",
    "print(f\"✓ Ready for time-series analysis and visualization\")\n",
    "print(f\"✓ Data can be exported to CSV for further analysis\")\n",
    "\n",
    "# Display final aggregated dataframe info\n",
    "print(f\"\\n=== AGGREGATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(minute_agg.columns)}\")\n",
    "print(f\"Shape: {minute_agg.shape}\")\n",
    "print(f\"Data types:\")\n",
    "print(minute_agg.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70e3d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HOURLY AGGREGATION ANALYSIS ===\n",
      "Aggregating data by hour...\n",
      "\n",
      "=== HOURLY AGGREGATION RESULTS ===\n",
      "Shape: (7, 14)\n",
      "   hour  avg_price  min_price  max_price  price_std  open_price  close_price  \\\n",
      "0     9     388.60     385.60     390.20       1.13      386.85       388.30   \n",
      "1    10     388.23     387.45     389.25       0.39      388.10       388.10   \n",
      "2    11     386.51     385.25     388.05       0.65      388.00       385.55   \n",
      "3    12     385.22     384.40     386.50       0.44      385.70       385.40   \n",
      "4    13     384.43     383.50     385.60       0.49      385.55       384.75   \n",
      "5    14     385.97     384.70     387.10       0.63      384.70       387.05   \n",
      "6    15     387.92     387.00     388.75       0.46      387.35       388.25   \n",
      "\n",
      "   total_qty  trade_count   total_trnvr  avg_price_change  price_change_std  \\\n",
      "0    2164111         1047  8.408010e+08               0.0              0.12   \n",
      "1    1436774         1476  5.577489e+08              -0.0              0.09   \n",
      "2    1340606         1653  5.181887e+08              -0.0              0.09   \n",
      "3    1462840         1807  5.634822e+08              -0.0              0.08   \n",
      "4    1428015         1679  5.489793e+08              -0.0              0.07   \n",
      "5    1985212         1521  7.664167e+08               0.0              0.08   \n",
      "6    1692613         1773  6.563524e+08               0.0              0.06   \n",
      "\n",
      "   min_price_change  max_price_change  \n",
      "0             -0.65              0.75  \n",
      "1             -0.35              0.45  \n",
      "2             -0.35              0.35  \n",
      "3             -0.30              0.30  \n",
      "4             -0.45              0.40  \n",
      "5             -0.45              0.50  \n",
      "6             -0.40              0.30  \n",
      "\n",
      "=== VOLUME ANALYSIS BY HOUR ===\n",
      "Highest volume hour:\n",
      "  Hour: 09:00 - 09:59\n",
      "  Volume: 2,164,111.0\n",
      "  Turnover: ₹840,800,983.15\n",
      "  Average price: ₹388.60\n",
      "\n",
      "Lowest volume hour:\n",
      "  Hour: 11:00 - 11:59\n",
      "  Volume: 1,340,606.0\n",
      "  Turnover: ₹518,188,746.40\n",
      "  Average price: ₹386.51\n",
      "\n",
      "=== VOLATILITY ANALYSIS BY HOUR ===\n",
      "Highest volatility hour: 09:00\n",
      "  Price standard deviation: ₹1.13\n",
      "  Price range: ₹385.60 - ₹390.20\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total trading hours: 7\n",
      "Average hourly volume: 1,644,310\n",
      "Average hourly turnover: ₹635,995,587.39\n",
      "Average hourly price volatility: ₹0.60\n"
     ]
    }
   ],
   "source": [
    "# Aggregate per hour: price volatility, volume, turnover\n",
    "print(\"=== HOURLY AGGREGATION ANALYSIS ===\")\n",
    "\n",
    "# Create hourly aggregation\n",
    "print(\"Aggregating data by hour...\")\n",
    "\n",
    "# Extract hour from datetime for grouping\n",
    "df['hour_key'] = df['date'].dt.hour\n",
    "\n",
    "# Group by hour and aggregate\n",
    "hourly_agg = df.groupby('hour_key').agg({\n",
    "    'price': ['mean', 'min', 'max', 'std', 'first', 'last'],  # Price statistics including volatility\n",
    "    'qty': ['sum', 'count'],                                   # Total volume and trade count\n",
    "    'trnvr': 'sum',                                            # Total turnover\n",
    "    'price_change': ['mean', 'std', 'min', 'max']              # Price change statistics\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "hourly_agg.columns = [\n",
    "    'avg_price', 'min_price', 'max_price', 'price_std', 'open_price', 'close_price',\n",
    "    'total_qty', 'trade_count', 'total_trnvr',\n",
    "    'avg_price_change', 'price_change_std', 'min_price_change', 'max_price_change'\n",
    "]\n",
    "\n",
    "# Reset index to make hour_key a column\n",
    "hourly_agg = hourly_agg.reset_index()\n",
    "hourly_agg.rename(columns={'hour_key': 'hour'}, inplace=True)\n",
    "\n",
    "# Display the hourly aggregation\n",
    "print(f\"\\n=== HOURLY AGGREGATION RESULTS ===\")\n",
    "print(f\"Shape: {hourly_agg.shape}\")\n",
    "print(hourly_agg)\n",
    "\n",
    "# Find highest and lowest volume hours\n",
    "print(f\"\\n=== VOLUME ANALYSIS BY HOUR ===\")\n",
    "highest_volume_hour = hourly_agg.loc[hourly_agg['total_qty'].idxmax()]\n",
    "lowest_volume_hour = hourly_agg.loc[hourly_agg['total_qty'].idxmin()]\n",
    "\n",
    "print(\"Highest volume hour:\")\n",
    "print(f\"  Hour: {int(highest_volume_hour['hour']):02d}:00 - {int(highest_volume_hour['hour']):02d}:59\")\n",
    "print(f\"  Volume: {highest_volume_hour['total_qty']:,}\")\n",
    "print(f\"  Turnover: ₹{highest_volume_hour['total_trnvr']:,.2f}\")\n",
    "print(f\"  Average price: ₹{highest_volume_hour['avg_price']:.2f}\")\n",
    "\n",
    "print(\"\\nLowest volume hour:\")\n",
    "print(f\"  Hour: {int(lowest_volume_hour['hour']):02d}:00 - {int(lowest_volume_hour['hour']):02d}:59\")\n",
    "print(f\"  Volume: {lowest_volume_hour['total_qty']:,}\")\n",
    "print(f\"  Turnover: ₹{lowest_volume_hour['total_trnvr']:,.2f}\")\n",
    "print(f\"  Average price: ₹{lowest_volume_hour['avg_price']:.2f}\")\n",
    "\n",
    "# Volatility analysis by hour\n",
    "print(f\"\\n=== VOLATILITY ANALYSIS BY HOUR ===\")\n",
    "highest_volatility_hour = hourly_agg.loc[hourly_agg['price_std'].idxmax()]\n",
    "print(f\"Highest volatility hour: {int(highest_volatility_hour['hour']):02d}:00\")\n",
    "print(f\"  Price standard deviation: ₹{highest_volatility_hour['price_std']:.2f}\")\n",
    "print(f\"  Price range: ₹{highest_volatility_hour['min_price']:.2f} - ₹{highest_volatility_hour['max_price']:.2f}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Total trading hours: {len(hourly_agg)}\")\n",
    "print(f\"Average hourly volume: {hourly_agg['total_qty'].mean():,.0f}\")\n",
    "print(f\"Average hourly turnover: ₹{hourly_agg['total_trnvr'].mean():,.2f}\")\n",
    "print(f\"Average hourly price volatility: ₹{hourly_agg['price_std'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15b204f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADING SESSION OHLC ANALYSIS ===\n",
      "Aggregating data by trading session...\n",
      "=== SINGLE TRADING SESSION OHLC ===\n",
      "Date: 2025-08-07\n",
      "Open: ₹386.85\n",
      "High: ₹390.20\n",
      "Low: ₹383.50\n",
      "Close: ₹388.25\n",
      "Price Range: ₹6.70\n",
      "Total Volume: 11,510,171\n",
      "Total Turnover: ₹4,451,969,111.70\n",
      "Trade Count: 10,956\n",
      "Average Price: ₹386.56\n",
      "\n",
      "=== ADDITIONAL METRICS ===\n",
      "Price Change: ₹1.40\n",
      "Price Change %: 0.36%\n",
      "Session VWAP: ₹386.79\n",
      "\n",
      "=== COMPLETE SESSION DATA ===\n",
      "         date    open   high    low   close  total_volume  total_turnover  \\\n",
      "0  2025-08-07  386.85  390.2  383.5  388.25      11510171    4.451969e+09   \n",
      "\n",
      "   trade_count  price_range   avg_price  price_change  price_change_pct  \n",
      "0        10956          6.7  386.561094           1.4          0.361897  \n"
     ]
    }
   ],
   "source": [
    "# Aggregate per trading session: OHLC + total volume\n",
    "print(\"=== TRADING SESSION OHLC ANALYSIS ===\")\n",
    "\n",
    "# Create trading session aggregation (assuming single day data)\n",
    "print(\"Aggregating data by trading session...\")\n",
    "\n",
    "# For single day data, we can create session-level OHLC\n",
    "# If you have multiple days, you can group by date_only instead\n",
    "if len(df['date_only'].unique()) == 1:\n",
    "    # Single trading day - create session OHLC\n",
    "    session_ohlc = {\n",
    "        'date': df['date_only'].iloc[0],\n",
    "        'open': df['price'].iloc[0],           # First price of the day\n",
    "        'high': df['price'].max(),             # Highest price of the day\n",
    "        'low': df['price'].min(),              # Lowest price of the day\n",
    "        'close': df['price'].iloc[-1],         # Last price of the day\n",
    "        'total_volume': df['qty'].sum(),       # Total volume for the day\n",
    "        'total_turnover': df['trnvr'].sum(),   # Total turnover for the day\n",
    "        'trade_count': len(df),                # Total number of trades\n",
    "        'price_range': df['price'].max() - df['price'].min(),  # High - Low\n",
    "        'avg_price': df['price'].mean()        # Average price for the day\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame from the session data\n",
    "    session_df = pd.DataFrame([session_ohlc])\n",
    "    \n",
    "    print(f\"=== SINGLE TRADING SESSION OHLC ===\")\n",
    "    print(f\"Date: {session_df['date'].iloc[0]}\")\n",
    "    print(f\"Open: ₹{session_df['open'].iloc[0]:.2f}\")\n",
    "    print(f\"High: ₹{session_df['high'].iloc[0]:.2f}\")\n",
    "    print(f\"Low: ₹{session_df['low'].iloc[0]:.2f}\")\n",
    "    print(f\"Close: ₹{session_df['close'].iloc[0]:.2f}\")\n",
    "    print(f\"Price Range: ₹{session_df['price_range'].iloc[0]:.2f}\")\n",
    "    print(f\"Total Volume: {session_df['total_volume'].iloc[0]:,}\")\n",
    "    print(f\"Total Turnover: ₹{session_df['total_turnover'].iloc[0]:,.2f}\")\n",
    "    print(f\"Trade Count: {session_df['trade_count'].iloc[0]:,}\")\n",
    "    print(f\"Average Price: ₹{session_df['avg_price'].iloc[0]:.2f}\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    print(f\"\\n=== ADDITIONAL METRICS ===\")\n",
    "    session_df['price_change'] = session_df['close'] - session_df['open']\n",
    "    session_df['price_change_pct'] = (session_df['price_change'] / session_df['open']) * 100\n",
    "    \n",
    "    print(f\"Price Change: ₹{session_df['price_change'].iloc[0]:.2f}\")\n",
    "    print(f\"Price Change %: {session_df['price_change_pct'].iloc[0]:.2f}%\")\n",
    "    \n",
    "    # VWAP calculation for the session\n",
    "    vwap = (df['price'] * df['qty']).sum() / df['qty'].sum()\n",
    "    print(f\"Session VWAP: ₹{vwap:.2f}\")\n",
    "    \n",
    "    # Display the complete session DataFrame\n",
    "    print(f\"\\n=== COMPLETE SESSION DATA ===\")\n",
    "    print(session_df)\n",
    "    \n",
    "else:\n",
    "    # Multiple trading days - group by date\n",
    "    print(\"Multiple trading days detected, grouping by date...\")\n",
    "    \n",
    "    # Group by date and create OHLC for each day\n",
    "    daily_ohlc = df.groupby('date_only').agg({\n",
    "        'price': ['first', 'max', 'min', 'last'],  # OHLC\n",
    "        'qty': 'sum',                               # Total volume\n",
    "        'trnvr': 'sum',                             # Total turnover\n",
    "        'qty': 'count'                              # Trade count\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    daily_ohlc.columns = ['open', 'high', 'low', 'close', 'total_volume', 'total_turnover', 'trade_count']\n",
    "    \n",
    "    # Reset index\n",
    "    daily_ohlc = daily_ohlc.reset_index()\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    daily_ohlc['price_range'] = daily_ohlc['high'] - daily_ohlc['low']\n",
    "    daily_ohlc['price_change'] = daily_ohlc['close'] - daily_ohlc['open']\n",
    "    daily_ohlc['price_change_pct'] = (daily_ohlc['price_change'] / daily_ohlc['open']) * 100\n",
    "    \n",
    "    print(f\"\\n=== MULTI-DAY OHLC DATA ===\")\n",
    "    print(daily_ohlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "465a5193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADE ACTIVITY DENSITY ANALYSIS ===\n",
      "Analyzing trade activity density across different time intervals...\n",
      "\n",
      "=== MINUTE-BY-MINUTE TRADE COUNT ===\n",
      "Total minutes with trades: 375\n",
      "Average trades per minute: 29.2\n",
      "Max trades in a minute: 116\n",
      "Min trades in a minute: 9\n",
      "\n",
      "=== TOP 10 MOST ACTIVE MINUTES ===\n",
      "09:15:00: 116 trades\n",
      "15:09:00: 108 trades\n",
      "09:22:00: 105 trades\n",
      "15:23:00: 98 trades\n",
      "09:19:00: 96 trades\n",
      "15:26:00: 96 trades\n",
      "09:16:00: 94 trades\n",
      "09:21:00: 94 trades\n",
      "15:17:00: 94 trades\n",
      "12:49:00: 93 trades\n",
      "\n",
      "=== 5-MINUTE INTERVAL TRADE COUNT ===\n",
      "Total 5-minute intervals: 75\n",
      "Average trades per 5-min: 146.1\n",
      "Max trades in 5-min: 383\n",
      "\n",
      "=== 15-MINUTE INTERVAL TRADE COUNT ===\n",
      "Total 15-minute intervals: 25\n",
      "Average trades per 15-min: 438.2\n",
      "Max trades in 15-min: 971\n",
      "\n",
      "=== HOURLY TRADE COUNT ===\n",
      "Total trading hours: 7\n",
      "Average trades per hour: 1565.1\n",
      "Max trades in an hour: 1807\n",
      "\n",
      "=== HOURLY BREAKDOWN ===\n",
      "09:00-09:59: 1,047 trades\n",
      "10:00-10:59: 1,476 trades\n",
      "11:00-11:59: 1,653 trades\n",
      "12:00-12:59: 1,807 trades\n",
      "13:00-13:59: 1,679 trades\n",
      "14:00-14:59: 1,521 trades\n",
      "15:00-15:59: 1,773 trades\n",
      "\n",
      "=== ACTIVITY DENSITY ANALYSIS ===\n",
      "Peak activity minute: 09:15:00 (116 trades)\n",
      "Peak activity 5-min: 15:20:00 (383 trades)\n",
      "Peak activity 15-min: 15:15:00 (971 trades)\n",
      "Peak activity hour: 12:00-12:59 (1,807 trades)\n",
      "\n",
      "=== QUIET PERIODS ANALYSIS ===\n",
      "Minutes with minimum activity (9 trades):\n",
      "  09:33:00\n",
      "  09:35:00\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total trades: 10,956\n",
      "Total active minutes: 375\n",
      "Total trading hours: 7\n",
      "Average trades per minute: 29.2\n",
      "Average trades per hour: 1565.1\n",
      "\n",
      "=== SAMPLE MINUTE-BY-MINUTE DATA (First 10 rows) ===\n",
      "           minute_key  trade_count      time\n",
      "0 2025-08-07 09:15:00          116  09:15:00\n",
      "1 2025-08-07 09:16:00           94  09:16:00\n",
      "2 2025-08-07 09:17:00           15  09:17:00\n",
      "3 2025-08-07 09:18:00           14  09:18:00\n",
      "4 2025-08-07 09:19:00           96  09:19:00\n",
      "5 2025-08-07 09:20:00           13  09:20:00\n",
      "6 2025-08-07 09:21:00           94  09:21:00\n",
      "7 2025-08-07 09:22:00          105  09:22:00\n",
      "8 2025-08-07 09:23:00           14  09:23:00\n",
      "9 2025-08-07 09:24:00           15  09:24:00\n"
     ]
    }
   ],
   "source": [
    "# Count trades per time interval (activity density)\n",
    "print(\"=== TRADE ACTIVITY DENSITY ANALYSIS ===\")\n",
    "\n",
    "# Create different time intervals for analysis\n",
    "print(\"Analyzing trade activity density across different time intervals...\")\n",
    "\n",
    "# 1. Minute-by-minute trade count\n",
    "print(\"\\n=== MINUTE-BY-MINUTE TRADE COUNT ===\")\n",
    "df['minute_key'] = df['date'].dt.floor('1min')\n",
    "minute_trades = df.groupby('minute_key').size().reset_index(name='trade_count')\n",
    "minute_trades['time'] = minute_trades['minute_key'].dt.time\n",
    "\n",
    "print(f\"Total minutes with trades: {len(minute_trades)}\")\n",
    "print(f\"Average trades per minute: {minute_trades['trade_count'].mean():.1f}\")\n",
    "print(f\"Max trades in a minute: {minute_trades['trade_count'].max()}\")\n",
    "print(f\"Min trades in a minute: {minute_trades['trade_count'].min()}\")\n",
    "\n",
    "# Display top 10 most active minutes\n",
    "print(f\"\\n=== TOP 10 MOST ACTIVE MINUTES ===\")\n",
    "top_active_minutes = minute_trades.nlargest(10, 'trade_count')\n",
    "for idx, row in top_active_minutes.iterrows():\n",
    "    print(f\"{row['time']}: {row['trade_count']} trades\")\n",
    "\n",
    "# 2. 5-minute interval trade count\n",
    "print(f\"\\n=== 5-MINUTE INTERVAL TRADE COUNT ===\")\n",
    "df['five_min_key'] = df['date'].dt.floor('5min')\n",
    "five_min_trades = df.groupby('five_min_key').size().reset_index(name='trade_count')\n",
    "five_min_trades['time'] = five_min_trades['five_min_key'].dt.time\n",
    "\n",
    "print(f\"Total 5-minute intervals: {len(five_min_trades)}\")\n",
    "print(f\"Average trades per 5-min: {five_min_trades['trade_count'].mean():.1f}\")\n",
    "print(f\"Max trades in 5-min: {five_min_trades['trade_count'].max()}\")\n",
    "\n",
    "# 3. 15-minute interval trade count\n",
    "print(f\"\\n=== 15-MINUTE INTERVAL TRADE COUNT ===\")\n",
    "df['fifteen_min_key'] = df['date'].dt.floor('15min')\n",
    "fifteen_min_trades = df.groupby('fifteen_min_key').size().reset_index(name='trade_count')\n",
    "fifteen_min_trades['time'] = fifteen_min_trades['fifteen_min_key'].dt.time\n",
    "\n",
    "print(f\"Total 15-minute intervals: {len(fifteen_min_trades)}\")\n",
    "print(f\"Average trades per 15-min: {fifteen_min_trades['trade_count'].mean():.1f}\")\n",
    "print(f\"Max trades in 15-min: {fifteen_min_trades['trade_count'].max()}\")\n",
    "\n",
    "# 4. Hourly trade count\n",
    "print(f\"\\n=== HOURLY TRADE COUNT ===\")\n",
    "df['hour_key'] = df['date'].dt.hour\n",
    "hourly_trades = df.groupby('hour_key').size().reset_index(name='trade_count')\n",
    "hourly_trades['time_range'] = hourly_trades['hour_key'].apply(lambda x: f\"{x:02d}:00-{x:02d}:59\")\n",
    "\n",
    "print(f\"Total trading hours: {len(hourly_trades)}\")\n",
    "print(f\"Average trades per hour: {hourly_trades['trade_count'].mean():.1f}\")\n",
    "print(f\"Max trades in an hour: {hourly_trades['trade_count'].max()}\")\n",
    "\n",
    "# Display hourly breakdown\n",
    "print(f\"\\n=== HOURLY BREAKDOWN ===\")\n",
    "for idx, row in hourly_trades.iterrows():\n",
    "    print(f\"{row['time_range']}: {row['trade_count']:,} trades\")\n",
    "\n",
    "# 5. Activity density analysis\n",
    "print(f\"\\n=== ACTIVITY DENSITY ANALYSIS ===\")\n",
    "\n",
    "# Find peak activity periods\n",
    "peak_minute = minute_trades.loc[minute_trades['trade_count'].idxmax()]\n",
    "peak_five_min = five_min_trades.loc[five_min_trades['trade_count'].idxmax()]\n",
    "peak_fifteen_min = fifteen_min_trades.loc[fifteen_min_trades['trade_count'].idxmax()]\n",
    "peak_hour = hourly_trades.loc[hourly_trades['trade_count'].idxmax()]\n",
    "\n",
    "print(f\"Peak activity minute: {peak_minute['time']} ({peak_minute['trade_count']} trades)\")\n",
    "print(f\"Peak activity 5-min: {peak_five_min['time']} ({peak_five_min['trade_count']} trades)\")\n",
    "print(f\"Peak activity 15-min: {peak_fifteen_min['time']} ({peak_fifteen_min['trade_count']} trades)\")\n",
    "print(f\"Peak activity hour: {peak_hour['time_range']} ({peak_hour['trade_count']:,} trades)\")\n",
    "\n",
    "# 6. Quiet periods analysis\n",
    "print(f\"\\n=== QUIET PERIODS ANALYSIS ===\")\n",
    "quiet_minutes = minute_trades[minute_trades['trade_count'] == minute_trades['trade_count'].min()]\n",
    "print(f\"Minutes with minimum activity ({minute_trades['trade_count'].min()} trades):\")\n",
    "for idx, row in quiet_minutes.head(5).iterrows():\n",
    "    print(f\"  {row['time']}\")\n",
    "\n",
    "# 7. Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "total_trades = len(df)\n",
    "total_minutes = len(minute_trades)\n",
    "total_hours = len(hourly_trades)\n",
    "\n",
    "print(f\"Total trades: {total_trades:,}\")\n",
    "print(f\"Total active minutes: {total_minutes}\")\n",
    "print(f\"Total trading hours: {total_hours}\")\n",
    "print(f\"Average trades per minute: {total_trades/total_minutes:.1f}\")\n",
    "print(f\"Average trades per hour: {total_trades/total_hours:.1f}\")\n",
    "\n",
    "# Display sample of minute-by-minute data\n",
    "print(f\"\\n=== SAMPLE MINUTE-BY-MINUTE DATA (First 10 rows) ===\")\n",
    "print(minute_trades.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f4fbac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTRADAY VOLATILITY ANALYSIS ===\n",
      "Calculating price volatility across different time intervals...\n",
      "\n",
      "=== MINUTE-BY-MINUTE VOLATILITY ===\n",
      "Total minutes analyzed: 375\n",
      "Minutes with volatility (multiple trades): 375\n",
      "Average minute volatility: ₹0.0957\n",
      "Max minute volatility: ₹0.7306\n",
      "\n",
      "=== 5-MINUTE INTERVAL VOLATILITY ===\n",
      "Total 5-minute intervals: 75\n",
      "Intervals with volatility: 75\n",
      "Average 5-min volatility: ₹0.1911\n",
      "Max 5-min volatility: ₹1.2729\n",
      "\n",
      "=== 15-MINUTE INTERVAL VOLATILITY ===\n",
      "Total 15-minute intervals: 25\n",
      "Intervals with volatility: 25\n",
      "Average 15-min volatility: ₹0.3198\n",
      "Max 15-min volatility: ₹1.3852\n",
      "\n",
      "=== HOURLY VOLATILITY ===\n",
      "Total trading hours: 7\n",
      "Average hourly volatility: ₹0.5978\n",
      "Max hourly volatility: ₹1.1315\n",
      "\n",
      "=== PEAK VOLATILITY PERIODS ===\n",
      "Highest minute volatility: 09:16:00 (₹0.7306)\n",
      "  Price range: ₹385.60 - ₹387.75\n",
      "  Trades: 94\n",
      "Highest 5-min volatility: 09:15:00 (₹1.2729)\n",
      "  Price range: ₹385.60 - ₹389.45\n",
      "Highest 15-min volatility: 09:15:00 (₹1.3852)\n",
      "  Price range: ₹385.60 - ₹390.20\n",
      "Highest hourly volatility: 09:00-09:59 (₹1.1315)\n",
      "  Price range: ₹385.60 - ₹390.20\n",
      "\n",
      "=== VOLATILITY DISTRIBUTION ANALYSIS ===\n",
      "Minute volatility percentiles:\n",
      "  25th percentile: ₹0.0611\n",
      "  50th percentile: ₹0.0832\n",
      "  75th percentile: ₹0.1143\n",
      "  90th percentile: ₹0.1575\n",
      "  95th percentile: ₹0.1931\n",
      "  99th percentile: ₹0.2773\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Overall price standard deviation: ₹1.5743\n",
      "Overall price range: ₹6.70\n",
      "Overall coefficient of variation: 0.41%\n",
      "\n",
      "=== SAMPLE MINUTE VOLATILITY DATA (First 10 rows) ===\n",
      "       time  avg_price  price_std  min_price  max_price  trade_count\n",
      "0  09:15:00   386.2414     0.2694     385.70     386.95          116\n",
      "1  09:16:00   387.0718     0.7306     385.60     387.75           94\n",
      "2  09:17:00   388.0600     0.3531     387.55     388.55           15\n",
      "3  09:18:00   389.0036     0.2742     388.45     389.45           14\n",
      "4  09:19:00   389.0891     0.0907     388.80     389.25           96\n",
      "5  09:20:00   389.1423     0.2465     388.90     389.85           13\n",
      "6  09:21:00   389.5707     0.1650     389.35     390.05           94\n",
      "7  09:22:00   389.8905     0.1754     389.50     390.20          105\n",
      "8  09:23:00   389.5607     0.2419     389.10     389.85           14\n",
      "9  09:24:00   388.7867     0.1157     388.60     389.00           15\n"
     ]
    }
   ],
   "source": [
    "# Calculate intraday volatility using standard deviation of price per minute/hour\n",
    "print(\"=== INTRADAY VOLATILITY ANALYSIS ===\")\n",
    "\n",
    "# Calculate volatility at different time intervals\n",
    "print(\"Calculating price volatility across different time intervals...\")\n",
    "\n",
    "# 1. Minute-by-minute volatility\n",
    "print(\"\\n=== MINUTE-BY-MINUTE VOLATILITY ===\")\n",
    "df['minute_key'] = df['date'].dt.floor('1min')\n",
    "minute_volatility = df.groupby('minute_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']  # Price statistics including std dev\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "minute_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "minute_volatility = minute_volatility.reset_index()\n",
    "minute_volatility['time'] = minute_volatility['minute_key'].dt.time\n",
    "\n",
    "# Filter out minutes with only 1 trade (std dev = 0 or NaN)\n",
    "minute_volatility_filtered = minute_volatility[minute_volatility['trade_count'] > 1]\n",
    "\n",
    "print(f\"Total minutes analyzed: {len(minute_volatility)}\")\n",
    "print(f\"Minutes with volatility (multiple trades): {len(minute_volatility_filtered)}\")\n",
    "print(f\"Average minute volatility: ₹{minute_volatility_filtered['price_std'].mean():.4f}\")\n",
    "print(f\"Max minute volatility: ₹{minute_volatility_filtered['price_std'].max():.4f}\")\n",
    "\n",
    "# 2. 5-minute interval volatility\n",
    "print(f\"\\n=== 5-MINUTE INTERVAL VOLATILITY ===\")\n",
    "df['five_min_key'] = df['date'].dt.floor('5min')\n",
    "five_min_volatility = df.groupby('five_min_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).round(4)\n",
    "\n",
    "five_min_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "five_min_volatility = five_min_volatility.reset_index()\n",
    "five_min_volatility['time'] = five_min_volatility['five_min_key'].dt.time\n",
    "\n",
    "five_min_filtered = five_min_volatility[five_min_volatility['trade_count'] > 1]\n",
    "\n",
    "print(f\"Total 5-minute intervals: {len(five_min_volatility)}\")\n",
    "print(f\"Intervals with volatility: {len(five_min_filtered)}\")\n",
    "print(f\"Average 5-min volatility: ₹{five_min_filtered['price_std'].mean():.4f}\")\n",
    "print(f\"Max 5-min volatility: ₹{five_min_filtered['price_std'].max():.4f}\")\n",
    "\n",
    "# 3. 15-minute interval volatility\n",
    "print(f\"\\n=== 15-MINUTE INTERVAL VOLATILITY ===\")\n",
    "df['fifteen_min_key'] = df['date'].dt.floor('15min')\n",
    "fifteen_min_volatility = df.groupby('fifteen_min_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).round(4)\n",
    "\n",
    "fifteen_min_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "fifteen_min_volatility = fifteen_min_volatility.reset_index()\n",
    "fifteen_min_volatility['time'] = fifteen_min_volatility['fifteen_min_key'].dt.time\n",
    "\n",
    "fifteen_min_filtered = fifteen_min_volatility[fifteen_min_volatility['trade_count'] > 1]\n",
    "\n",
    "print(f\"Total 15-minute intervals: {len(fifteen_min_volatility)}\")\n",
    "print(f\"Intervals with volatility: {len(fifteen_min_filtered)}\")\n",
    "print(f\"Average 15-min volatility: ₹{fifteen_min_volatility['price_std'].mean():.4f}\")\n",
    "print(f\"Max 15-min volatility: ₹{fifteen_min_volatility['price_std'].max():.4f}\")\n",
    "\n",
    "# 4. Hourly volatility\n",
    "print(f\"\\n=== HOURLY VOLATILITY ===\")\n",
    "df['hour_key'] = df['date'].dt.hour\n",
    "hourly_volatility = df.groupby('hour_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).round(4)\n",
    "\n",
    "hourly_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "hourly_volatility = hourly_volatility.reset_index()\n",
    "hourly_volatility['time_range'] = hourly_volatility['hour_key'].apply(lambda x: f\"{x:02d}:00-{x:02d}:59\")\n",
    "\n",
    "print(f\"Total trading hours: {len(hourly_volatility)}\")\n",
    "print(f\"Average hourly volatility: ₹{hourly_volatility['price_std'].mean():.4f}\")\n",
    "print(f\"Max hourly volatility: ₹{hourly_volatility['price_std'].max():.4f}\")\n",
    "\n",
    "# 5. Peak volatility periods identification\n",
    "print(f\"\\n=== PEAK VOLATILITY PERIODS ===\")\n",
    "\n",
    "# Find highest volatility periods\n",
    "highest_vol_minute = minute_volatility_filtered.loc[minute_volatility_filtered['price_std'].idxmax()]\n",
    "highest_vol_five_min = five_min_filtered.loc[five_min_filtered['price_std'].idxmax()]\n",
    "highest_vol_fifteen_min = fifteen_min_filtered.loc[fifteen_min_filtered['price_std'].idxmax()]\n",
    "highest_vol_hour = hourly_volatility.loc[hourly_volatility['price_std'].idxmax()]\n",
    "\n",
    "print(f\"Highest minute volatility: {highest_vol_minute['time']} (₹{highest_vol_minute['price_std']:.4f})\")\n",
    "print(f\"  Price range: ₹{highest_vol_minute['min_price']:.2f} - ₹{highest_vol_minute['max_price']:.2f}\")\n",
    "print(f\"  Trades: {highest_vol_minute['trade_count']}\")\n",
    "\n",
    "print(f\"Highest 5-min volatility: {highest_vol_five_min['time']} (₹{highest_vol_five_min['price_std']:.4f})\")\n",
    "print(f\"  Price range: ₹{highest_vol_five_min['min_price']:.2f} - ₹{highest_vol_five_min['max_price']:.2f}\")\n",
    "\n",
    "print(f\"Highest 15-min volatility: {highest_vol_fifteen_min['time']} (₹{highest_vol_fifteen_min['price_std']:.4f})\")\n",
    "print(f\"  Price range: ₹{highest_vol_fifteen_min['min_price']:.2f} - ₹{highest_vol_fifteen_min['max_price']:.2f}\")\n",
    "\n",
    "print(f\"Highest hourly volatility: {highest_vol_hour['time_range']} (₹{highest_vol_hour['price_std']:.4f})\")\n",
    "print(f\"  Price range: ₹{highest_vol_hour['min_price']:.2f} - ₹{highest_vol_hour['max_price']:.2f}\")\n",
    "\n",
    "# 6. Volatility distribution analysis\n",
    "print(f\"\\n=== VOLATILITY DISTRIBUTION ANALYSIS ===\")\n",
    "\n",
    "# Calculate volatility percentiles\n",
    "volatility_percentiles = minute_volatility_filtered['price_std'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n",
    "print(\"Minute volatility percentiles:\")\n",
    "for p, v in volatility_percentiles.items():\n",
    "    print(f\"  {p*100:2.0f}th percentile: ₹{v:.4f}\")\n",
    "\n",
    "# 7. Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Overall price standard deviation: ₹{df['price'].std():.4f}\")\n",
    "print(f\"Overall price range: ₹{df['price'].max() - df['price'].min():.2f}\")\n",
    "print(f\"Overall coefficient of variation: {(df['price'].std() / df['price'].mean() * 100):.2f}%\")\n",
    "\n",
    "# Display sample volatility data\n",
    "print(f\"\\n=== SAMPLE MINUTE VOLATILITY DATA (First 10 rows) ===\")\n",
    "print(minute_volatility_filtered[['time', 'avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82467e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP N VOLATILE MINUTES ANALYSIS ===\n",
      "Identifying top 20 most volatile minutes...\n",
      "\n",
      "=== TOP 20 MOST VOLATILE MINUTES ===\n",
      "Total minutes with volatility: 375\n",
      "Showing top 20 minutes by price standard deviation\n",
      "\n",
      "Rank Time     Std Dev    Price Range  Min Price  Max Price  Trades \n",
      "--------------------------------------------------------------------------------\n",
      "1    09:16:00 ₹0.7306    ₹2.15        ₹385.60    ₹387.75    94     \n",
      "2    09:17:00 ₹0.3531    ₹1.00        ₹387.55    ₹388.55    15     \n",
      "3    14:24:00 ₹0.2965    ₹0.95        ₹385.15    ₹386.10    16     \n",
      "4    13:02:00 ₹0.2861    ₹0.75        ₹384.65    ₹385.40    14     \n",
      "5    09:18:00 ₹0.2742    ₹1.00        ₹388.45    ₹389.45    14     \n",
      "6    09:15:00 ₹0.2694    ₹1.25        ₹385.70    ₹386.95    116    \n",
      "7    09:20:00 ₹0.2465    ₹0.95        ₹388.90    ₹389.85    13     \n",
      "8    09:23:00 ₹0.2419    ₹0.75        ₹389.10    ₹389.85    14     \n",
      "9    09:32:00 ₹0.2281    ₹0.70        ₹389.15    ₹389.85    11     \n",
      "10   10:36:00 ₹0.2203    ₹0.60        ₹388.00    ₹388.60    20     \n",
      "11   11:53:00 ₹0.2188    ₹0.55        ₹385.40    ₹385.95    57     \n",
      "12   13:44:00 ₹0.2175    ₹0.80        ₹384.40    ₹385.20    21     \n",
      "13   10:04:00 ₹0.2128    ₹0.55        ₹388.35    ₹388.90    17     \n",
      "14   13:25:00 ₹0.2098    ₹0.55        ₹383.50    ₹384.05    21     \n",
      "15   11:01:00 ₹0.2043    ₹0.70        ₹387.15    ₹387.85    21     \n",
      "16   09:29:00 ₹0.2006    ₹0.65        ₹388.35    ₹389.00    13     \n",
      "17   14:20:00 ₹0.1995    ₹0.50        ₹385.90    ₹386.40    20     \n",
      "18   10:40:00 ₹0.1981    ₹0.65        ₹387.60    ₹388.25    21     \n",
      "19   12:09:00 ₹0.1951    ₹0.60        ₹384.75    ₹385.35    72     \n",
      "20   14:55:00 ₹0.1923    ₹0.65        ₹386.35    ₹387.00    14     \n",
      "\n",
      "=== DETAILED ANALYSIS OF TOP 20 VOLATILE MINUTES ===\n",
      "\n",
      "--- TIME DISTRIBUTION ---\n",
      "Hourly distribution of top volatile minutes:\n",
      "  09:00-09:59: 8 minutes\n",
      "  10:00-10:59: 3 minutes\n",
      "  11:00-11:59: 2 minutes\n",
      "  12:00-12:59: 1 minutes\n",
      "  13:00-13:59: 3 minutes\n",
      "  14:00-14:59: 3 minutes\n",
      "\n",
      "--- VOLATILITY MAGNITUDE ANALYSIS ---\n",
      "Highest volatility: ₹0.7306\n",
      "Lowest volatility (in top 20): ₹0.1923\n",
      "Average volatility (top 20): ₹0.2598\n",
      "Median volatility (top 20): ₹0.2195\n",
      "\n",
      "--- PRICE RANGE ANALYSIS ---\n",
      "Largest price range: ₹2.15\n",
      "Smallest price range (in top 20): ₹0.50\n",
      "Average price range (top 20): ₹0.82\n",
      "\n",
      "--- TRADE COUNT ANALYSIS ---\n",
      "Most trades in volatile minute: 116\n",
      "Least trades in volatile minute: 11\n",
      "Average trades in volatile minutes: 30.2\n",
      "\n",
      "--- EXTREME VOLATILITY PERIODS ---\n",
      "Extreme volatility minutes (top 10%): 2\n",
      "  09:16:00: ₹0.7306 std dev, ₹2.15 range\n",
      "  09:17:00: ₹0.3531 std dev, ₹1.00 range\n",
      "\n",
      "--- COMPARISON WITH OVERALL STATISTICS ---\n",
      "Overall day volatility: ₹1.5743\n",
      "Overall day price range: ₹6.70\n",
      "Top 20 volatility vs overall: 0.17x higher\n",
      "Top 20 price range vs overall: 0.12x higher\n",
      "\n",
      "=== EXPORT DATA ===\n",
      "Top volatile minutes data is available in 'top_volatile_minutes' DataFrame\n",
      "You can export this data or use it for further analysis\n",
      "\n",
      "=== SUMMARY TABLE ===\n",
      "         Metric               Value\n",
      "          Count                  20\n",
      "    Avg Std Dev             ₹0.2598\n",
      "Avg Price Range               ₹0.82\n",
      "     Avg Trades                30.2\n",
      "     Time Range 09:15:00 - 14:55:00\n"
     ]
    }
   ],
   "source": [
    "# Identify top N volatile minutes in the day\n",
    "print(\"=== TOP N VOLATILE MINUTES ANALYSIS ===\")\n",
    "\n",
    "# Set N for top volatile minutes (you can change this value)\n",
    "N = 20  # Change this to see top 10, 15, 25, etc.\n",
    "\n",
    "print(f\"Identifying top {N} most volatile minutes...\")\n",
    "\n",
    "# Calculate minute-by-minute volatility (if not already calculated)\n",
    "if 'minute_key' not in df.columns:\n",
    "    df['minute_key'] = df['date'].dt.floor('1min')\n",
    "\n",
    "minute_volatility = df.groupby('minute_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "minute_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "minute_volatility = minute_volatility.reset_index()\n",
    "minute_volatility['time'] = minute_volatility['minute_key'].dt.time\n",
    "\n",
    "# Filter out minutes with only 1 trade (no meaningful volatility)\n",
    "minute_volatility_filtered = minute_volatility[minute_volatility['trade_count'] > 1].copy()\n",
    "\n",
    "# Sort by volatility (price_std) in descending order\n",
    "top_volatile_minutes = minute_volatility_filtered.nlargest(N, 'price_std').copy()\n",
    "\n",
    "# Add additional metrics\n",
    "top_volatile_minutes['price_range'] = top_volatile_minutes['max_price'] - top_volatile_minutes['min_price']\n",
    "top_volatile_minutes['volatility_rank'] = range(1, len(top_volatile_minutes) + 1)\n",
    "\n",
    "print(f\"\\n=== TOP {N} MOST VOLATILE MINUTES ===\")\n",
    "print(f\"Total minutes with volatility: {len(minute_volatility_filtered)}\")\n",
    "print(f\"Showing top {N} minutes by price standard deviation\")\n",
    "\n",
    "# Display the top N volatile minutes\n",
    "print(f\"\\n{'Rank':<4} {'Time':<8} {'Std Dev':<10} {'Price Range':<12} {'Min Price':<10} {'Max Price':<10} {'Trades':<7}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, row in top_volatile_minutes.iterrows():\n",
    "    print(f\"{row['volatility_rank']:<4} {str(row['time']):<8} ₹{row['price_std']:<9.4f} ₹{row['price_range']:<11.2f} ₹{row['min_price']:<9.2f} ₹{row['max_price']:<9.2f} {row['trade_count']:<7}\")\n",
    "\n",
    "# Detailed analysis of top volatile minutes\n",
    "print(f\"\\n=== DETAILED ANALYSIS OF TOP {N} VOLATILE MINUTES ===\")\n",
    "\n",
    "# 1. Time distribution analysis\n",
    "print(\"\\n--- TIME DISTRIBUTION ---\")\n",
    "top_volatile_minutes['hour'] = top_volatile_minutes['time'].apply(lambda x: x.hour)\n",
    "hourly_distribution = top_volatile_minutes['hour'].value_counts().sort_index()\n",
    "\n",
    "print(\"Hourly distribution of top volatile minutes:\")\n",
    "for hour, count in hourly_distribution.items():\n",
    "    print(f\"  {hour:02d}:00-{hour:02d}:59: {count} minutes\")\n",
    "\n",
    "# 2. Volatility magnitude analysis\n",
    "print(f\"\\n--- VOLATILITY MAGNITUDE ANALYSIS ---\")\n",
    "print(f\"Highest volatility: ₹{top_volatile_minutes['price_std'].max():.4f}\")\n",
    "print(f\"Lowest volatility (in top {N}): ₹{top_volatile_minutes['price_std'].min():.4f}\")\n",
    "print(f\"Average volatility (top {N}): ₹{top_volatile_minutes['price_std'].mean():.4f}\")\n",
    "print(f\"Median volatility (top {N}): ₹{top_volatile_minutes['price_std'].median():.4f}\")\n",
    "\n",
    "# 3. Price range analysis\n",
    "print(f\"\\n--- PRICE RANGE ANALYSIS ---\")\n",
    "print(f\"Largest price range: ₹{top_volatile_minutes['price_range'].max():.2f}\")\n",
    "print(f\"Smallest price range (in top {N}): ₹{top_volatile_minutes['price_range'].min():.2f}\")\n",
    "print(f\"Average price range (top {N}): ₹{top_volatile_minutes['price_range'].mean():.2f}\")\n",
    "\n",
    "# 4. Trade count analysis\n",
    "print(f\"\\n--- TRADE COUNT ANALYSIS ---\")\n",
    "print(f\"Most trades in volatile minute: {top_volatile_minutes['trade_count'].max()}\")\n",
    "print(f\"Least trades in volatile minute: {top_volatile_minutes['trade_count'].min()}\")\n",
    "print(f\"Average trades in volatile minutes: {top_volatile_minutes['trade_count'].mean():.1f}\")\n",
    "\n",
    "# 5. Extreme volatility periods\n",
    "print(f\"\\n--- EXTREME VOLATILITY PERIODS ---\")\n",
    "extreme_volatility = top_volatile_minutes[top_volatile_minutes['price_std'] > top_volatile_minutes['price_std'].quantile(0.9)]\n",
    "print(f\"Extreme volatility minutes (top 10%): {len(extreme_volatility)}\")\n",
    "for idx, row in extreme_volatility.iterrows():\n",
    "    print(f\"  {row['time']}: ₹{row['price_std']:.4f} std dev, ₹{row['price_range']:.2f} range\")\n",
    "\n",
    "# 6. Comparison with overall statistics\n",
    "print(f\"\\n--- COMPARISON WITH OVERALL STATISTICS ---\")\n",
    "overall_std = df['price'].std()\n",
    "overall_range = df['price'].max() - df['price'].min()\n",
    "\n",
    "print(f\"Overall day volatility: ₹{overall_std:.4f}\")\n",
    "print(f\"Overall day price range: ₹{overall_range:.2f}\")\n",
    "print(f\"Top {N} volatility vs overall: {top_volatile_minutes['price_std'].mean()/overall_std:.2f}x higher\")\n",
    "print(f\"Top {N} price range vs overall: {top_volatile_minutes['price_range'].mean()/overall_range:.2f}x higher\")\n",
    "\n",
    "# 7. Export top volatile minutes data\n",
    "print(f\"\\n=== EXPORT DATA ===\")\n",
    "print(\"Top volatile minutes data is available in 'top_volatile_minutes' DataFrame\")\n",
    "print(\"You can export this data or use it for further analysis\")\n",
    "\n",
    "# Display summary table\n",
    "print(f\"\\n=== SUMMARY TABLE ===\")\n",
    "summary_stats = {\n",
    "    'Metric': ['Count', 'Avg Std Dev', 'Avg Price Range', 'Avg Trades', 'Time Range'],\n",
    "    'Value': [\n",
    "        len(top_volatile_minutes),\n",
    "        f\"₹{top_volatile_minutes['price_std'].mean():.4f}\",\n",
    "        f\"₹{top_volatile_minutes['price_range'].mean():.2f}\",\n",
    "        f\"{top_volatile_minutes['trade_count'].mean():.1f}\",\n",
    "        f\"{top_volatile_minutes['time'].min()} - {top_volatile_minutes['time'].max()}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e6dcaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADE SIZE ANALYSIS ===\n",
      "Calculating trade size metrics...\n",
      "=== BASIC TRADE SIZE STATISTICS ===\n",
      "Average trade size: 1,051\n",
      "Median trade size: 200\n",
      "Minimum trade size: 1\n",
      "Maximum trade size: 153,858\n",
      "Standard deviation: 3,358\n",
      "\n",
      "=== TRADE SIZE PERCENTILES ===\n",
      "10th percentile: 4\n",
      "25th percentile: 26\n",
      "50th percentile: 200\n",
      "75th percentile: 799\n",
      "90th percentile: 2,440\n",
      "95th percentile: 4,485\n",
      "99th percentile: 13,820\n",
      "\n",
      "=== TRADE SIZE CATEGORIES ===\n",
      "Trade size distribution:\n",
      "  Small (≤100): 4,440 trades (40.53%)\n",
      "  Medium (101-500): 2,757 trades (25.16%)\n",
      "  Very Large (1001-5000): 1,855 trades (16.93%)\n",
      "  Large (501-1000): 1,408 trades (12.85%)\n",
      "  Huge (>5000): 496 trades (4.53%)\n",
      "\n",
      "=== VOLUME-WEIGHTED METRICS ===\n",
      "Volume-weighted average trade size: 11,780\n",
      "Simple average vs volume-weighted: 1,051 vs 11,780\n",
      "Difference: 10,729\n",
      "\n",
      "=== TRADE SIZE BY TIME OF DAY ===\n",
      "Hourly trade size analysis:\n",
      "  09:00-09:59: Avg=2,067, Median=424, Count=1,047.0\n",
      "  10:00-10:59: Avg=973, Median=180, Count=1,476.0\n",
      "  11:00-11:59: Avg=811, Median=115, Count=1,653.0\n",
      "  12:00-12:59: Avg=810, Median=202, Count=1,807.0\n",
      "  13:00-13:59: Avg=851, Median=196, Count=1,679.0\n",
      "  14:00-14:59: Avg=1,305, Median=230, Count=1,521.0\n",
      "  15:00-15:59: Avg=955, Median=173, Count=1,773.0\n",
      "\n",
      "Hour with largest average trade size: 09:00 (2,067)\n",
      "Hour with smallest average trade size: 12:00 (810)\n",
      "\n",
      "=== OUTLIER ANALYSIS ===\n",
      "Outlier threshold (IQR method):\n",
      "  Lower bound: -1,134\n",
      "  Upper bound: 1,958\n",
      "  Outlier trades: 1,337 (12.20%)\n",
      "  Normal trades: 9,619 (87.80%)\n",
      "\n",
      "Outlier trade sizes:\n",
      "  Largest outlier: 153,858\n",
      "  Smallest outlier: 1,962\n",
      "  Average outlier size: 6,191\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total trades analyzed: 10,956\n",
      "Total volume traded: 11,510,171\n",
      "Average trade size: 1,051\n",
      "Most common trade size category: Small (≤100)\n",
      "Trade size coefficient of variation: 319.6%\n",
      "\n",
      "=== SAMPLE TRADES BY SIZE ===\n",
      "Small trades sample:\n",
      "                  date   price  qty     trnvr\n",
      "45 2025-08-07 09:15:23  386.45   71  27437.95\n",
      "46 2025-08-07 09:15:23  386.30   65  25109.50\n",
      "47 2025-08-07 09:15:24  386.45   26  10047.70\n",
      "\n",
      "Large trades sample:\n",
      "                 date   price    qty        trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00\n"
     ]
    }
   ],
   "source": [
    "# Measure average trade size and related volume metrics\n",
    "print(\"=== TRADE SIZE ANALYSIS ===\")\n",
    "\n",
    "# Calculate basic trade size statistics\n",
    "print(\"Calculating trade size metrics...\")\n",
    "\n",
    "# Basic statistics\n",
    "avg_trade_size = df['qty'].mean()\n",
    "median_trade_size = df['qty'].median()\n",
    "min_trade_size = df['qty'].min()\n",
    "max_trade_size = df['qty'].max()\n",
    "std_trade_size = df['qty'].std()\n",
    "\n",
    "print(f\"=== BASIC TRADE SIZE STATISTICS ===\")\n",
    "print(f\"Average trade size: {avg_trade_size:,.0f}\")\n",
    "print(f\"Median trade size: {median_trade_size:,.0f}\")\n",
    "print(f\"Minimum trade size: {min_trade_size:,}\")\n",
    "print(f\"Maximum trade size: {max_trade_size:,}\")\n",
    "print(f\"Standard deviation: {std_trade_size:,.0f}\")\n",
    "\n",
    "# Calculate percentiles for trade size distribution\n",
    "print(f\"\\n=== TRADE SIZE PERCENTILES ===\")\n",
    "trade_size_percentiles = df['qty'].quantile([0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n",
    "for p, v in trade_size_percentiles.items():\n",
    "    print(f\"{p*100:2.0f}th percentile: {v:,.0f}\")\n",
    "\n",
    "# Trade size categories analysis\n",
    "print(f\"\\n=== TRADE SIZE CATEGORIES ===\")\n",
    "\n",
    "# Define trade size categories\n",
    "def categorize_trade_size(qty):\n",
    "    if qty <= 100:\n",
    "        return 'Small (≤100)'\n",
    "    elif qty <= 500:\n",
    "        return 'Medium (101-500)'\n",
    "    elif qty <= 1000:\n",
    "        return 'Large (501-1000)'\n",
    "    elif qty <= 5000:\n",
    "        return 'Very Large (1001-5000)'\n",
    "    else:\n",
    "        return 'Huge (>5000)'\n",
    "\n",
    "# Apply categorization\n",
    "df['trade_size_category'] = df['qty'].apply(categorize_trade_size)\n",
    "\n",
    "# Count trades in each category\n",
    "size_category_counts = df['trade_size_category'].value_counts()\n",
    "size_category_percentages = (size_category_counts / len(df) * 100).round(2)\n",
    "\n",
    "print(\"Trade size distribution:\")\n",
    "for category, count in size_category_counts.items():\n",
    "    percentage = size_category_percentages[category]\n",
    "    print(f\"  {category}: {count:,} trades ({percentage}%)\")\n",
    "\n",
    "# Volume-weighted average trade size\n",
    "print(f\"\\n=== VOLUME-WEIGHTED METRICS ===\")\n",
    "volume_weighted_avg = (df['qty'] * df['qty']).sum() / df['qty'].sum()\n",
    "print(f\"Volume-weighted average trade size: {volume_weighted_avg:,.0f}\")\n",
    "\n",
    "# Compare with simple average\n",
    "print(f\"Simple average vs volume-weighted: {avg_trade_size:,.0f} vs {volume_weighted_avg:,.0f}\")\n",
    "print(f\"Difference: {volume_weighted_avg - avg_trade_size:,.0f}\")\n",
    "\n",
    "# Trade size by time of day\n",
    "print(f\"\\n=== TRADE SIZE BY TIME OF DAY ===\")\n",
    "df['hour'] = df['date'].dt.hour\n",
    "hourly_trade_sizes = df.groupby('hour')['qty'].agg(['mean', 'median', 'count']).round(0)\n",
    "hourly_trade_sizes.columns = ['Avg Trade Size', 'Median Trade Size', 'Trade Count']\n",
    "\n",
    "print(\"Hourly trade size analysis:\")\n",
    "for hour, row in hourly_trade_sizes.iterrows():\n",
    "    print(f\"  {hour:02d}:00-{hour:02d}:59: Avg={row['Avg Trade Size']:,.0f}, Median={row['Median Trade Size']:,.0f}, Count={row['Trade Count']:,}\")\n",
    "\n",
    "# Find hours with largest and smallest average trade sizes\n",
    "max_avg_hour = hourly_trade_sizes['Avg Trade Size'].idxmax()\n",
    "min_avg_hour = hourly_trade_sizes['Avg Trade Size'].idxmin()\n",
    "\n",
    "print(f\"\\nHour with largest average trade size: {max_avg_hour:02d}:00 ({hourly_trade_sizes.loc[max_avg_hour, 'Avg Trade Size']:,.0f})\")\n",
    "print(f\"Hour with smallest average trade size: {min_avg_hour:02d}:00 ({hourly_trade_sizes.loc[min_avg_hour, 'Avg Trade Size']:,.0f})\")\n",
    "\n",
    "# Trade size outliers analysis\n",
    "print(f\"\\n=== OUTLIER ANALYSIS ===\")\n",
    "\n",
    "# Define outliers using IQR method\n",
    "Q1 = df['qty'].quantile(0.25)\n",
    "Q3 = df['qty'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['qty'] < lower_bound) | (df['qty'] > upper_bound)]\n",
    "normal_trades = df[(df['qty'] >= lower_bound) & (df['qty'] <= upper_bound)]\n",
    "\n",
    "print(f\"Outlier threshold (IQR method):\")\n",
    "print(f\"  Lower bound: {lower_bound:,.0f}\")\n",
    "print(f\"  Upper bound: {upper_bound:,.0f}\")\n",
    "print(f\"  Outlier trades: {len(outliers):,} ({(len(outliers)/len(df)*100):.2f}%)\")\n",
    "print(f\"  Normal trades: {len(normal_trades):,} ({(len(normal_trades)/len(df)*100):.2f}%)\")\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    print(f\"\\nOutlier trade sizes:\")\n",
    "    print(f\"  Largest outlier: {outliers['qty'].max():,}\")\n",
    "    print(f\"  Smallest outlier: {outliers['qty'].min():,}\")\n",
    "    print(f\"  Average outlier size: {outliers['qty'].mean():,.0f}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"Total trades analyzed: {len(df):,}\")\n",
    "print(f\"Total volume traded: {df['qty'].sum():,}\")\n",
    "print(f\"Average trade size: {avg_trade_size:,.0f}\")\n",
    "print(f\"Most common trade size category: {size_category_counts.index[0]}\")\n",
    "print(f\"Trade size coefficient of variation: {(std_trade_size/avg_trade_size*100):.1f}%\")\n",
    "\n",
    "# Display sample of different trade sizes\n",
    "print(f\"\\n=== SAMPLE TRADES BY SIZE ===\")\n",
    "print(\"Small trades sample:\")\n",
    "small_trades = df[df['qty'] <= 100][['date', 'price', 'qty', 'trnvr']].head(3)\n",
    "print(small_trades)\n",
    "\n",
    "print(\"\\nLarge trades sample:\")\n",
    "large_trades = df[df['qty'] > 1000][['date', 'price', 'qty', 'trnvr']].head(3)\n",
    "print(large_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76b0a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNUSUAL TRADE SIZES ANALYSIS ===\n",
      "Identifying top 1% largest trade sizes...\n",
      "=== VOLUME PERCENTILE THRESHOLDS ===\n",
      "50.0th percentile: 200\n",
      "75.0th percentile: 799\n",
      "90.0th percentile: 2,440\n",
      "95.0th percentile: 4,485\n",
      "99.0th percentile: 13,820\n",
      "99.9th percentile: 38,091\n",
      "\n",
      "Unusual trade size threshold (top 1%): 13,820\n",
      "\n",
      "=== UNUSUAL TRADES SUMMARY ===\n",
      "Total unusual trades (top 1%): 110\n",
      "Percentage of total trades: 1.00%\n",
      "Total volume in unusual trades: 2,781,296\n",
      "Percentage of total volume: 24.16%\n",
      "\n",
      "=== ALL UNUSUAL TRADES (TOP 1%) ===\n",
      "Rank Time         Price    Quantity   Turnover     Cum Turnover   \n",
      "--------------------------------------------------------------------------------\n",
      "1    15:01:57     ₹387.05  153,858    ₹59,550,738.90 ₹3,896,603,224.25\n",
      "2    09:20:41     ₹389.30  67,256     ₹26,182,760.80 ₹344,731,947.85\n",
      "3    09:15:00     ₹386.85  65,740     ₹25,431,519.00 ₹25,431,519.00 \n",
      "4    12:08:06     ₹385.05  60,580     ₹23,326,329.00 ₹1,993,683,235.00\n",
      "5    12:08:12     ₹384.80  55,402     ₹21,318,689.60 ₹2,016,729,133.00\n",
      "6    14:40:45     ₹385.95  54,602     ₹21,073,641.90 ₹3,498,574,314.65\n",
      "7    09:20:49     ₹389.85  43,873     ₹17,103,889.05 ₹361,847,515.90\n",
      "8    14:45:21     ₹386.40  43,199     ₹16,692,093.60 ₹3,611,221,840.20\n",
      "9    15:07:53     ₹387.80  42,697     ₹16,557,896.60 ₹4,012,897,672.80\n",
      "10   14:05:06     ₹385.15  40,953     ₹15,773,047.95 ₹3,066,209,083.95\n",
      "11   14:45:12     ₹386.05  40,000     ₹15,442,000.00 ₹3,593,732,275.95\n",
      "12   15:28:54     ₹388.25  38,001     ₹14,753,888.25 ₹4,433,507,314.40\n",
      "13   10:40:13     ₹388.05  36,352     ₹14,106,393.60 ₹1,181,149,654.55\n",
      "14   10:30:25     ₹388.15  35,050     ₹13,604,657.50 ₹1,059,454,173.20\n",
      "15   14:16:13     ₹385.80  33,636     ₹12,976,768.80 ₹3,165,278,654.70\n",
      "16   09:21:01     ₹389.65  33,563     ₹13,077,822.95 ₹374,925,338.85\n",
      "17   14:59:34     ₹387.00  33,376     ₹12,916,512.00 ₹3,793,698,696.55\n",
      "18   10:46:23     ₹387.60  33,297     ₹12,905,917.20 ₹1,304,605,638.80\n",
      "19   12:43:06     ₹384.70  32,819     ₹12,625,469.30 ₹2,323,273,980.00\n",
      "20   14:39:07     ₹386.05  32,811     ₹12,666,686.55 ₹3,461,254,453.35\n",
      "21   10:17:48     ₹388.85  32,072     ₹12,471,197.20 ₹965,010,705.05\n",
      "22   09:18:14     ₹389.00  31,428     ₹12,225,492.00 ₹222,028,512.70\n",
      "23   11:02:02     ₹387.00  30,882     ₹11,951,334.00 ₹1,451,275,099.90\n",
      "24   14:20:20     ₹386.30  30,597     ₹11,819,621.10 ₹3,204,131,146.85\n",
      "25   12:17:06     ₹386.40  30,424     ₹11,755,833.60 ₹2,115,828,939.65\n",
      "26   14:37:29     ₹386.25  30,288     ₹11,698,740.00 ₹3,421,333,843.00\n",
      "27   09:58:30     ₹387.80  27,948     ₹10,838,234.40 ₹810,861,813.25\n",
      "28   15:20:26     ₹387.85  27,894     ₹10,818,687.90 ₹4,262,217,243.40\n",
      "29   10:40:08     ₹388.15  27,344     ₹10,613,573.60 ₹1,165,820,430.95\n",
      "30   14:22:17     ₹386.40  27,002     ₹10,433,572.80 ₹3,247,740,153.35\n",
      "31   13:50:34     ₹385.00  26,669     ₹10,267,565.00 ₹2,963,162,647.70\n",
      "32   14:11:39     ₹385.40  26,355     ₹10,157,217.00 ₹3,109,312,966.05\n",
      "33   14:44:40     ₹386.40  26,299     ₹10,161,933.60 ₹3,555,979,160.85\n",
      "34   14:44:51     ₹386.10  26,203     ₹10,116,978.30 ₹3,566,163,741.65\n",
      "35   11:25:31     ₹386.60  26,173     ₹10,118,481.80 ₹1,619,352,953.35\n",
      "36   14:22:05     ₹386.30  26,151     ₹10,102,131.30 ₹3,235,707,091.55\n",
      "37   14:44:34     ₹386.40  26,130     ₹10,096,632.00 ₹3,545,816,454.55\n",
      "38   14:37:57     ₹386.15  25,744     ₹9,941,045.60 ₹3,433,395,652.75\n",
      "39   12:42:49     ₹385.00  25,415     ₹9,784,775.00 ₹2,301,199,306.40\n",
      "40   14:45:00     ₹386.45  25,183     ₹9,731,970.35 ₹3,576,848,311.25\n",
      "41   13:14:20     ₹384.20  23,941     ₹9,198,132.20 ₹2,587,201,979.00\n",
      "42   11:37:01     ₹385.95  23,354     ₹9,013,476.30 ₹1,701,722,658.35\n",
      "43   14:22:29     ₹386.30  23,279     ₹8,992,677.70 ₹3,258,084,071.85\n",
      "44   11:02:00     ₹387.00  23,213     ₹8,983,431.00 ₹1,439,225,455.20\n",
      "45   09:26:58     ₹389.00  23,182     ₹9,017,798.00 ₹507,733,619.00\n",
      "46   14:25:38     ₹385.10  22,639     ₹8,718,278.90 ₹3,315,524,377.15\n",
      "47   11:36:34     ₹386.25  22,282     ₹8,606,422.50 ₹1,692,201,677.40\n",
      "48   09:56:35     ₹388.40  22,027     ₹8,555,286.80 ₹785,263,738.75\n",
      "49   09:17:24     ₹387.95  21,993     ₹8,532,184.35 ₹190,605,492.65\n",
      "50   11:16:56     ₹387.70  21,846     ₹8,469,694.20 ₹1,554,894,209.00\n",
      "51   14:23:04     ₹386.20  21,478     ₹8,294,803.60 ₹3,275,187,164.75\n",
      "52   15:00:04     ₹387.35  21,410     ₹8,293,163.50 ₹3,803,909,913.65\n",
      "53   14:51:34     ₹386.80  21,144     ₹8,178,499.20 ₹3,687,205,016.90\n",
      "54   10:31:53     ₹387.90  20,921     ₹8,115,255.90 ₹1,092,782,650.40\n",
      "55   15:11:00     ₹387.30  20,741     ₹8,032,989.30 ₹4,089,213,478.25\n",
      "56   15:17:56     ₹388.05  20,717     ₹8,039,231.85 ₹4,207,204,422.30\n",
      "57   11:53:29     ₹385.75  20,234     ₹7,805,265.50 ₹1,871,130,125.65\n",
      "58   14:21:48     ₹386.25  20,163     ₹7,787,958.75 ₹3,222,589,456.25\n",
      "59   14:24:21     ₹385.65  20,101     ₹7,751,950.65 ₹3,293,130,130.55\n",
      "60   09:17:16     ₹387.60  19,892     ₹7,710,139.20 ₹180,496,125.70\n",
      "61   13:14:51     ₹384.25  19,589     ₹7,527,073.25 ₹2,598,226,825.05\n",
      "62   09:20:33     ₹389.15  19,580     ₹7,619,557.00 ₹318,510,272.05\n",
      "63   12:17:01     ₹386.20  19,316     ₹7,459,839.20 ₹2,104,073,106.05\n",
      "64   09:18:31     ₹389.15  19,299     ₹7,510,205.85 ₹239,838,201.15\n",
      "65   10:42:01     ₹387.75  19,202     ₹7,445,575.50 ₹1,226,019,155.20\n",
      "66   13:50:39     ₹385.00  19,158     ₹7,375,830.00 ₹2,970,538,477.70\n",
      "67   09:18:23     ₹389.45  19,083     ₹7,431,874.35 ₹230,820,426.55\n",
      "68   09:35:41     ₹389.05  18,202     ₹7,081,488.10 ₹623,732,994.90\n",
      "69   15:20:33     ₹387.95  17,827     ₹6,915,984.65 ₹4,269,183,642.05\n",
      "70   09:17:08     ₹387.60  17,699     ₹6,860,132.40 ₹170,786,228.50\n",
      "71   13:51:13     ₹384.90  17,620     ₹6,781,938.00 ₹2,980,287,536.95\n",
      "72   14:44:17     ₹386.60  17,509     ₹6,768,979.40 ₹3,533,901,188.85\n",
      "73   09:59:02     ₹388.40  17,444     ₹6,775,249.60 ₹819,963,866.35\n",
      "74   09:18:47     ₹388.45  17,426     ₹6,769,129.70 ₹251,789,815.60\n",
      "75   09:18:55     ₹389.05  17,196     ₹6,690,103.80 ₹258,480,307.85\n",
      "76   13:44:32     ₹384.70  17,128     ₹6,589,141.60 ₹2,888,397,213.85\n",
      "77   10:00:55     ₹388.50  17,077     ₹6,634,414.50 ₹851,184,772.05\n",
      "78   10:46:29     ₹387.60  16,834     ₹6,524,858.40 ₹1,311,213,809.70\n",
      "79   11:24:44     ₹386.95  16,834     ₹6,513,916.30 ₹1,597,502,544.95\n",
      "80   15:06:51     ₹387.80  16,797     ₹6,513,876.60 ₹3,984,218,742.55\n",
      "81   09:29:38     ₹388.45  16,750     ₹6,506,537.50 ₹546,205,610.35\n",
      "82   12:50:39     ₹385.00  16,428     ₹6,324,780.00 ₹2,405,639,267.60\n",
      "83   09:19:53     ₹389.10  16,221     ₹6,311,591.10 ₹288,967,743.05\n",
      "84   09:27:28     ₹388.90  16,043     ₹6,239,122.70 ₹515,276,131.50\n",
      "85   14:30:12     ₹385.95  16,005     ₹6,177,129.75 ₹3,363,660,303.50\n",
      "86   09:16:59     ₹387.60  15,914     ₹6,168,266.40 ₹161,454,370.90\n",
      "87   10:42:49     ₹387.75  15,621     ₹6,057,042.75 ₹1,241,916,681.15\n",
      "88   13:19:34     ₹384.05  15,619     ₹5,998,476.95 ₹2,636,069,397.55\n",
      "89   09:40:36     ₹389.70  15,553     ₹6,061,004.10 ₹675,905,644.85\n",
      "90   09:18:06     ₹388.85  15,524     ₹6,036,507.40 ₹209,800,298.05\n",
      "91   09:20:17     ₹389.15  15,248     ₹5,933,759.20 ₹305,767,466.55\n",
      "92   09:26:13     ₹388.95  15,248     ₹5,930,709.60 ₹491,244,597.20\n",
      "93   13:48:36     ₹384.95  15,221     ₹5,859,323.95 ₹2,943,050,120.30\n",
      "94   09:25:27     ₹388.95  15,181     ₹5,904,649.95 ₹476,933,736.25\n",
      "95   13:22:46     ₹384.00  15,113     ₹5,803,392.00 ₹2,681,610,213.70\n",
      "96   13:25:30     ₹383.85  15,037     ₹5,771,952.45 ₹2,717,590,655.55\n",
      "97   14:36:14     ₹386.30  15,007     ₹5,797,204.10 ₹3,402,116,846.90\n",
      "98   10:43:51     ₹387.70  14,884     ₹5,770,526.80 ₹1,262,313,313.95\n",
      "99   12:42:50     ₹385.00  14,745     ₹5,676,825.00 ₹2,306,876,131.40\n",
      "100  13:44:28     ₹385.15  14,711     ₹5,665,941.65 ₹2,881,808,072.25\n",
      "101  09:23:56     ₹389.15  14,702     ₹5,721,283.30 ₹450,789,111.55\n",
      "102  09:59:08     ₹388.35  14,633     ₹5,682,725.55 ₹825,710,644.90\n",
      "103  14:16:03     ₹385.60  14,558     ₹5,613,564.80 ₹3,151,525,690.70\n",
      "104  12:07:24     ₹385.15  14,322     ₹5,516,118.30 ₹1,959,933,962.10\n",
      "105  10:40:24     ₹387.75  14,307     ₹5,547,539.25 ₹1,193,298,417.40\n",
      "106  09:21:55     ₹389.90  14,224     ₹5,545,937.60 ₹405,012,184.60\n",
      "107  09:23:33     ₹389.45  14,076     ₹5,481,898.20 ₹442,247,223.35\n",
      "108  13:10:28     ₹384.35  14,025     ₹5,390,508.75 ₹2,559,164,607.60\n",
      "109  10:57:08     ₹388.25  13,895     ₹5,394,733.75 ₹1,387,760,360.70\n",
      "110  09:15:08     ₹386.00  13,838     ₹5,341,468.00 ₹43,402,867.25 \n",
      "\n",
      "=== DETAILED ANALYSIS OF UNUSUAL TRADES ===\n",
      "\n",
      "--- SIZE DISTRIBUTION ---\n",
      "Size distribution of unusual trades:\n",
      "  Huge (10K-50K): 104 trades\n",
      "  Massive (>50K): 6 trades\n",
      "\n",
      "--- TIME DISTRIBUTION ---\n",
      "Hourly distribution of unusual trades:\n",
      "  09:00-09:59: 32 trades\n",
      "  10:00-10:59: 13 trades\n",
      "  11:00-11:59: 8 trades\n",
      "  12:00-12:59: 9 trades\n",
      "  13:00-13:59: 12 trades\n",
      "  14:00-14:59: 27 trades\n",
      "  15:00-15:59: 9 trades\n",
      "\n",
      "--- PRICE ANALYSIS ---\n",
      "Average price of unusual trades: ₹387.02\n",
      "Price range of unusual trades: ₹383.85 - ₹389.90\n",
      "Price standard deviation: ₹1.58\n",
      "\n",
      "--- MARKET IMPACT ANALYSIS ---\n",
      "Unusual trades represent:\n",
      "  Volume: 2,781,296 / 11,510,171 = 24.16%\n",
      "  Turnover: ₹1,076,308,067.55 / ₹4,451,969,111.70 = 24.18%\n",
      "\n",
      "--- TOP 5 LARGEST SINGLE TRADES ---\n",
      "1. 15:01:57 - 153,858 shares at ₹387.05\n",
      "   Turnover: ₹59,550,738.90\n",
      "2. 09:20:41 - 67,256 shares at ₹389.30\n",
      "   Turnover: ₹26,182,760.80\n",
      "3. 09:15:00 - 65,740 shares at ₹386.85\n",
      "   Turnover: ₹25,431,519.00\n",
      "4. 12:08:06 - 60,580 shares at ₹385.05\n",
      "   Turnover: ₹23,326,329.00\n",
      "5. 12:08:12 - 55,402 shares at ₹384.80\n",
      "   Turnover: ₹21,318,689.60\n",
      "\n",
      "--- STATISTICAL COMPARISON ---\n",
      "Unusual trades vs Normal trades:\n",
      "  Average size: 25,285 vs 805\n",
      "  Median size: 20,729 vs 194\n",
      "  Size ratio: 31.4x larger\n",
      "\n",
      "--- CLUSTERING ANALYSIS ---\n",
      "Unusual trades within 5 minutes of each other: 86\n",
      "Clustering percentage: 78.2%\n",
      "\n",
      "=== EXPORT DATA ===\n",
      "Unusual trades data is available in 'unusual_trades' DataFrame\n",
      "You can export this data for further analysis\n",
      "\n",
      "=== SUMMARY TABLE ===\n",
      "        Metric             Value\n",
      "         Count               110\n",
      "  Total Volume         2,781,296\n",
      "Total Turnover ₹1,076,308,067.55\n",
      "      Avg Size            25,285\n",
      " Largest Trade           153,858\n",
      "    Time Range     09:15 - 15:28\n"
     ]
    }
   ],
   "source": [
    "# Identify unusual trade sizes (top 1% volume)\n",
    "print(\"=== UNUSUAL TRADE SIZES ANALYSIS ===\")\n",
    "\n",
    "# Calculate the 99th percentile threshold for unusual trade sizes\n",
    "print(\"Identifying top 1% largest trade sizes...\")\n",
    "\n",
    "# Calculate volume percentiles\n",
    "volume_percentiles = df['qty'].quantile([0.5, 0.75, 0.9, 0.95, 0.99, 0.999])\n",
    "unusual_threshold = volume_percentiles[0.99]\n",
    "\n",
    "print(f\"=== VOLUME PERCENTILE THRESHOLDS ===\")\n",
    "for p, v in volume_percentiles.items():\n",
    "    print(f\"{p*100:3.1f}th percentile: {v:,.0f}\")\n",
    "\n",
    "print(f\"\\nUnusual trade size threshold (top 1%): {unusual_threshold:,.0f}\")\n",
    "\n",
    "# Identify unusual trades (top 1%)\n",
    "unusual_trades = df[df['qty'] >= unusual_threshold].copy()\n",
    "unusual_trades = unusual_trades.sort_values('qty', ascending=False)\n",
    "\n",
    "print(f\"\\n=== UNUSUAL TRADES SUMMARY ===\")\n",
    "print(f\"Total unusual trades (top 1%): {len(unusual_trades):,}\")\n",
    "print(f\"Percentage of total trades: {(len(unusual_trades)/len(df)*100):.2f}%\")\n",
    "print(f\"Total volume in unusual trades: {unusual_trades['qty'].sum():,}\")\n",
    "print(f\"Percentage of total volume: {(unusual_trades['qty'].sum()/df['qty'].sum()*100):.2f}%\")\n",
    "\n",
    "# Display all unusual trades\n",
    "print(f\"\\n=== ALL UNUSUAL TRADES (TOP 1%) ===\")\n",
    "print(f\"{'Rank':<4} {'Time':<12} {'Price':<8} {'Quantity':<10} {'Turnover':<12} {'Cum Turnover':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, (_, row) in enumerate(unusual_trades.iterrows(), 1):\n",
    "    print(f\"{idx:<4} {row['date'].strftime('%H:%M:%S'):<12} ₹{row['price']:<7.2f} {row['qty']:<10,} ₹{row['trnvr']:<11,.2f} ₹{row['cum_trnvr']:<14,.2f}\")\n",
    "\n",
    "# Detailed analysis of unusual trades\n",
    "print(f\"\\n=== DETAILED ANALYSIS OF UNUSUAL TRADES ===\")\n",
    "\n",
    "# 1. Size distribution of unusual trades\n",
    "print(\"\\n--- SIZE DISTRIBUTION ---\")\n",
    "unusual_trades['size_category'] = unusual_trades['qty'].apply(lambda x: \n",
    "    'Large (1K-5K)' if x <= 5000 else\n",
    "    'Very Large (5K-10K)' if x <= 10000 else\n",
    "    'Huge (10K-50K)' if x <= 50000 else\n",
    "    'Massive (>50K)'\n",
    ")\n",
    "\n",
    "size_distribution = unusual_trades['size_category'].value_counts()\n",
    "print(\"Size distribution of unusual trades:\")\n",
    "for category, count in size_distribution.items():\n",
    "    print(f\"  {category}: {count} trades\")\n",
    "\n",
    "# 2. Time distribution of unusual trades\n",
    "print(f\"\\n--- TIME DISTRIBUTION ---\")\n",
    "unusual_trades['hour'] = unusual_trades['date'].dt.hour\n",
    "hourly_distribution = unusual_trades['hour'].value_counts().sort_index()\n",
    "\n",
    "print(\"Hourly distribution of unusual trades:\")\n",
    "for hour, count in hourly_distribution.items():\n",
    "    print(f\"  {hour:02d}:00-{hour:02d}:59: {count} trades\")\n",
    "\n",
    "# 3. Price analysis of unusual trades\n",
    "print(f\"\\n--- PRICE ANALYSIS ---\")\n",
    "print(f\"Average price of unusual trades: ₹{unusual_trades['price'].mean():.2f}\")\n",
    "print(f\"Price range of unusual trades: ₹{unusual_trades['price'].min():.2f} - ₹{unusual_trades['price'].max():.2f}\")\n",
    "print(f\"Price standard deviation: ₹{unusual_trades['price'].std():.2f}\")\n",
    "\n",
    "# 4. Impact analysis\n",
    "print(f\"\\n--- MARKET IMPACT ANALYSIS ---\")\n",
    "total_volume = df['qty'].sum()\n",
    "total_turnover = df['trnvr'].sum()\n",
    "\n",
    "print(f\"Unusual trades represent:\")\n",
    "print(f\"  Volume: {unusual_trades['qty'].sum():,} / {total_volume:,} = {(unusual_trades['qty'].sum()/total_volume*100):.2f}%\")\n",
    "print(f\"  Turnover: ₹{unusual_trades['trnvr'].sum():,.2f} / ₹{total_turnover:,.2f} = {(unusual_trades['trnvr'].sum()/total_turnover*100):.2f}%\")\n",
    "\n",
    "# 5. Largest single trades\n",
    "print(f\"\\n--- TOP 5 LARGEST SINGLE TRADES ---\")\n",
    "top_5_trades = unusual_trades.head(5)\n",
    "for idx, (_, row) in enumerate(top_5_trades.iterrows(), 1):\n",
    "    print(f\"{idx}. {row['date'].strftime('%H:%M:%S')} - {row['qty']:,} shares at ₹{row['price']:.2f}\")\n",
    "    print(f\"   Turnover: ₹{row['trnvr']:,.2f}\")\n",
    "\n",
    "# 6. Statistical comparison\n",
    "print(f\"\\n--- STATISTICAL COMPARISON ---\")\n",
    "print(\"Unusual trades vs Normal trades:\")\n",
    "print(f\"  Average size: {unusual_trades['qty'].mean():,.0f} vs {df[df['qty'] < unusual_threshold]['qty'].mean():,.0f}\")\n",
    "print(f\"  Median size: {unusual_trades['qty'].median():,.0f} vs {df[df['qty'] < unusual_threshold]['qty'].median():,.0f}\")\n",
    "print(f\"  Size ratio: {unusual_trades['qty'].mean() / df[df['qty'] < unusual_threshold]['qty'].mean():.1f}x larger\")\n",
    "\n",
    "# 7. Clustering analysis\n",
    "print(f\"\\n--- CLUSTERING ANALYSIS ---\")\n",
    "# Check if unusual trades are clustered in time\n",
    "unusual_trades_sorted = unusual_trades.sort_values('date')\n",
    "time_diffs = unusual_trades_sorted['date'].diff().dt.total_seconds() / 60  # in minutes\n",
    "\n",
    "clustered_trades = time_diffs[time_diffs <= 5]  # Within 5 minutes\n",
    "print(f\"Unusual trades within 5 minutes of each other: {len(clustered_trades)}\")\n",
    "print(f\"Clustering percentage: {(len(clustered_trades)/len(unusual_trades)*100):.1f}%\")\n",
    "\n",
    "# 8. Export unusual trades data\n",
    "print(f\"\\n=== EXPORT DATA ===\")\n",
    "print(\"Unusual trades data is available in 'unusual_trades' DataFrame\")\n",
    "print(\"You can export this data for further analysis\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n=== SUMMARY TABLE ===\")\n",
    "summary_data = {\n",
    "    'Metric': ['Count', 'Total Volume', 'Total Turnover', 'Avg Size', 'Largest Trade', 'Time Range'],\n",
    "    'Value': [\n",
    "        len(unusual_trades),\n",
    "        f\"{unusual_trades['qty'].sum():,}\",\n",
    "        f\"₹{unusual_trades['trnvr'].sum():,.2f}\",\n",
    "        f\"{unusual_trades['qty'].mean():,.0f}\",\n",
    "        f\"{unusual_trades['qty'].max():,}\",\n",
    "        f\"{unusual_trades['date'].min().strftime('%H:%M')} - {unusual_trades['date'].max().strftime('%H:%M')}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60bd37ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BIDIRECTIONAL PRICE CHANGES ANALYSIS ===\n",
      "Analyzing price movement directions...\n",
      "=== DIRECTION DISTRIBUTION ===\n",
      "Total price ticks: 10,956\n",
      "No change ticks: 4,441 (40.53%)\n",
      "Down ticks: 3,299 (30.11%)\n",
      "Up ticks: 3,216 (29.35%)\n",
      "\n",
      "Up/Down ratio: 0.975\n",
      "Down ticks are 1.0x more frequent than up ticks\n",
      "\n",
      "=== DIRECTION ANALYSIS BY TIME INTERVALS ===\n",
      "Minute-by-minute direction analysis:\n",
      "Minutes with up bias (>1.2 ratio): 88\n",
      "Minutes with down bias (<0.8 ratio): 103\n",
      "Minutes with neutral bias (0.8-1.2 ratio): ((minute_direction['up_down_ratio'] >= 0.8) & (minute_direction['up_down_ratio'] <= 1.2)).sum()\n",
      "\n",
      "Hourly direction analysis:\n",
      "  09:00-09:59: Up=336, Down=348, Ratio=0.97 (Neutral)\n",
      "  10:00-10:59: Up=467, Down=478, Ratio=0.98 (Neutral)\n",
      "  11:00-11:59: Up=485, Down=538, Ratio=0.90 (Neutral)\n",
      "  12:00-12:59: Up=544, Down=565, Ratio=0.96 (Neutral)\n",
      "  13:00-13:59: Up=455, Down=473, Ratio=0.96 (Neutral)\n",
      "  14:00-14:59: Up=450, Down=428, Ratio=1.05 (Neutral)\n",
      "  15:00-15:59: Up=479, Down=469, Ratio=1.02 (Neutral)\n",
      "\n",
      "=== CONSECUTIVE DIRECTION STREAKS ===\n",
      "Up streaks: 2717\n",
      "Down streaks: 2774\n",
      "Longest up streak: 7 ticks\n",
      "Average up streak: 1.2 ticks\n",
      "Longest down streak: 5 ticks\n",
      "Average down streak: 1.2 ticks\n",
      "\n",
      "=== DIRECTION CHANGE FREQUENCY ===\n",
      "Total direction changes: 7884\n",
      "Average ticks per direction change: 1.4\n",
      "\n",
      "=== PRICE CHANGE MAGNITUDE BY DIRECTION ===\n",
      "Up ticks:\n",
      "  Average change: ₹0.0939\n",
      "  Median change: ₹0.1000\n",
      "  Max change: ₹0.7500\n",
      "Down ticks:\n",
      "  Average change: ₹-0.0911\n",
      "  Median change: ₹-0.0500\n",
      "  Max change: ₹-0.6500\n",
      "\n",
      "=== DIRECTION BIAS SUMMARY ===\n",
      "Overall bias: Downward\n",
      "Up ticks: 3,216 (29.4%)\n",
      "Down ticks: 3,299 (30.1%)\n",
      "No change: 4,441 (40.5%)\n",
      "\n",
      "=== EXPORT DATA ===\n",
      "Direction analysis data is available in:\n",
      "- 'minute_direction': Minute-by-minute direction breakdown\n",
      "- 'hourly_direction': Hourly direction breakdown\n",
      "- 'streaks': List of consecutive direction streaks\n",
      "\n",
      "=== SAMPLE MINUTE DIRECTION DATA (First 10 rows) ===\n",
      "direction            Up  Down  up_down_ratio  total_ticks\n",
      "minute_key                                               \n",
      "2025-08-07 09:15:00  37    47       0.787234          116\n",
      "2025-08-07 09:16:00  33    28       1.178571           94\n",
      "2025-08-07 09:17:00   9     3       3.000000           15\n",
      "2025-08-07 09:18:00   7     4       1.750000           14\n",
      "2025-08-07 09:19:00  25    24       1.041667           96\n",
      "2025-08-07 09:20:00   5     5       1.000000           13\n",
      "2025-08-07 09:21:00  30    30       1.000000           94\n",
      "2025-08-07 09:22:00  34    36       0.944444          105\n",
      "2025-08-07 09:23:00   5     7       0.714286           14\n",
      "2025-08-07 09:24:00   3     8       0.375000           15\n"
     ]
    }
   ],
   "source": [
    "# Compute bidirectional price changes (number of up vs. down ticks)\n",
    "print(\"=== BIDIRECTIONAL PRICE CHANGES ANALYSIS ===\")\n",
    "\n",
    "# Calculate price changes (if not already calculated)\n",
    "if 'price_change' not in df.columns:\n",
    "    df['price_change'] = df['price'].diff()\n",
    "\n",
    "# Create direction column (if not already created)\n",
    "if 'direction' not in df.columns:\n",
    "    df['direction'] = df['price_change'].apply(lambda x: \n",
    "        'Up' if x > 0 else \n",
    "        'Down' if x < 0 else \n",
    "        'No change'\n",
    "    )\n",
    "\n",
    "print(\"Analyzing price movement directions...\")\n",
    "\n",
    "# Count the occurrences of each direction\n",
    "direction_counts = df['direction'].value_counts()\n",
    "total_ticks = len(df)\n",
    "\n",
    "print(f\"=== DIRECTION DISTRIBUTION ===\")\n",
    "print(f\"Total price ticks: {total_ticks:,}\")\n",
    "\n",
    "for direction, count in direction_counts.items():\n",
    "    percentage = (count / total_ticks) * 100\n",
    "    print(f\"{direction} ticks: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "# Calculate up vs down ratio\n",
    "up_ticks = direction_counts.get('Up', 0)\n",
    "down_ticks = direction_counts.get('Down', 0)\n",
    "no_change_ticks = direction_counts.get('No change', 0)\n",
    "\n",
    "if down_ticks > 0:\n",
    "    up_down_ratio = up_ticks / down_ticks\n",
    "    print(f\"\\nUp/Down ratio: {up_down_ratio:.3f}\")\n",
    "    print(f\"Up ticks are {up_down_ratio:.1f}x more frequent than down ticks\" if up_down_ratio > 1 else f\"Down ticks are {1/up_down_ratio:.1f}x more frequent than up ticks\")\n",
    "\n",
    "# Direction analysis by time intervals\n",
    "print(f\"\\n=== DIRECTION ANALYSIS BY TIME INTERVALS ===\")\n",
    "\n",
    "# 1. Minute-by-minute direction analysis\n",
    "df['minute_key'] = df['date'].dt.floor('1min')\n",
    "minute_direction = df.groupby('minute_key')['direction'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Calculate up/down ratio per minute\n",
    "minute_direction['up_down_ratio'] = minute_direction['Up'] / minute_direction['Down'].replace(0, 1)\n",
    "minute_direction['total_ticks'] = minute_direction['Up'] + minute_direction['Down'] + minute_direction.get('No change', 0)\n",
    "\n",
    "print(f\"Minute-by-minute direction analysis:\")\n",
    "print(f\"Minutes with up bias (>1.2 ratio): {(minute_direction['up_down_ratio'] > 1.2).sum()}\")\n",
    "print(f\"Minutes with down bias (<0.8 ratio): {(minute_direction['up_down_ratio'] < 0.8).sum()}\")\n",
    "print(f\"Minutes with neutral bias (0.8-1.2 ratio): ((minute_direction['up_down_ratio'] >= 0.8) & (minute_direction['up_down_ratio'] <= 1.2)).sum()\")\n",
    "\n",
    "# 2. Hourly direction analysis\n",
    "df['hour_key'] = df['date'].dt.hour\n",
    "hourly_direction = df.groupby('hour_key')['direction'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Calculate up/down ratio per hour\n",
    "hourly_direction['up_down_ratio'] = hourly_direction['Up'] / hourly_direction['Down'].replace(0, 1)\n",
    "hourly_direction['total_ticks'] = hourly_direction['Up'] + hourly_direction['Down'] + hourly_direction.get('No change', 0)\n",
    "\n",
    "print(f\"\\nHourly direction analysis:\")\n",
    "for hour in hourly_direction.index:\n",
    "    up_count = hourly_direction.loc[hour, 'Up']\n",
    "    down_count = hourly_direction.loc[hour, 'Down']\n",
    "    ratio = hourly_direction.loc[hour, 'up_down_ratio']\n",
    "    total = hourly_direction.loc[hour, 'total_ticks']\n",
    "    \n",
    "    bias = \"Up\" if ratio > 1.2 else \"Down\" if ratio < 0.8 else \"Neutral\"\n",
    "    print(f\"  {hour:02d}:00-{hour:02d}:59: Up={up_count}, Down={down_count}, Ratio={ratio:.2f} ({bias})\")\n",
    "\n",
    "# 3. Consecutive direction streaks\n",
    "print(f\"\\n=== CONSECUTIVE DIRECTION STREAKS ===\")\n",
    "\n",
    "def find_streaks(directions):\n",
    "    \"\"\"Find consecutive streaks of the same direction\"\"\"\n",
    "    streaks = []\n",
    "    current_streak = 1\n",
    "    current_direction = directions.iloc[0]\n",
    "    \n",
    "    for i in range(1, len(directions)):\n",
    "        if directions.iloc[i] == current_direction:\n",
    "            current_streak += 1\n",
    "        else:\n",
    "            if current_direction != 'No change':  # Only count meaningful streaks\n",
    "                streaks.append((current_direction, current_streak))\n",
    "            current_streak = 1\n",
    "            current_direction = directions.iloc[i]\n",
    "    \n",
    "    # Add the last streak\n",
    "    if current_direction != 'No change':\n",
    "        streaks.append((current_direction, current_streak))\n",
    "    \n",
    "    return streaks\n",
    "\n",
    "# Find streaks in the data\n",
    "streaks = find_streaks(df['direction'])\n",
    "\n",
    "# Analyze streaks\n",
    "up_streaks = [s for s in streaks if s[0] == 'Up']\n",
    "down_streaks = [s for s in streaks if s[0] == 'Down']\n",
    "\n",
    "print(f\"Up streaks: {len(up_streaks)}\")\n",
    "print(f\"Down streaks: {len(down_streaks)}\")\n",
    "\n",
    "if up_streaks:\n",
    "    print(f\"Longest up streak: {max(up_streaks, key=lambda x: x[1])[1]} ticks\")\n",
    "    print(f\"Average up streak: {sum(s[1] for s in up_streaks) / len(up_streaks):.1f} ticks\")\n",
    "\n",
    "if down_streaks:\n",
    "    print(f\"Longest down streak: {max(down_streaks, key=lambda x: x[1])[1]} ticks\")\n",
    "    print(f\"Average down streak: {sum(s[1] for s in down_streaks) / len(down_streaks):.1f} ticks\")\n",
    "\n",
    "# 4. Direction change frequency\n",
    "print(f\"\\n=== DIRECTION CHANGE FREQUENCY ===\")\n",
    "direction_changes = (df['direction'] != df['direction'].shift()).sum()\n",
    "print(f\"Total direction changes: {direction_changes}\")\n",
    "print(f\"Average ticks per direction change: {total_ticks / direction_changes:.1f}\")\n",
    "\n",
    "# 5. Price change magnitude analysis\n",
    "print(f\"\\n=== PRICE CHANGE MAGNITUDE BY DIRECTION ===\")\n",
    "up_changes = df[df['direction'] == 'Up']['price_change']\n",
    "down_changes = df[df['direction'] == 'Down']['price_change']\n",
    "\n",
    "if len(up_changes) > 0:\n",
    "    print(f\"Up ticks:\")\n",
    "    print(f\"  Average change: ₹{up_changes.mean():.4f}\")\n",
    "    print(f\"  Median change: ₹{up_changes.median():.4f}\")\n",
    "    print(f\"  Max change: ₹{up_changes.max():.4f}\")\n",
    "\n",
    "if len(down_changes) > 0:\n",
    "    print(f\"Down ticks:\")\n",
    "    print(f\"  Average change: ₹{down_changes.mean():.4f}\")\n",
    "    print(f\"  Median change: ₹{down_changes.median():.4f}\")\n",
    "    print(f\"  Max change: ₹{down_changes.min():.4f}\")\n",
    "\n",
    "# 6. Direction bias summary\n",
    "print(f\"\\n=== DIRECTION BIAS SUMMARY ===\")\n",
    "print(f\"Overall bias: {'Upward' if up_ticks > down_ticks else 'Downward' if down_ticks > up_ticks else 'Neutral'}\")\n",
    "print(f\"Up ticks: {up_ticks:,} ({up_ticks/total_ticks*100:.1f}%)\")\n",
    "print(f\"Down ticks: {down_ticks:,} ({down_ticks/total_ticks*100:.1f}%)\")\n",
    "print(f\"No change: {no_change_ticks:,} ({no_change_ticks/total_ticks*100:.1f}%)\")\n",
    "\n",
    "# 7. Export direction data\n",
    "print(f\"\\n=== EXPORT DATA ===\")\n",
    "print(\"Direction analysis data is available in:\")\n",
    "print(\"- 'minute_direction': Minute-by-minute direction breakdown\")\n",
    "print(\"- 'hourly_direction': Hourly direction breakdown\")\n",
    "print(\"- 'streaks': List of consecutive direction streaks\")\n",
    "\n",
    "# Display sample of minute direction data\n",
    "print(f\"\\n=== SAMPLE MINUTE DIRECTION DATA (First 10 rows) ===\")\n",
    "print(minute_direction[['Up', 'Down', 'up_down_ratio', 'total_ticks']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64c1421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRICE SPIKE DETECTION ANALYSIS ===\n",
      "Detecting price spikes > 0.5% within 60 seconds...\n",
      "Calculating percentage price changes...\n",
      "Calculating rolling maximum percentage changes...\n",
      "Identifying price spikes...\n",
      "\n",
      "=== SPIKE DETECTION RESULTS ===\n",
      "Simple percentage change spikes: 0\n",
      "Rolling window spikes: 8\n",
      "Window maximum spikes: 58\n",
      "\n",
      "=== ROLLING WINDOW SPIKE ANALYSIS (>0.5% in 60s) ===\n",
      "Top 10 largest rolling window changes:\n",
      "Rank Time         Price    Pct Change   Type  \n",
      "------------------------------------------------------------\n",
      "1    09:16:50     ₹387.75  0.56       % Up    \n",
      "2    09:16:51     ₹387.75  0.54       % Up    \n",
      "3    09:18:23     ₹389.45  0.54       % Up    \n",
      "4    09:16:48     ₹387.60  0.52       % Up    \n",
      "5    09:16:45     ₹387.75  0.52       % Up    \n",
      "6    09:16:44     ₹387.75  0.52       % Up    \n",
      "7    09:16:47     ₹387.60  0.51       % Up    \n",
      "8    09:16:46     ₹387.60  0.51       % Up    \n",
      "\n",
      "=== WINDOW MAXIMUM SPIKE ANALYSIS (>0.5% max in 60s) ===\n",
      "Top 10 largest window maximum changes:\n",
      "Rank Time         Price    Max Pct Change \n",
      "------------------------------------------------------------\n",
      "1    09:16:44     ₹387.75  0.56          %\n",
      "2    09:16:45     ₹387.60  0.56          %\n",
      "3    09:16:45     ₹387.75  0.56          %\n",
      "4    09:16:46     ₹387.60  0.56          %\n",
      "5    09:16:46     ₹387.60  0.56          %\n",
      "6    09:16:47     ₹387.60  0.56          %\n",
      "7    09:16:48     ₹387.60  0.56          %\n",
      "8    09:16:49     ₹387.70  0.56          %\n",
      "9    09:16:49     ₹387.60  0.56          %\n",
      "10   09:16:42     ₹387.70  0.54          %\n",
      "\n",
      "=== TIME-BASED SPIKE ANALYSIS ===\n",
      "\n",
      "=== SPIKE CLUSTERING ANALYSIS ===\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total price ticks analyzed: 10,956\n",
      "Spike threshold: 0.5%\n",
      "Time window: 60 seconds\n",
      "Total spikes detected: 0\n",
      "Spike frequency: 0.00%\n",
      "\n",
      "=== EXPORT DATA ===\n",
      "Spike data is available in:\n",
      "- 'spikes_simple': Simple percentage change spikes\n",
      "- 'spikes_rolling': Rolling window spikes\n",
      "- 'spikes_window': Window maximum spikes\n"
     ]
    }
   ],
   "source": [
    "# Identify spikes in price > X% within Y seconds\n",
    "print(\"=== PRICE SPIKE DETECTION ANALYSIS ===\")\n",
    "\n",
    "# Set parameters for spike detection (you can adjust these values)\n",
    "X_PERCENT = 0.5  # Minimum percentage change to consider as a spike\n",
    "Y_SECONDS = 60   # Time window in seconds to look for spikes\n",
    "\n",
    "print(f\"Detecting price spikes > {X_PERCENT}% within {Y_SECONDS} seconds...\")\n",
    "\n",
    "# Ensure data is sorted by datetime\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Calculate percentage price changes over different time windows\n",
    "print(\"Calculating percentage price changes...\")\n",
    "\n",
    "# Method 1: Rolling percentage change over Y seconds\n",
    "df['price_pct_change'] = df['price'].pct_change() * 100\n",
    "\n",
    "# Method 2: Percentage change from Y seconds ago\n",
    "df['price_pct_change_rolling'] = df['price'].pct_change(periods=Y_SECONDS) * 100\n",
    "\n",
    "# Method 3: Maximum percentage change within rolling Y-second window\n",
    "def max_pct_change_in_window(prices, window_seconds):\n",
    "    \"\"\"Calculate maximum percentage change within a time window\"\"\"\n",
    "    if len(prices) < 2:\n",
    "        return 0\n",
    "    \n",
    "    max_pct_change = 0\n",
    "    for i in range(len(prices)):\n",
    "        for j in range(i+1, min(i+window_seconds+1, len(prices))):\n",
    "            pct_change = abs((prices.iloc[j] - prices.iloc[i]) / prices.iloc[i]) * 100\n",
    "            max_pct_change = max(max_pct_change, pct_change)\n",
    "    \n",
    "    return max_pct_change\n",
    "\n",
    "# Calculate rolling maximum percentage change\n",
    "print(\"Calculating rolling maximum percentage changes...\")\n",
    "df['max_pct_change_window'] = df['price'].rolling(window=Y_SECONDS, min_periods=1).apply(\n",
    "    lambda x: max_pct_change_in_window(x, Y_SECONDS), raw=False\n",
    ")\n",
    "\n",
    "# Identify spikes based on different criteria\n",
    "print(\"Identifying price spikes...\")\n",
    "\n",
    "# Criterion 1: Simple percentage change threshold\n",
    "spikes_simple = df[abs(df['price_pct_change']) > X_PERCENT].copy()\n",
    "spikes_simple['spike_type'] = spikes_simple['price_pct_change'].apply(\n",
    "    lambda x: 'Up' if x > 0 else 'Down'\n",
    ")\n",
    "\n",
    "# Criterion 2: Rolling window percentage change threshold\n",
    "spikes_rolling = df[abs(df['price_pct_change_rolling']) > X_PERCENT].copy()\n",
    "spikes_rolling['spike_type'] = spikes_rolling['price_pct_change_rolling'].apply(\n",
    "    lambda x: 'Up' if x > 0 else 'Down'\n",
    ")\n",
    "\n",
    "# Criterion 3: Maximum percentage change within window threshold\n",
    "spikes_window = df[df['max_pct_change_window'] > X_PERCENT].copy()\n",
    "\n",
    "print(f\"\\n=== SPIKE DETECTION RESULTS ===\")\n",
    "print(f\"Simple percentage change spikes: {len(spikes_simple):,}\")\n",
    "print(f\"Rolling window spikes: {len(spikes_rolling):,}\")\n",
    "print(f\"Window maximum spikes: {len(spikes_window):,}\")\n",
    "\n",
    "# Analyze simple percentage change spikes\n",
    "if len(spikes_simple) > 0:\n",
    "    print(f\"\\n=== SIMPLE PERCENTAGE CHANGE SPIKES (>{X_PERCENT}%) ===\")\n",
    "    \n",
    "    # Group spikes by type\n",
    "    up_spikes = spikes_simple[spikes_simple['spike_type'] == 'Up']\n",
    "    down_spikes = spikes_simple[spikes_simple['spike_type'] == 'Down']\n",
    "    \n",
    "    print(f\"Up spikes: {len(up_spikes):,}\")\n",
    "    print(f\"Down spikes: {len(down_spikes):,}\")\n",
    "    \n",
    "    # Display top spikes\n",
    "    print(f\"\\nTop 10 largest percentage changes:\")\n",
    "    top_spikes = spikes_simple.nlargest(10, 'price_pct_change')\n",
    "    print(f\"{'Rank':<4} {'Time':<12} {'Price':<8} {'Pct Change':<12} {'Type':<6} {'Qty':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_spikes.iterrows(), 1):\n",
    "        print(f\"{idx:<4} {row['date'].strftime('%H:%M:%S'):<12} ₹{row['price']:<7.2f} {row['price_pct_change']:<11.2f}% {row['spike_type']:<6} {row['qty']:<8,}\")\n",
    "\n",
    "# Analyze rolling window spikes\n",
    "if len(spikes_rolling) > 0:\n",
    "    print(f\"\\n=== ROLLING WINDOW SPIKE ANALYSIS (>{X_PERCENT}% in {Y_SECONDS}s) ===\")\n",
    "    \n",
    "    # Find the largest rolling window spikes\n",
    "    largest_rolling_spikes = spikes_rolling.nlargest(10, 'price_pct_change_rolling')\n",
    "    \n",
    "    print(f\"Top 10 largest rolling window changes:\")\n",
    "    print(f\"{'Rank':<4} {'Time':<12} {'Price':<8} {'Pct Change':<12} {'Type':<6}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(largest_rolling_spikes.iterrows(), 1):\n",
    "        print(f\"{idx:<4} {row['date'].strftime('%H:%M:%S'):<12} ₹{row['price']:<7.2f} {row['price_pct_change_rolling']:<11.2f}% {row['spike_type']:<6}\")\n",
    "\n",
    "# Analyze window maximum spikes\n",
    "if len(spikes_window) > 0:\n",
    "    print(f\"\\n=== WINDOW MAXIMUM SPIKE ANALYSIS (>{X_PERCENT}% max in {Y_SECONDS}s) ===\")\n",
    "    \n",
    "    # Find the largest window maximum spikes\n",
    "    largest_window_spikes = spikes_window.nlargest(10, 'max_pct_change_window')\n",
    "    \n",
    "    print(f\"Top 10 largest window maximum changes:\")\n",
    "    print(f\"{'Rank':<4} {'Time':<12} {'Price':<8} {'Max Pct Change':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(largest_window_spikes.iterrows(), 1):\n",
    "        print(f\"{idx:<4} {row['date'].strftime('%H:%M:%S'):<12} ₹{row['price']:<7.2f} {row['max_pct_change_window']:<14.2f}%\")\n",
    "\n",
    "# Time-based spike analysis\n",
    "print(f\"\\n=== TIME-BASED SPIKE ANALYSIS ===\")\n",
    "\n",
    "# Group spikes by hour\n",
    "if len(spikes_simple) > 0:\n",
    "    spikes_simple['hour'] = spikes_simple['date'].dt.hour\n",
    "    hourly_spikes = spikes_simple.groupby('hour').size()\n",
    "    \n",
    "    print(\"Hourly distribution of spikes:\")\n",
    "    for hour, count in hourly_spikes.items():\n",
    "        print(f\"  {hour:02d}:00-{hour:02d}:59: {count} spikes\")\n",
    "\n",
    "# Spike clustering analysis\n",
    "print(f\"\\n=== SPIKE CLUSTERING ANALYSIS ===\")\n",
    "\n",
    "if len(spikes_simple) > 1:\n",
    "    # Check if spikes are clustered in time\n",
    "    spikes_sorted = spikes_simple.sort_values('date')\n",
    "    time_diffs = spikes_sorted['date'].diff().dt.total_seconds()\n",
    "    \n",
    "    clustered_spikes = time_diffs[time_diffs <= 300]  # Within 5 minutes\n",
    "    print(f\"Spikes within 5 minutes of each other: {len(clustered_spikes)}\")\n",
    "    print(f\"Clustering percentage: {(len(clustered_spikes)/len(spikes_simple)*100):.1f}%\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Total price ticks analyzed: {len(df):,}\")\n",
    "print(f\"Spike threshold: {X_PERCENT}%\")\n",
    "print(f\"Time window: {Y_SECONDS} seconds\")\n",
    "print(f\"Total spikes detected: {len(spikes_simple):,}\")\n",
    "print(f\"Spike frequency: {len(spikes_simple)/len(df)*100:.2f}%\")\n",
    "\n",
    "if len(spikes_simple) > 0:\n",
    "    print(f\"Largest spike: {spikes_simple['price_pct_change'].max():.2f}%\")\n",
    "    print(f\"Average spike magnitude: {spikes_simple['price_pct_change'].abs().mean():.2f}%\")\n",
    "\n",
    "# Export spike data\n",
    "print(f\"\\n=== EXPORT DATA ===\")\n",
    "print(\"Spike data is available in:\")\n",
    "print(\"- 'spikes_simple': Simple percentage change spikes\")\n",
    "print(\"- 'spikes_rolling': Rolling window spikes\")\n",
    "print(\"- 'spikes_window': Window maximum spikes\")\n",
    "\n",
    "# Display sample of spike data\n",
    "if len(spikes_simple) > 0:\n",
    "    print(f\"\\n=== SAMPLE SPIKE DATA (First 5 rows) ===\")\n",
    "    sample_spikes = spikes_simple[['date', 'price', 'price_pct_change', 'spike_type', 'qty']].head(5)\n",
    "    print(sample_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed20f3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VOLUME BURST DETECTION ANALYSIS ===\n",
      "Detecting volume bursts where qty > 3.0× rolling average...\n",
      "Rolling average window: 20 trades\n",
      "Calculating rolling average of quantity...\n",
      "\n",
      "=== VOLUME BURST DETECTION RESULTS ===\n",
      "Total volume bursts detected: 1,008\n",
      "Percentage of total trades: 9.20%\n",
      "Total volume in bursts: 6,070,933\n",
      "Percentage of total volume: 52.74%\n",
      "Total turnover in bursts: ₹2,347,871,874.70\n",
      "Percentage of total turnover: 52.74%\n",
      "\n",
      "=== ALL VOLUME BURSTS (>3.0× rolling average) ===\n",
      "Rank Time         Price    Quantity   Rolling Avg  Multiple   Turnover    \n",
      "------------------------------------------------------------------------------------------\n",
      "1    15:01:57     ₹387.05  153,858    7,855       19.6     x ₹59,550,738.90\n",
      "2    09:20:41     ₹389.30  67,256     7,164       9.4      x ₹26,182,760.80\n",
      "3    12:08:06     ₹385.05  60,580     4,271       14.2     x ₹23,326,329.00\n",
      "4    12:08:12     ₹384.80  55,402     6,283       8.8      x ₹21,318,689.60\n",
      "5    14:40:45     ₹385.95  54,602     4,607       11.9     x ₹21,073,641.90\n",
      "6    09:20:49     ₹389.85  43,873     9,139       4.8      x ₹17,103,889.05\n",
      "7    14:45:21     ₹386.40  43,199     4,368       9.9      x ₹16,692,093.60\n",
      "8    15:07:53     ₹387.80  42,697     2,336       18.3     x ₹16,557,896.60\n",
      "9    14:05:06     ₹385.15  40,953     2,565       16.0     x ₹15,773,047.95\n",
      "10   14:45:12     ₹386.05  40,000     3,448       11.6     x ₹15,442,000.00\n",
      "11   15:28:54     ₹388.25  38,001     3,774       10.1     x ₹14,753,888.25\n",
      "12   10:40:13     ₹388.05  36,352     4,110       8.8      x ₹14,106,393.60\n",
      "13   10:30:25     ₹388.15  35,050     4,460       7.9      x ₹13,604,657.50\n",
      "14   14:16:13     ₹385.80  33,636     2,864       11.7     x ₹12,976,768.80\n",
      "15   09:21:01     ₹389.65  33,563     10,821      3.1      x ₹13,077,822.95\n",
      "16   14:59:34     ₹387.00  33,376     2,577       13.0     x ₹12,916,512.00\n",
      "17   10:46:23     ₹387.60  33,297     2,723       12.2     x ₹12,905,917.20\n",
      "18   12:43:06     ₹384.70  32,819     2,866       11.5     x ₹12,625,469.30\n",
      "19   14:39:07     ₹386.05  32,811     1,687       19.4     x ₹12,666,686.55\n",
      "20   10:17:48     ₹388.85  32,072     1,986       16.1     x ₹12,471,197.20\n",
      "21   09:18:14     ₹389.00  31,428     8,636       3.6      x ₹12,225,492.00\n",
      "22   11:02:02     ₹387.00  30,882     4,990       6.2      x ₹11,951,334.00\n",
      "23   14:20:20     ₹386.30  30,597     2,236       13.7     x ₹11,819,621.10\n",
      "24   12:17:06     ₹386.40  30,424     3,124       9.7      x ₹11,755,833.60\n",
      "25   14:37:29     ₹386.25  30,288     3,439       8.8      x ₹11,698,740.00\n",
      "26   09:58:30     ₹387.80  27,948     2,613       10.7     x ₹10,838,234.40\n",
      "27   15:20:26     ₹387.85  27,894     3,025       9.2      x ₹10,818,687.90\n",
      "28   10:40:08     ₹388.15  27,344     2,206       12.4     x ₹10,613,573.60\n",
      "29   14:22:17     ₹386.40  27,002     4,688       5.8      x ₹10,433,572.80\n",
      "30   13:50:34     ₹385.00  26,669     2,161       12.3     x ₹10,267,565.00\n",
      "31   14:11:39     ₹385.40  26,355     1,598       16.5     x ₹10,157,217.00\n",
      "32   14:44:40     ₹386.40  26,299     5,055       5.2      x ₹10,161,933.60\n",
      "33   14:44:51     ₹386.10  26,203     6,333       4.1      x ₹10,116,978.30\n",
      "34   11:25:31     ₹386.60  26,173     3,724       7.0      x ₹10,118,481.80\n",
      "35   14:22:05     ₹386.30  26,151     3,141       8.3      x ₹10,102,131.30\n",
      "36   14:44:34     ₹386.40  26,130     3,769       6.9      x ₹10,096,632.00\n",
      "37   14:37:57     ₹386.15  25,744     3,669       7.0      x ₹9,941,045.60\n",
      "38   12:42:49     ₹385.00  25,415     1,891       13.4     x ₹9,784,775.00\n",
      "39   14:45:00     ₹386.45  25,183     7,549       3.3      x ₹9,731,970.35\n",
      "40   13:14:20     ₹384.20  23,941     1,614       14.8     x ₹9,198,132.20\n",
      "41   11:37:01     ₹385.95  23,354     2,794       8.4      x ₹9,013,476.30\n",
      "42   14:22:29     ₹386.30  23,279     5,998       3.9      x ₹8,992,677.70\n",
      "43   11:02:00     ₹387.00  23,213     3,947       5.9      x ₹8,983,431.00\n",
      "44   09:26:58     ₹389.00  23,182     3,960       5.9      x ₹9,017,798.00\n",
      "45   14:25:38     ₹385.10  22,639     4,033       5.6      x ₹8,718,278.90\n",
      "46   11:36:34     ₹386.25  22,282     2,045       10.9     x ₹8,606,422.50\n",
      "47   09:56:35     ₹388.40  22,027     1,816       12.1     x ₹8,555,286.80\n",
      "48   09:17:24     ₹387.95  21,993     5,267       4.2      x ₹8,532,184.35\n",
      "49   11:16:56     ₹387.70  21,846     1,520       14.4     x ₹8,469,694.20\n",
      "50   15:00:04     ₹387.35  21,410     3,717       5.8      x ₹8,293,163.50\n",
      "51   14:51:34     ₹386.80  21,144     2,939       7.2      x ₹8,178,499.20\n",
      "52   10:31:53     ₹387.90  20,921     1,157       18.1     x ₹8,115,255.90\n",
      "53   15:11:00     ₹387.30  20,741     1,236       16.8     x ₹8,032,989.30\n",
      "54   15:17:56     ₹388.05  20,717     1,962       10.6     x ₹8,039,231.85\n",
      "55   11:53:29     ₹385.75  20,234     1,163       17.4     x ₹7,805,265.50\n",
      "56   14:21:48     ₹386.25  20,163     1,708       11.8     x ₹7,787,958.75\n",
      "57   14:24:21     ₹385.65  20,101     2,325       8.6      x ₹7,751,950.65\n",
      "58   09:17:16     ₹387.60  19,892     3,969       5.0      x ₹7,710,139.20\n",
      "59   13:14:51     ₹384.25  19,589     2,756       7.1      x ₹7,527,073.25\n",
      "60   09:20:33     ₹389.15  19,580     4,610       4.2      x ₹7,619,557.00\n",
      "61   12:17:01     ₹386.20  19,316     1,635       11.8     x ₹7,459,839.20\n",
      "62   10:42:01     ₹387.75  19,202     1,230       15.6     x ₹7,445,575.50\n",
      "63   13:50:39     ₹385.00  19,158     3,036       6.3      x ₹7,375,830.00\n",
      "64   09:35:41     ₹389.05  18,202     2,754       6.6      x ₹7,081,488.10\n",
      "65   15:20:33     ₹387.95  17,827     3,778       4.7      x ₹6,915,984.65\n",
      "66   09:17:08     ₹387.60  17,699     2,739       6.5      x ₹6,860,132.40\n",
      "67   13:51:13     ₹384.90  17,620     4,000       4.4      x ₹6,781,938.00\n",
      "68   14:44:17     ₹386.60  17,509     2,303       7.6      x ₹6,768,979.40\n",
      "69   09:59:02     ₹388.40  17,444     2,935       5.9      x ₹6,775,249.60\n",
      "70   13:44:32     ₹384.70  17,128     4,343       3.9      x ₹6,589,141.60\n",
      "71   10:00:55     ₹388.50  17,077     912         18.7     x ₹6,634,414.50\n",
      "72   10:46:29     ₹387.60  16,834     3,571       4.7      x ₹6,524,858.40\n",
      "73   11:24:44     ₹386.95  16,834     1,527       11.0     x ₹6,513,916.30\n",
      "74   15:06:51     ₹387.80  16,797     2,883       5.8      x ₹6,513,876.60\n",
      "75   09:29:38     ₹388.45  16,750     2,533       6.6      x ₹6,506,537.50\n",
      "76   12:50:39     ₹385.00  16,428     1,243       13.2     x ₹6,324,780.00\n",
      "77   09:19:53     ₹389.10  16,221     1,056       15.4     x ₹6,311,591.10\n",
      "78   09:27:28     ₹388.90  16,043     4,203       3.8      x ₹6,239,122.70\n",
      "79   14:30:12     ₹385.95  16,005     1,980       8.1      x ₹6,177,129.75\n",
      "80   09:16:59     ₹387.60  15,914     1,625       9.8      x ₹6,168,266.40\n",
      "81   10:42:49     ₹387.75  15,621     3,010       5.2      x ₹6,057,042.75\n",
      "82   13:19:34     ₹384.05  15,619     1,734       9.0      x ₹5,998,476.95\n",
      "83   09:40:36     ₹389.70  15,553     3,140       5.0      x ₹6,061,004.10\n",
      "84   09:20:17     ₹389.15  15,248     2,993       5.1      x ₹5,933,759.20\n",
      "85   09:26:13     ₹388.95  15,248     3,961       3.8      x ₹5,930,709.60\n",
      "86   13:48:36     ₹384.95  15,221     1,358       11.2     x ₹5,859,323.95\n",
      "87   09:25:27     ₹388.95  15,181     3,362       4.5      x ₹5,904,649.95\n",
      "88   13:22:46     ₹384.00  15,113     2,048       7.4      x ₹5,803,392.00\n",
      "89   13:25:30     ₹383.85  15,037     1,628       9.2      x ₹5,771,952.45\n",
      "90   14:36:14     ₹386.30  15,007     1,414       10.6     x ₹5,797,204.10\n",
      "91   10:43:51     ₹387.70  14,884     1,310       11.4     x ₹5,770,526.80\n",
      "92   12:42:50     ₹385.00  14,745     2,630       5.6      x ₹5,676,825.00\n",
      "93   13:44:28     ₹385.15  14,711     3,489       4.2      x ₹5,665,941.65\n",
      "94   09:23:56     ₹389.15  14,702     2,652       5.5      x ₹5,721,283.30\n",
      "95   09:59:08     ₹388.35  14,633     3,595       4.1      x ₹5,682,725.55\n",
      "96   14:16:03     ₹385.60  14,558     1,142       12.8     x ₹5,613,564.80\n",
      "97   12:07:24     ₹385.15  14,322     1,309       10.9     x ₹5,516,118.30\n",
      "98   09:21:55     ₹389.90  14,224     1,398       10.2     x ₹5,545,937.60\n",
      "99   09:23:33     ₹389.45  14,076     1,681       8.4      x ₹5,481,898.20\n",
      "100  13:10:28     ₹384.35  14,025     847         16.6     x ₹5,390,508.75\n",
      "101  10:57:08     ₹388.25  13,895     1,144       12.1     x ₹5,394,733.75\n",
      "102  14:55:56     ₹386.35  13,806     4,199       3.3      x ₹5,333,948.10\n",
      "103  10:06:59     ₹388.35  13,672     1,596       8.6      x ₹5,309,521.20\n",
      "104  12:33:53     ₹384.80  13,655     1,852       7.4      x ₹5,254,444.00\n",
      "105  09:24:03     ₹389.00  13,631     3,331       4.1      x ₹5,302,459.00\n",
      "106  11:42:28     ₹386.70  13,622     1,290       10.6     x ₹5,267,627.40\n",
      "107  12:09:30     ₹384.90  13,559     848         16.0     x ₹5,218,859.10\n",
      "108  14:40:40     ₹386.00  13,481     1,879       7.2      x ₹5,203,666.00\n",
      "109  14:34:18     ₹386.20  13,446     1,612       8.3      x ₹5,192,845.20\n",
      "110  15:05:03     ₹387.50  13,419     3,266       4.1      x ₹5,199,862.50\n",
      "111  09:20:25     ₹388.95  13,139     3,649       3.6      x ₹5,110,414.05\n",
      "112  15:16:32     ₹387.50  13,108     3,569       3.7      x ₹5,079,350.00\n",
      "113  11:08:21     ₹387.10  13,062     815         16.0     x ₹5,056,300.20\n",
      "114  11:01:05     ₹387.85  12,836     1,102       11.6     x ₹4,978,442.60\n",
      "115  15:25:19     ₹388.50  12,651     1,001       12.6     x ₹4,914,913.50\n",
      "116  09:16:01     ₹385.85  12,594     1,115       11.3     x ₹4,859,394.90\n",
      "117  12:17:11     ₹386.45  12,545     3,604       3.5      x ₹4,848,015.25\n",
      "118  10:44:20     ₹387.95  12,500     2,332       5.4      x ₹4,849,375.00\n",
      "119  15:16:25     ₹387.60  12,304     3,091       4.0      x ₹4,769,030.40\n",
      "120  13:23:02     ₹383.70  12,191     2,484       4.9      x ₹4,677,686.70\n",
      "121  09:16:20     ₹387.15  11,997     3,402       3.5      x ₹4,644,638.55\n",
      "122  11:56:11     ₹385.90  11,988     1,648       7.3      x ₹4,626,169.20\n",
      "123  15:10:12     ₹387.45  11,589     1,672       6.9      x ₹4,490,158.05\n",
      "124  09:36:23     ₹388.90  11,564     3,101       3.7      x ₹4,497,239.60\n",
      "125  10:33:07     ₹388.15  11,550     1,319       8.8      x ₹4,483,132.50\n",
      "126  11:01:16     ₹387.40  11,511     2,006       5.7      x ₹4,459,361.40\n",
      "127  09:40:08     ₹389.50  11,438     2,402       4.8      x ₹4,455,101.00\n",
      "128  13:56:10     ₹384.60  11,382     851         13.4     x ₹4,377,517.20\n",
      "129  11:44:34     ₹385.70  11,356     1,262       9.0      x ₹4,380,009.20\n",
      "130  13:46:41     ₹385.00  11,293     1,529       7.4      x ₹4,347,805.00\n",
      "131  14:53:47     ₹386.70  11,287     1,254       9.0      x ₹4,364,682.90\n",
      "132  09:20:08     ₹388.95  11,223     1,888       5.9      x ₹4,365,185.85\n",
      "133  11:33:12     ₹386.25  11,193     1,687       6.6      x ₹4,323,296.25\n",
      "134  09:19:13     ₹389.00  11,085     1,264       8.8      x ₹4,312,065.00\n",
      "135  14:52:38     ₹386.70  11,040     1,191       9.3      x ₹4,269,168.00\n",
      "136  11:56:06     ₹385.60  11,016     1,076       10.2     x ₹4,247,769.60\n",
      "137  14:55:27     ₹386.70  11,005     3,548       3.1      x ₹4,255,633.50\n",
      "138  09:38:19     ₹389.20  10,984     1,702       6.5      x ₹4,274,972.80\n",
      "139  13:00:12     ₹385.55  10,946     1,628       6.7      x ₹4,220,230.30\n",
      "140  15:04:08     ₹387.60  10,944     2,025       5.4      x ₹4,241,894.40\n",
      "141  11:52:47     ₹385.75  10,923     2,079       5.3      x ₹4,213,547.25\n",
      "142  13:19:40     ₹384.30  10,821     2,627       4.1      x ₹4,158,510.30\n",
      "143  11:01:21     ₹387.25  10,750     2,550       4.2      x ₹4,162,937.50\n",
      "144  10:30:18     ₹388.40  10,715     2,392       4.5      x ₹4,161,706.00\n",
      "145  14:55:21     ₹386.85  10,670     3,111       3.4      x ₹4,127,689.50\n",
      "146  14:05:17     ₹385.10  10,651     3,084       3.5      x ₹4,101,700.10\n",
      "147  10:53:35     ₹388.00  10,607     1,636       6.5      x ₹4,115,516.00\n",
      "148  12:42:24     ₹385.05  10,550     788         13.4     x ₹4,062,277.50\n",
      "149  15:05:53     ₹387.75  10,407     2,914       3.6      x ₹4,035,314.25\n",
      "150  13:21:48     ₹384.00  10,406     1,131       9.2      x ₹3,995,904.00\n",
      "151  09:16:52     ₹387.60  10,239     1,432       7.1      x ₹3,968,636.40\n",
      "152  11:01:11     ₹387.50  10,178     1,536       6.6      x ₹3,943,975.00\n",
      "153  14:25:09     ₹385.15  10,167     2,808       3.6      x ₹3,915,820.05\n",
      "154  15:14:05     ₹387.70  10,041     1,805       5.6      x ₹3,892,895.70\n",
      "155  13:58:46     ₹384.80  9,988      1,096       9.1      x ₹3,843,382.40\n",
      "156  12:11:15     ₹385.70  9,910      586         16.9     x ₹3,822,287.00\n",
      "157  10:30:01     ₹388.30  9,891      933         10.6     x ₹3,840,675.30\n",
      "158  13:41:38     ₹384.30  9,882      1,319       7.5      x ₹3,797,652.60\n",
      "159  11:49:34     ₹386.10  9,860      1,213       8.1      x ₹3,806,946.00\n",
      "160  14:55:08     ₹387.00  9,852      2,969       3.3      x ₹3,812,724.00\n",
      "161  13:09:43     ₹384.70  9,835      1,457       6.7      x ₹3,783,524.50\n",
      "162  15:05:41     ₹387.80  9,734      2,620       3.7      x ₹3,774,845.20\n",
      "163  09:33:09     ₹389.25  9,714      2,501       3.9      x ₹3,781,174.50\n",
      "164  12:33:05     ₹385.00  9,656      1,183       8.2      x ₹3,717,560.00\n",
      "165  11:58:34     ₹385.75  9,627      1,047       9.2      x ₹3,713,615.25\n",
      "166  14:54:40     ₹386.70  9,500      2,562       3.7      x ₹3,673,650.00\n",
      "167  13:21:54     ₹384.05  9,395      1,558       6.0      x ₹3,608,149.75\n",
      "168  12:48:09     ₹384.85  9,354      602         15.5     x ₹3,599,886.90\n",
      "169  09:29:45     ₹388.40  9,251      2,895       3.2      x ₹3,593,088.40\n",
      "170  15:04:00     ₹387.50  9,213      1,322       7.0      x ₹3,570,037.50\n",
      "171  11:44:59     ₹386.05  9,158      2,071       4.4      x ₹3,535,445.90\n",
      "172  12:58:32     ₹385.35  9,100      757         12.0     x ₹3,506,685.00\n",
      "173  09:53:58     ₹389.00  9,043      969         9.3      x ₹3,517,727.00\n",
      "174  14:44:05     ₹386.45  8,980      1,491       6.0      x ₹3,470,321.00\n",
      "175  13:30:56     ₹384.10  8,863      1,224       7.2      x ₹3,404,278.30\n",
      "176  11:07:02     ₹386.95  8,827      2,519       3.5      x ₹3,415,607.65\n",
      "177  15:27:34     ₹388.25  8,633      940         9.2      x ₹3,351,762.25\n",
      "178  09:57:41     ₹388.15  8,627      2,550       3.4      x ₹3,348,570.05\n",
      "179  12:43:53     ₹384.70  8,585      974         8.8      x ₹3,302,649.50\n",
      "180  09:52:19     ₹389.00  8,533      899         9.5      x ₹3,319,337.00\n",
      "181  09:42:18     ₹389.00  8,454      1,578       5.4      x ₹3,288,606.00\n",
      "182  11:25:04     ₹386.70  8,292      1,895       4.4      x ₹3,206,516.40\n",
      "183  15:21:59     ₹388.40  8,280      1,670       5.0      x ₹3,215,952.00\n",
      "184  09:20:09     ₹389.05  8,265      2,238       3.7      x ₹3,215,498.25\n",
      "185  11:30:59     ₹386.55  8,252      920         9.0      x ₹3,189,810.60\n",
      "186  15:22:43     ₹388.65  8,236      700         11.8     x ₹3,200,921.40\n",
      "187  13:05:27     ₹385.05  8,229      1,205       6.8      x ₹3,168,576.45\n",
      "188  13:25:27     ₹383.65  8,217      878         9.4      x ₹3,152,452.05\n",
      "189  13:46:27     ₹385.10  8,118      685         11.8     x ₹3,126,241.80\n",
      "190  11:45:09     ₹385.85  8,100      2,639       3.1      x ₹3,125,385.00\n",
      "191  09:37:45     ₹388.90  8,091      933         8.7      x ₹3,146,589.90\n",
      "192  09:46:53     ₹389.20  8,074      1,333       6.1      x ₹3,142,400.80\n",
      "193  14:39:36     ₹386.00  8,043      2,574       3.1      x ₹3,104,598.00\n",
      "194  12:46:24     ₹384.90  8,026      2,317       3.5      x ₹3,089,207.40\n",
      "195  09:50:36     ₹388.75  8,014      1,686       4.8      x ₹3,115,442.50\n",
      "196  14:13:32     ₹385.20  8,014      1,277       6.3      x ₹3,086,992.80\n",
      "197  09:16:10     ₹385.60  8,001      2,461       3.3      x ₹3,085,185.60\n",
      "198  13:22:20     ₹384.00  7,966      1,922       4.1      x ₹3,058,944.00\n",
      "199  09:54:23     ₹388.75  7,959      1,439       5.5      x ₹3,094,061.25\n",
      "200  12:01:22     ₹385.50  7,939      832         9.5      x ₹3,060,484.50\n",
      "201  13:02:51     ₹385.30  7,915      1,568       5.0      x ₹3,049,649.50\n",
      "202  13:40:24     ₹384.05  7,906      759         10.4     x ₹3,036,299.30\n",
      "203  13:38:54     ₹383.60  7,898      1,074       7.4      x ₹3,029,672.80\n",
      "204  11:29:02     ₹386.75  7,898      989         8.0      x ₹3,054,551.50\n",
      "205  13:44:21     ₹385.10  7,888      2,155       3.7      x ₹3,037,668.80\n",
      "206  12:04:27     ₹385.65  7,877      1,332       5.9      x ₹3,037,765.05\n",
      "207  13:19:35     ₹384.10  7,863      2,100       3.7      x ₹3,020,178.30\n",
      "208  13:39:27     ₹383.70  7,819      1,549       5.0      x ₹3,000,150.30\n",
      "209  12:46:00     ₹384.45  7,813      1,288       6.1      x ₹3,003,707.85\n",
      "210  15:15:07     ₹387.60  7,813      2,571       3.0      x ₹3,028,318.80\n",
      "211  12:12:55     ₹386.20  7,811      1,370       5.7      x ₹3,016,608.20\n",
      "212  13:40:45     ₹384.05  7,804      1,169       6.7      x ₹2,997,126.20\n",
      "213  14:12:09     ₹385.65  7,767      1,992       3.9      x ₹2,995,343.55\n",
      "214  13:44:23     ₹385.10  7,705      2,535       3.0      x ₹2,967,195.50\n",
      "215  10:52:43     ₹387.90  7,635      708         10.8     x ₹2,961,616.50\n",
      "216  10:52:49     ₹388.05  7,608      1,038       7.3      x ₹2,952,284.40\n",
      "217  09:15:20     ₹386.45  7,531      2,388       3.2      x ₹2,910,354.95\n",
      "218  09:48:10     ₹389.10  7,527      1,705       4.4      x ₹2,928,755.70\n",
      "219  10:15:58     ₹388.30  7,516      684         11.0     x ₹2,918,462.80\n",
      "220  13:19:18     ₹384.15  7,512      958         7.8      x ₹2,885,734.80\n",
      "221  13:33:39     ₹384.00  7,475      1,289       5.8      x ₹2,870,400.00\n",
      "222  11:25:10     ₹386.70  7,448      2,425       3.1      x ₹2,880,141.60\n",
      "223  13:31:57     ₹384.15  7,443      1,080       6.9      x ₹2,859,228.45\n",
      "224  14:51:01     ₹386.80  7,396      2,193       3.4      x ₹2,860,772.80\n",
      "225  09:15:40     ₹386.10  7,356      966         7.6      x ₹2,840,151.60\n",
      "226  10:28:25     ₹388.45  7,300      1,078       6.8      x ₹2,835,685.00\n",
      "227  09:19:27     ₹389.15  7,259      783         9.3      x ₹2,824,839.85\n",
      "228  15:21:58     ₹388.45  7,231      1,318       5.5      x ₹2,808,881.95\n",
      "229  09:47:31     ₹389.05  7,227      1,719       4.2      x ₹2,811,664.35\n",
      "230  12:42:48     ₹385.00  7,169      1,089       6.6      x ₹2,760,065.00\n",
      "231  11:26:21     ₹386.70  7,151      777         9.2      x ₹2,765,291.70\n",
      "232  12:28:38     ₹385.30  7,139      1,094       6.5      x ₹2,750,656.70\n",
      "233  12:59:47     ₹385.30  7,134      827         8.6      x ₹2,748,730.20\n",
      "234  10:32:56     ₹388.10  7,122      724         9.8      x ₹2,764,048.20\n",
      "235  10:48:09     ₹387.75  7,043      441         16.0     x ₹2,730,923.25\n",
      "236  10:02:10     ₹388.50  7,005      887         7.9      x ₹2,721,442.50\n",
      "237  13:44:05     ₹384.75  7,001      918         7.6      x ₹2,693,634.75\n",
      "238  14:13:03     ₹385.60  6,974      1,968       3.5      x ₹2,689,174.40\n",
      "239  12:38:28     ₹385.00  6,935      753         9.2      x ₹2,669,975.00\n",
      "240  14:43:54     ₹386.25  6,918      997         6.9      x ₹2,672,077.50\n",
      "241  11:23:28     ₹387.10  6,914      982         7.0      x ₹2,676,409.40\n",
      "242  09:16:07     ₹385.65  6,911      2,112       3.3      x ₹2,665,227.15\n",
      "243  14:54:11     ₹386.75  6,838      1,719       4.0      x ₹2,644,596.50\n",
      "244  12:39:22     ₹385.00  6,823      2,011       3.4      x ₹2,626,855.00\n",
      "245  09:38:59     ₹389.40  6,800      2,235       3.0      x ₹2,647,920.00\n",
      "246  12:55:49     ₹385.10  6,793      1,019       6.7      x ₹2,615,984.30\n",
      "247  10:42:11     ₹387.80  6,781      2,007       3.4      x ₹2,629,671.80\n",
      "248  12:08:37     ₹384.75  6,709      988         6.8      x ₹2,581,287.75\n",
      "249  14:31:20     ₹385.85  6,706      718         9.3      x ₹2,587,510.10\n",
      "250  14:30:06     ₹385.70  6,700      1,201       5.6      x ₹2,584,190.00\n",
      "251  11:48:08     ₹386.15  6,674      591         11.3     x ₹2,577,165.10\n",
      "252  10:36:20     ₹388.20  6,651      580         11.5     x ₹2,581,918.20\n",
      "253  13:44:15     ₹385.00  6,638      1,481       4.5      x ₹2,555,630.00\n",
      "254  09:15:25     ₹386.35  6,598      1,904       3.5      x ₹2,549,137.30\n",
      "255  11:31:44     ₹386.45  6,598      1,371       4.8      x ₹2,549,797.10\n",
      "256  11:35:33     ₹386.55  6,585      777         8.5      x ₹2,545,431.75\n",
      "257  15:10:02     ₹387.50  6,571      883         7.4      x ₹2,546,262.50\n",
      "258  14:29:26     ₹385.60  6,552      1,387       4.7      x ₹2,526,451.20\n",
      "259  09:40:01     ₹389.40  6,533      1,900       3.4      x ₹2,543,950.20\n",
      "260  12:41:52     ₹385.05  6,525      1,732       3.8      x ₹2,512,451.25\n",
      "261  14:52:21     ₹386.80  6,489      1,956       3.3      x ₹2,509,945.20\n",
      "262  09:21:21     ₹389.55  6,488      1,204       5.4      x ₹2,527,400.40\n",
      "263  14:47:08     ₹386.85  6,455      737         8.8      x ₹2,497,116.75\n",
      "264  10:30:06     ₹388.20  6,454      1,325       4.9      x ₹2,505,442.80\n",
      "265  10:43:49     ₹387.90  6,403      717         8.9      x ₹2,483,723.70\n",
      "266  09:50:04     ₹388.75  6,400      1,369       4.7      x ₹2,488,000.00\n",
      "267  09:38:52     ₹389.40  6,400      1,958       3.3      x ₹2,492,160.00\n",
      "268  09:17:00     ₹387.60  6,377      1,892       3.4      x ₹2,471,725.20\n",
      "269  10:11:40     ₹388.40  6,374      1,158       5.5      x ₹2,475,661.60\n",
      "270  12:50:44     ₹385.20  6,367      1,561       4.1      x ₹2,452,568.40\n",
      "271  14:34:12     ₹385.90  6,362      951         6.7      x ₹2,455,095.80\n",
      "272  10:09:09     ₹388.20  6,359      1,040       6.1      x ₹2,468,563.80\n",
      "273  09:15:40     ₹386.00  6,357      598         10.6     x ₹2,453,802.00\n",
      "274  15:24:19     ₹388.55  6,349      698         9.1      x ₹2,466,903.95\n",
      "275  10:05:28     ₹388.50  6,326      1,217       5.2      x ₹2,457,651.00\n",
      "276  14:50:59     ₹386.50  6,309      1,827       3.5      x ₹2,438,428.50\n",
      "277  15:28:07     ₹388.30  6,283      749         8.4      x ₹2,439,688.90\n",
      "278  14:31:32     ₹386.05  6,271      1,067       5.9      x ₹2,420,919.55\n",
      "279  12:41:09     ₹385.05  6,265      1,396       4.5      x ₹2,412,338.25\n",
      "280  11:30:13     ₹386.55  6,235      1,248       5.0      x ₹2,410,139.25\n",
      "281  13:44:17     ₹385.10  6,222      1,773       3.5      x ₹2,396,092.20\n",
      "282  14:54:17     ₹386.80  6,213      2,025       3.1      x ₹2,403,188.40\n",
      "283  14:50:53     ₹386.50  6,191      1,429       4.3      x ₹2,392,821.50\n",
      "284  13:00:17     ₹385.60  6,170      1,937       3.2      x ₹2,379,152.00\n",
      "285  13:28:03     ₹383.75  6,168      917         6.7      x ₹2,366,970.00\n",
      "286  10:20:28     ₹389.15  6,161      930         6.6      x ₹2,397,553.15\n",
      "287  12:38:33     ₹385.00  6,150      1,056       5.8      x ₹2,367,750.00\n",
      "288  10:36:28     ₹388.45  6,129      1,004       6.1      x ₹2,380,810.05\n",
      "289  15:20:12     ₹387.80  6,118      1,394       4.4      x ₹2,372,560.40\n",
      "290  10:43:54     ₹387.85  6,109      1,621       3.8      x ₹2,369,375.65\n",
      "291  14:51:28     ₹386.85  6,071      1,936       3.1      x ₹2,348,566.35\n",
      "292  11:33:17     ₹386.40  6,047      1,987       3.0      x ₹2,336,560.80\n",
      "293  13:31:21     ₹384.25  6,024      1,535       3.9      x ₹2,314,722.00\n",
      "294  09:16:36     ₹387.45  6,024      1,154       5.2      x ₹2,333,998.80\n",
      "295  10:14:16     ₹388.55  6,022      799         7.5      x ₹2,339,848.10\n",
      "296  11:28:57     ₹386.85  5,998      594         10.1     x ₹2,320,326.30\n",
      "297  12:07:42     ₹385.20  5,983      1,653       3.6      x ₹2,304,651.60\n",
      "298  13:57:13     ₹384.75  5,974      1,537       3.9      x ₹2,298,496.50\n",
      "299  14:07:55     ₹385.35  5,967      988         6.0      x ₹2,299,383.45\n",
      "300  11:26:23     ₹386.70  5,962      1,013       5.9      x ₹2,305,505.40\n",
      "301  14:13:06     ₹385.50  5,953      1,878       3.2      x ₹2,294,881.50\n",
      "302  13:33:34     ₹383.75  5,936      890         6.7      x ₹2,277,940.00\n",
      "303  14:38:25     ₹386.00  5,927      471         12.6     x ₹2,287,822.00\n",
      "304  15:03:51     ₹387.40  5,916      445         13.3     x ₹2,291,858.40\n",
      "305  11:52:08     ₹385.35  5,886      1,074       5.5      x ₹2,268,170.10\n",
      "306  11:06:14     ₹386.90  5,881      836         7.0      x ₹2,275,358.90\n",
      "307  11:59:44     ₹385.60  5,864      619         9.5      x ₹2,261,158.40\n",
      "308  13:41:06     ₹384.15  5,863      1,410       4.2      x ₹2,252,271.45\n",
      "309  09:43:38     ₹388.80  5,859      1,882       3.1      x ₹2,277,979.20\n",
      "310  09:49:14     ₹388.80  5,856      1,756       3.3      x ₹2,276,812.80\n",
      "311  12:28:35     ₹385.35  5,845      748         7.8      x ₹2,252,370.75\n",
      "312  10:48:47     ₹387.95  5,844      1,167       5.0      x ₹2,267,179.80\n",
      "313  14:28:37     ₹385.20  5,842      1,002       5.8      x ₹2,250,338.40\n",
      "314  14:21:36     ₹386.35  5,837      1,054       5.5      x ₹2,255,124.95\n",
      "315  12:14:47     ₹385.95  5,826      1,079       5.4      x ₹2,248,544.70\n",
      "316  15:11:13     ₹387.35  5,809      1,564       3.7      x ₹2,250,116.15\n",
      "317  10:49:56     ₹387.95  5,742      777         7.4      x ₹2,227,608.90\n",
      "318  11:17:05     ₹387.85  5,739      1,904       3.0      x ₹2,225,871.15\n",
      "319  09:21:54     ₹389.55  5,732      702         8.2      x ₹2,232,900.60\n",
      "320  15:12:16     ₹387.65  5,721      863         6.6      x ₹2,217,745.65\n",
      "321  14:21:59     ₹386.20  5,636      1,870       3.0      x ₹2,176,623.20\n",
      "322  15:10:37     ₹387.40  5,623      607         9.3      x ₹2,178,350.20\n",
      "323  10:34:27     ₹388.35  5,614      1,340       4.2      x ₹2,180,196.90\n",
      "324  14:29:54     ₹385.75  5,595      893         6.3      x ₹2,158,271.25\n",
      "325  14:18:05     ₹386.20  5,588      970         5.8      x ₹2,158,085.60\n",
      "326  11:31:09     ₹386.40  5,587      1,175       4.8      x ₹2,158,816.80\n",
      "327  11:52:23     ₹385.25  5,571      1,424       3.9      x ₹2,146,227.75\n",
      "328  15:20:04     ₹387.80  5,566      1,095       5.1      x ₹2,158,494.80\n",
      "329  12:04:00     ₹385.65  5,561      996         5.6      x ₹2,144,599.65\n",
      "330  13:02:31     ₹385.05  5,549      933         5.9      x ₹2,136,642.45\n",
      "331  12:46:15     ₹384.55  5,487      1,714       3.2      x ₹2,110,025.85\n",
      "332  14:13:51     ₹385.05  5,460      1,658       3.3      x ₹2,102,373.00\n",
      "333  09:16:02     ₹385.90  5,418      1,439       3.8      x ₹2,090,806.20\n",
      "334  10:10:09     ₹388.30  5,411      1,561       3.5      x ₹2,101,091.30\n",
      "335  09:55:53     ₹388.60  5,394      528         10.2     x ₹2,096,108.40\n",
      "336  14:15:02     ₹385.20  5,390      603         8.9      x ₹2,076,228.00\n",
      "337  13:54:50     ₹384.70  5,367      470         11.4     x ₹2,064,684.90\n",
      "338  10:48:12     ₹387.70  5,338      698         7.7      x ₹2,069,542.60\n",
      "339  11:15:43     ₹387.35  5,315      679         7.8      x ₹2,058,765.25\n",
      "340  10:38:24     ₹388.35  5,271      774         6.8      x ₹2,046,992.85\n",
      "341  10:42:06     ₹387.85  5,265      1,620       3.2      x ₹2,042,030.25\n",
      "342  11:42:03     ₹386.30  5,219      556         9.4      x ₹2,016,099.70\n",
      "343  11:44:49     ₹385.95  5,200      1,565       3.3      x ₹2,006,940.00\n",
      "344  09:53:22     ₹388.90  5,199      934         5.6      x ₹2,021,891.10\n",
      "345  13:56:25     ₹384.70  5,191      1,145       4.5      x ₹1,996,977.70\n",
      "346  09:22:03     ₹389.55  5,188      1,718       3.0      x ₹2,020,985.40\n",
      "347  12:56:55     ₹385.10  5,181      797         6.5      x ₹1,995,203.10\n",
      "348  09:38:12     ₹389.00  5,179      1,168       4.4      x ₹2,014,631.00\n",
      "349  15:19:29     ₹387.90  5,136      789         6.5      x ₹1,992,254.40\n",
      "350  14:42:29     ₹386.20  5,117      1,223       4.2      x ₹1,976,185.40\n",
      "351  10:33:13     ₹387.95  5,101      1,494       3.4      x ₹1,978,932.95\n",
      "352  09:16:41     ₹387.40  5,097      983         5.2      x ₹1,974,577.80\n",
      "353  12:26:23     ₹385.45  5,079      552         9.2      x ₹1,957,700.55\n",
      "354  09:46:27     ₹389.00  5,058      1,135       4.5      x ₹1,967,562.00\n",
      "355  14:18:29     ₹386.20  5,053      1,184       4.3      x ₹1,951,468.60\n",
      "356  11:50:54     ₹385.60  5,052      888         5.7      x ₹1,948,051.20\n",
      "357  12:36:09     ₹384.95  5,021      1,225       4.1      x ₹1,932,833.95\n",
      "358  13:09:00     ₹384.40  5,007      487         10.3     x ₹1,924,690.80\n",
      "359  14:48:41     ₹386.50  5,006      1,403       3.6      x ₹1,934,819.00\n",
      "360  09:19:39     ₹389.15  5,006      1,048       4.8      x ₹1,948,084.90\n",
      "361  15:17:32     ₹387.60  5,003      604         8.3      x ₹1,939,162.80\n",
      "362  11:39:23     ₹385.90  5,001      411         12.2     x ₹1,929,885.90\n",
      "363  12:09:11     ₹385.00  4,988      466         10.7     x ₹1,920,380.00\n",
      "364  12:41:04     ₹385.15  4,949      1,088       4.6      x ₹1,906,107.35\n",
      "365  15:28:06     ₹388.30  4,881      460         10.6     x ₹1,895,292.30\n",
      "366  13:52:12     ₹384.60  4,874      1,003       4.9      x ₹1,874,540.40\n",
      "367  10:48:50     ₹387.95  4,846      1,409       3.4      x ₹1,880,005.70\n",
      "368  15:21:58     ₹388.40  4,816      956         5.0      x ₹1,870,534.40\n",
      "369  11:05:06     ₹387.15  4,781      966         5.0      x ₹1,850,964.15\n",
      "370  14:49:40     ₹386.50  4,732      1,121       4.2      x ₹1,828,918.00\n",
      "371  12:01:47     ₹385.55  4,732      946         5.0      x ₹1,824,422.60\n",
      "372  15:27:25     ₹388.35  4,696      697         6.7      x ₹1,823,691.60\n",
      "373  09:21:12     ₹389.35  4,692      1,396       3.4      x ₹1,826,830.20\n",
      "374  12:03:50     ₹385.65  4,652      703         6.6      x ₹1,794,043.80\n",
      "375  15:19:28     ₹387.85  4,650      545         8.5      x ₹1,803,502.50\n",
      "376  15:08:52     ₹387.75  4,600      789         5.8      x ₹1,783,650.00\n",
      "377  12:24:15     ₹385.65  4,598      1,055       4.4      x ₹1,773,218.70\n",
      "378  09:22:26     ₹390.00  4,571      862         5.3      x ₹1,782,690.00\n",
      "379  10:02:26     ₹388.55  4,568      1,021       4.5      x ₹1,774,896.40\n",
      "380  15:01:42     ₹387.40  4,563      433         10.5     x ₹1,767,706.20\n",
      "381  09:43:04     ₹388.75  4,550      1,502       3.0      x ₹1,768,812.50\n",
      "382  10:05:04     ₹388.55  4,535      661         6.9      x ₹1,762,074.25\n",
      "383  13:48:46     ₹385.05  4,530      1,482       3.1      x ₹1,744,276.50\n",
      "384  11:38:30     ₹385.90  4,505      789         5.7      x ₹1,738,479.50\n",
      "385  12:35:47     ₹384.70  4,500      936         4.8      x ₹1,731,150.00\n",
      "386  09:16:42     ₹387.70  4,495      1,206       3.7      x ₹1,742,711.50\n",
      "387  15:13:59     ₹387.70  4,486      1,394       3.2      x ₹1,739,222.20\n",
      "388  12:54:23     ₹384.85  4,485      635         7.1      x ₹1,726,052.25\n",
      "389  11:40:09     ₹386.50  4,479      923         4.9      x ₹1,731,133.50\n",
      "390  12:38:37     ₹385.05  4,478      1,168       3.8      x ₹1,724,253.90\n",
      "391  15:27:36     ₹388.25  4,468      1,158       3.9      x ₹1,734,701.00\n",
      "392  13:33:28     ₹383.90  4,456      592         7.5      x ₹1,710,658.40\n",
      "393  14:09:18     ₹385.35  4,452      426         10.4     x ₹1,715,578.20\n",
      "394  09:46:01     ₹388.85  4,441      907         4.9      x ₹1,726,882.85\n",
      "395  13:08:33     ₹384.50  4,430      331         13.4     x ₹1,703,335.00\n",
      "396  11:06:37     ₹386.80  4,429      1,356       3.3      x ₹1,713,137.20\n",
      "397  14:06:47     ₹385.30  4,426      1,291       3.4      x ₹1,705,337.80\n",
      "398  14:19:40     ₹385.95  4,416      735         6.0      x ₹1,704,355.20\n",
      "399  13:58:18     ₹384.95  4,413      574         7.7      x ₹1,698,784.35\n",
      "400  14:58:47     ₹386.50  4,405      602         7.3      x ₹1,702,532.50\n",
      "401  10:28:31     ₹388.50  4,401      1,186       3.7      x ₹1,709,788.50\n",
      "402  12:46:10     ₹384.65  4,401      1,440       3.1      x ₹1,692,844.65\n",
      "403  11:32:51     ₹386.45  4,399      1,015       4.3      x ₹1,699,993.55\n",
      "404  09:19:54     ₹389.15  4,379      1,247       3.5      x ₹1,704,087.85\n",
      "405  14:34:06     ₹385.95  4,379      693         6.3      x ₹1,690,075.05\n",
      "406  12:47:42     ₹384.75  4,371      318         13.8     x ₹1,681,742.25\n",
      "407  10:28:18     ₹388.50  4,369      780         5.6      x ₹1,697,356.50\n",
      "408  13:00:12     ₹385.60  4,361      1,122       3.9      x ₹1,681,601.60\n",
      "409  14:48:29     ₹386.45  4,352      948         4.6      x ₹1,681,830.40\n",
      "410  15:17:32     ₹387.80  4,344      385         11.3     x ₹1,684,603.20\n",
      "411  12:14:33     ₹385.95  4,337      719         6.0      x ₹1,673,865.15\n",
      "412  11:22:35     ₹387.35  4,337      628         6.9      x ₹1,679,936.95\n",
      "413  10:57:11     ₹388.40  4,328      1,360       3.2      x ₹1,680,995.20\n",
      "414  12:21:16     ₹385.60  4,317      848         5.1      x ₹1,664,635.20\n",
      "415  14:43:43     ₹386.10  4,311      930         4.6      x ₹1,664,477.10\n",
      "416  15:01:26     ₹387.50  4,257      346         12.3     x ₹1,649,587.50\n",
      "417  13:45:45     ₹385.05  4,248      750         5.7      x ₹1,635,692.40\n",
      "418  11:04:08     ₹387.00  4,248      443         9.6      x ₹1,643,976.00\n",
      "419  12:56:56     ₹385.10  4,230      992         4.3      x ₹1,628,973.00\n",
      "420  13:44:12     ₹384.95  4,222      1,197       3.5      x ₹1,625,258.90\n",
      "421  14:48:06     ₹386.65  4,205      379         11.1     x ₹1,625,863.25\n",
      "422  13:01:56     ₹384.75  4,203      382         11.0     x ₹1,617,104.25\n",
      "423  10:43:31     ₹387.70  4,201      455         9.2      x ₹1,628,727.70\n",
      "424  10:37:56     ₹388.45  4,197      795         5.3      x ₹1,630,324.65\n",
      "425  13:30:35     ₹383.85  4,194      750         5.6      x ₹1,609,866.90\n",
      "426  10:41:30     ₹387.85  4,192      365         11.5     x ₹1,625,867.20\n",
      "427  10:05:16     ₹388.60  4,171      1,113       3.7      x ₹1,620,850.60\n",
      "428  14:01:42     ₹384.75  4,164      490         8.5      x ₹1,602,099.00\n",
      "429  14:20:09     ₹385.95  4,159      739         5.6      x ₹1,605,166.05\n",
      "430  11:52:22     ₹385.45  4,157      1,352       3.1      x ₹1,602,315.65\n",
      "431  12:12:50     ₹386.20  4,152      955         4.3      x ₹1,603,502.40\n",
      "432  12:40:49     ₹385.00  4,151      918         4.5      x ₹1,598,135.00\n",
      "433  11:08:24     ₹387.20  4,144      1,020       4.1      x ₹1,604,556.80\n",
      "434  11:51:34     ₹385.60  4,142      829         5.0      x ₹1,597,155.20\n",
      "435  09:23:10     ₹389.65  4,141      795         5.2      x ₹1,613,540.65\n",
      "436  09:22:10     ₹390.05  4,132      650         6.4      x ₹1,611,686.60\n",
      "437  11:48:14     ₹386.25  4,123      797         5.2      x ₹1,592,508.75\n",
      "438  11:06:25     ₹386.85  4,121      1,184       3.5      x ₹1,594,208.85\n",
      "439  15:24:06     ₹388.45  4,106      673         6.1      x ₹1,594,975.70\n",
      "440  13:36:52     ₹383.65  4,105      530         7.7      x ₹1,574,883.25\n",
      "441  15:18:53     ₹387.90  4,101      431         9.5      x ₹1,590,777.90\n",
      "442  10:05:10     ₹388.60  4,083      936         4.4      x ₹1,586,653.80\n",
      "443  12:45:01     ₹384.60  4,078      267         15.2     x ₹1,568,398.80\n",
      "444  10:20:33     ₹389.15  4,064      1,104       3.7      x ₹1,581,505.60\n",
      "445  13:49:55     ₹385.15  4,060      1,039       3.9      x ₹1,563,709.00\n",
      "446  09:45:28     ₹388.80  4,048      844         4.8      x ₹1,573,862.40\n",
      "447  15:21:53     ₹388.20  4,032      916         4.4      x ₹1,565,222.40\n",
      "448  12:57:01     ₹385.00  4,026      1,317       3.1      x ₹1,550,010.00\n",
      "449  14:53:41     ₹386.75  3,993      1,243       3.2      x ₹1,544,292.75\n",
      "450  13:37:09     ₹383.90  3,983      962         4.1      x ₹1,529,073.70\n",
      "451  15:28:13     ₹388.30  3,977      938         4.2      x ₹1,544,269.10\n",
      "452  13:39:00     ₹383.65  3,960      1,238       3.2      x ₹1,519,254.00\n",
      "453  13:44:00     ₹384.40  3,956      446         8.9      x ₹1,520,686.40\n",
      "454  11:00:01     ₹388.00  3,941      628         6.3      x ₹1,529,108.00\n",
      "455  14:28:39     ₹385.35  3,931      1,163       3.4      x ₹1,514,810.85\n",
      "456  12:46:05     ₹384.60  3,930      1,178       3.3      x ₹1,511,478.00\n",
      "457  11:40:09     ₹386.50  3,907      1,112       3.5      x ₹1,510,055.50\n",
      "458  12:58:31     ₹385.15  3,904      307         12.7     x ₹1,503,625.60\n",
      "459  14:36:08     ₹386.15  3,901      675         5.8      x ₹1,506,371.15\n",
      "460  09:21:46     ₹389.55  3,893      608         6.4      x ₹1,516,518.15\n",
      "461  10:41:33     ₹388.00  3,887      621         6.3      x ₹1,508,156.00\n",
      "462  13:27:48     ₹383.85  3,877      677         5.7      x ₹1,488,186.45\n",
      "463  12:29:04     ₹385.65  3,856      1,188       3.2      x ₹1,487,066.40\n",
      "464  10:02:53     ₹388.75  3,849      1,258       3.1      x ₹1,496,298.75\n",
      "465  11:40:46     ₹386.80  3,823      348         11.0     x ₹1,478,736.40\n",
      "466  10:50:51     ₹388.25  3,815      760         5.0      x ₹1,481,173.75\n",
      "467  11:18:18     ₹387.65  3,815      652         5.8      x ₹1,478,884.75\n",
      "468  10:40:02     ₹388.15  3,811      770         4.9      x ₹1,479,239.65\n",
      "469  10:49:51     ₹387.70  3,802      272         14.0     x ₹1,474,035.40\n",
      "470  10:36:57     ₹388.45  3,798      1,219       3.1      x ₹1,475,333.10\n",
      "471  14:07:48     ₹385.15  3,792      611         6.2      x ₹1,460,488.80\n",
      "472  15:21:43     ₹388.20  3,785      348         10.9     x ₹1,469,337.00\n",
      "473  11:38:20     ₹385.70  3,735      704         5.3      x ₹1,440,589.50\n",
      "474  12:48:13     ₹385.15  3,734      759         4.9      x ₹1,438,150.10\n",
      "475  13:29:26     ₹383.60  3,725      705         5.3      x ₹1,428,910.00\n",
      "476  15:08:35     ₹387.45  3,721      655         5.7      x ₹1,441,701.45\n",
      "477  14:48:35     ₹386.55  3,703      1,152       3.2      x ₹1,431,394.65\n",
      "478  11:50:33     ₹385.65  3,692      957         3.9      x ₹1,423,819.80\n",
      "479  15:02:54     ₹387.25  3,662      563         6.5      x ₹1,418,109.50\n",
      "480  13:09:09     ₹384.45  3,644      577         6.3      x ₹1,400,935.80\n",
      "481  13:37:55     ₹383.65  3,638      1,045       3.5      x ₹1,395,718.70\n",
      "482  11:20:49     ₹387.45  3,633      713         5.1      x ₹1,407,605.85\n",
      "483  13:52:22     ₹384.60  3,625      934         3.9      x ₹1,394,175.00\n",
      "484  13:28:25     ₹383.60  3,625      1,139       3.2      x ₹1,390,550.00\n",
      "485  13:53:06     ₹384.75  3,602      1,082       3.3      x ₹1,385,869.50\n",
      "486  12:22:03     ₹385.60  3,598      736         4.9      x ₹1,387,388.80\n",
      "487  10:29:50     ₹388.40  3,562      448         7.9      x ₹1,383,480.80\n",
      "488  15:09:21     ₹387.55  3,561      474         7.5      x ₹1,380,065.55\n",
      "489  12:37:16     ₹384.95  3,555      627         5.7      x ₹1,368,497.25\n",
      "490  15:08:57     ₹387.75  3,549      827         4.3      x ₹1,376,124.75\n",
      "491  14:45:56     ₹386.50  3,549      370         9.6      x ₹1,371,688.50\n",
      "492  11:49:34     ₹385.80  3,524      743         4.7      x ₹1,359,559.20\n",
      "493  11:06:20     ₹386.90  3,507      1,038       3.4      x ₹1,356,858.30\n",
      "494  11:02:32     ₹387.00  3,468      398         8.7      x ₹1,342,116.00\n",
      "495  13:16:18     ₹384.45  3,468      378         9.2      x ₹1,333,272.60\n",
      "496  12:12:20     ₹385.75  3,450      395         8.7      x ₹1,330,837.50\n",
      "497  12:45:55     ₹384.50  3,445      788         4.4      x ₹1,324,602.50\n",
      "498  13:50:28     ₹385.00  3,433      828         4.1      x ₹1,321,705.00\n",
      "499  13:24:58     ₹383.55  3,432      291         11.8     x ₹1,316,343.60\n",
      "500  14:47:01     ₹386.60  3,366      352         9.6      x ₹1,301,295.60\n",
      "501  10:34:15     ₹388.25  3,360      916         3.7      x ₹1,304,520.00\n",
      "502  15:18:57     ₹388.00  3,351      696         4.8      x ₹1,300,188.00\n",
      "503  12:20:26     ₹385.65  3,350      501         6.7      x ₹1,291,927.50\n",
      "504  15:21:51     ₹388.20  3,349      719         4.7      x ₹1,300,081.80\n",
      "505  13:33:11     ₹383.75  3,346      398         8.4      x ₹1,284,027.50\n",
      "506  12:40:30     ₹384.90  3,326      744         4.5      x ₹1,280,177.40\n",
      "507  13:11:21     ₹384.30  3,316      253         13.1     x ₹1,274,338.80\n",
      "508  14:26:46     ₹385.30  3,313      579         5.7      x ₹1,276,498.90\n",
      "509  09:56:10     ₹388.50  3,292      609         5.4      x ₹1,278,942.00\n",
      "510  12:52:05     ₹385.05  3,285      1,095       3.0      x ₹1,264,889.25\n",
      "511  15:27:15     ₹388.50  3,270      411         8.0      x ₹1,270,395.00\n",
      "512  11:38:46     ₹385.75  3,253      547         5.9      x ₹1,254,844.75\n",
      "513  13:38:22     ₹383.50  3,247      881         3.7      x ₹1,245,224.50\n",
      "514  11:51:48     ₹385.60  3,237      765         4.2      x ₹1,248,187.20\n",
      "515  13:19:23     ₹384.20  3,236      1,029       3.1      x ₹1,243,271.20\n",
      "516  10:59:54     ₹388.00  3,233      368         8.8      x ₹1,254,404.00\n",
      "517  15:08:17     ₹387.65  3,219      618         5.2      x ₹1,247,845.35\n",
      "518  11:40:01     ₹386.40  3,207      510         6.3      x ₹1,239,184.80\n",
      "519  15:19:58     ₹387.80  3,195      952         3.4      x ₹1,239,021.00\n",
      "520  14:04:01     ₹384.80  3,189      434         7.4      x ₹1,227,127.20\n",
      "521  15:19:56     ₹387.75  3,169      756         4.2      x ₹1,228,779.75\n",
      "522  13:46:33     ₹385.05  3,168      926         3.4      x ₹1,219,838.40\n",
      "523  11:38:08     ₹385.65  3,155      607         5.2      x ₹1,216,725.75\n",
      "524  11:57:51     ₹385.75  3,147      559         5.6      x ₹1,213,955.25\n",
      "525  15:26:06     ₹388.45  3,144      672         4.7      x ₹1,221,286.80\n",
      "526  14:02:40     ₹384.80  3,140      667         4.7      x ₹1,208,272.00\n",
      "527  14:15:49     ₹385.45  3,105      702         4.4      x ₹1,196,822.25\n",
      "528  11:12:23     ₹387.30  3,103      602         5.2      x ₹1,201,791.90\n",
      "529  14:56:29     ₹386.65  3,102      444         7.0      x ₹1,199,388.30\n",
      "530  12:03:55     ₹385.55  3,072      833         3.7      x ₹1,184,409.60\n",
      "531  13:06:54     ₹384.80  3,065      848         3.6      x ₹1,179,412.00\n",
      "532  11:47:37     ₹385.75  3,062      444         6.9      x ₹1,181,166.50\n",
      "533  13:24:10     ₹383.60  3,059      344         8.9      x ₹1,173,432.40\n",
      "534  11:57:37     ₹385.50  3,058      304         10.1     x ₹1,178,859.00\n",
      "535  15:26:55     ₹388.35  3,055      481         6.3      x ₹1,186,409.25\n",
      "536  10:56:42     ₹388.05  3,050      418         7.3      x ₹1,183,552.50\n",
      "537  14:32:29     ₹386.25  3,050      852         3.6      x ₹1,178,062.50\n",
      "538  13:05:02     ₹385.00  3,048      718         4.2      x ₹1,173,480.00\n",
      "539  10:23:10     ₹388.85  3,048      572         5.3      x ₹1,185,214.80\n",
      "540  12:28:15     ₹385.40  3,034      616         4.9      x ₹1,169,303.60\n",
      "541  11:42:08     ₹386.65  3,029      661         4.6      x ₹1,171,162.85\n",
      "542  15:09:46     ₹387.45  3,024      432         7.0      x ₹1,171,648.80\n",
      "543  13:24:21     ₹383.55  3,021      439         6.9      x ₹1,158,704.55\n",
      "544  14:47:40     ₹386.75  3,020      366         8.2      x ₹1,167,985.00\n",
      "545  15:09:42     ₹387.50  3,020      362         8.3      x ₹1,170,250.00\n",
      "546  13:30:37     ₹383.90  3,019      882         3.4      x ₹1,158,994.10\n",
      "547  13:26:27     ₹383.80  3,012      971         3.1      x ₹1,156,005.60\n",
      "548  11:47:26     ₹385.95  3,000      273         11.0     x ₹1,157,850.00\n",
      "549  11:39:40     ₹386.40  3,000      622         4.8      x ₹1,159,200.00\n",
      "550  10:47:15     ₹387.45  3,000      570         5.3      x ₹1,162,350.00\n",
      "551  10:45:23     ₹387.90  2,998      391         7.7      x ₹1,162,924.20\n",
      "552  13:09:14     ₹384.50  2,996      709         4.2      x ₹1,151,962.00\n",
      "553  15:10:36     ₹387.55  2,995      350         8.6      x ₹1,160,712.25\n",
      "554  15:21:25     ₹388.15  2,994      414         7.2      x ₹1,162,121.10\n",
      "555  11:36:29     ₹386.15  2,992      944         3.2      x ₹1,155,360.80\n",
      "556  15:22:16     ₹388.60  2,991      735         4.1      x ₹1,162,302.60\n",
      "557  15:25:36     ₹388.50  2,975      342         8.7      x ₹1,155,787.50\n",
      "558  11:09:43     ₹387.05  2,973      471         6.3      x ₹1,150,699.65\n",
      "559  11:03:40     ₹387.20  2,970      216         13.8     x ₹1,149,984.00\n",
      "560  13:38:45     ₹383.50  2,970      808         3.7      x ₹1,138,995.00\n",
      "561  11:11:27     ₹387.15  2,962      522         5.7      x ₹1,146,738.30\n",
      "562  15:03:06     ₹387.25  2,958      582         5.1      x ₹1,145,485.50\n",
      "563  12:16:02     ₹386.05  2,948      588         5.0      x ₹1,138,075.40\n",
      "564  12:32:55     ₹385.05  2,945      636         4.6      x ₹1,133,972.25\n",
      "565  13:12:53     ₹384.15  2,945      495         6.0      x ₹1,131,321.75\n",
      "566  15:26:05     ₹388.45  2,930      509         5.8      x ₹1,138,158.50\n",
      "567  15:22:56     ₹388.45  2,924      435         6.7      x ₹1,135,827.80\n",
      "568  15:09:52     ₹387.45  2,923      580         5.0      x ₹1,132,516.35\n",
      "569  14:38:35     ₹386.00  2,910      869         3.3      x ₹1,123,260.00\n",
      "570  15:21:47     ₹388.20  2,901      540         5.4      x ₹1,126,168.20\n",
      "571  15:26:26     ₹388.50  2,900      348         8.3      x ₹1,126,650.00\n",
      "572  12:22:42     ₹385.80  2,900      829         3.5      x ₹1,118,820.00\n",
      "573  15:02:09     ₹387.00  2,899      592         4.9      x ₹1,121,913.00\n",
      "574  12:35:27     ₹384.75  2,894      749         3.9      x ₹1,113,466.50\n",
      "575  14:56:23     ₹386.75  2,894      603         4.8      x ₹1,119,254.50\n",
      "576  15:19:46     ₹387.75  2,878      904         3.2      x ₹1,115,944.50\n",
      "577  15:02:43     ₹387.20  2,874      648         4.4      x ₹1,112,812.80\n",
      "578  11:18:28     ₹387.60  2,860      663         4.3      x ₹1,108,536.00\n",
      "579  15:23:56     ₹388.60  2,860      615         4.7      x ₹1,111,396.00\n",
      "580  11:03:00     ₹387.00  2,858      274         10.4     x ₹1,106,046.00\n",
      "581  14:05:05     ₹385.00  2,856      536         5.3      x ₹1,099,560.00\n",
      "582  15:11:26     ₹387.60  2,855      751         3.8      x ₹1,106,598.00\n",
      "583  14:38:34     ₹386.00  2,855      613         4.7      x ₹1,102,030.00\n",
      "584  13:37:02     ₹383.70  2,853      700         4.1      x ₹1,094,696.10\n",
      "585  11:02:45     ₹387.20  2,852      531         5.4      x ₹1,104,294.40\n",
      "586  09:22:25     ₹390.00  2,852      633         4.5      x ₹1,112,280.00\n",
      "587  14:47:42     ₹386.85  2,850      505         5.6      x ₹1,102,522.50\n",
      "588  11:22:26     ₹387.30  2,850      451         6.3      x ₹1,103,805.00\n",
      "589  15:17:16     ₹387.80  2,850      569         5.0      x ₹1,105,230.00\n",
      "590  15:08:36     ₹387.50  2,850      797         3.6      x ₹1,104,375.00\n",
      "591  10:45:49     ₹387.70  2,850      185         15.4     x ₹1,104,945.00\n",
      "592  10:45:49     ₹387.70  2,850      327         8.7      x ₹1,104,945.00\n",
      "593  10:45:50     ₹387.70  2,850      470         6.1      x ₹1,104,945.00\n",
      "594  14:48:19     ₹386.70  2,850      623         4.6      x ₹1,102,095.00\n",
      "595  14:28:08     ₹385.20  2,845      676         4.2      x ₹1,095,894.00\n",
      "596  11:43:38     ₹386.25  2,845      458         6.2      x ₹1,098,881.25\n",
      "597  11:54:16     ₹385.95  2,845      355         8.0      x ₹1,098,027.75\n",
      "598  09:19:37     ₹389.10  2,836      776         3.7      x ₹1,103,487.60\n",
      "599  13:37:50     ₹383.50  2,816      918         3.1      x ₹1,079,936.00\n",
      "600  11:51:59     ₹385.55  2,804      760         3.7      x ₹1,081,082.20\n",
      "601  11:13:40     ₹387.20  2,800      437         6.4      x ₹1,084,160.00\n",
      "602  10:23:17     ₹388.70  2,798      703         4.0      x ₹1,087,582.60\n",
      "603  15:02:17     ₹387.25  2,790      791         3.5      x ₹1,080,427.50\n",
      "604  13:40:08     ₹384.00  2,780      900         3.1      x ₹1,067,520.00\n",
      "605  14:46:35     ₹386.55  2,778      301         9.2      x ₹1,073,835.90\n",
      "606  11:16:18     ₹387.40  2,777      596         4.7      x ₹1,075,809.80\n",
      "607  11:34:31     ₹386.35  2,776      698         4.0      x ₹1,072,507.60\n",
      "608  12:55:44     ₹384.80  2,774      638         4.3      x ₹1,067,435.20\n",
      "609  13:17:53     ₹384.45  2,765      778         3.6      x ₹1,063,004.25\n",
      "610  14:26:45     ₹385.15  2,750      448         6.1      x ₹1,059,162.50\n",
      "611  15:09:57     ₹387.50  2,749      408         6.7      x ₹1,065,237.50\n",
      "612  11:04:24     ₹387.25  2,744      608         4.5      x ₹1,062,614.00\n",
      "613  14:07:53     ₹385.20  2,733      704         3.9      x ₹1,052,751.60\n",
      "614  10:25:03     ₹388.95  2,731      826         3.3      x ₹1,062,222.45\n",
      "615  12:49:05     ₹385.00  2,729      710         3.8      x ₹1,050,665.00\n",
      "616  10:43:33     ₹387.75  2,729      604         4.5      x ₹1,058,169.75\n",
      "617  15:23:17     ₹388.40  2,726      331         8.2      x ₹1,058,778.40\n",
      "618  12:43:31     ₹384.65  2,725      683         4.0      x ₹1,048,171.25\n",
      "619  15:11:56     ₹387.70  2,709      434         6.2      x ₹1,050,279.30\n",
      "620  14:48:25     ₹386.70  2,706      742         3.6      x ₹1,046,410.20\n",
      "621  15:26:26     ₹388.50  2,702      474         5.7      x ₹1,049,727.00\n",
      "622  10:17:03     ₹388.40  2,689      335         8.0      x ₹1,044,407.60\n",
      "623  10:47:16     ₹387.80  2,676      587         4.6      x ₹1,037,752.80\n",
      "624  14:18:02     ₹385.80  2,674      720         3.7      x ₹1,031,629.20\n",
      "625  10:04:15     ₹388.90  2,668      440         6.1      x ₹1,037,585.20\n",
      "626  10:28:13     ₹388.55  2,662      621         4.3      x ₹1,034,320.10\n",
      "627  12:11:17     ₹385.85  2,661      753         3.5      x ₹1,026,746.85\n",
      "628  10:36:25     ₹388.40  2,656      705         3.8      x ₹1,031,590.40\n",
      "629  11:24:04     ₹387.20  2,649      810         3.3      x ₹1,025,692.80\n",
      "630  15:12:10     ₹387.65  2,609      579         4.5      x ₹1,011,378.85\n",
      "631  13:24:23     ₹383.60  2,606      667         3.9      x ₹999,661.60 \n",
      "632  15:22:13     ₹388.60  2,604      590         4.4      x ₹1,011,914.40\n",
      "633  11:38:19     ₹385.65  2,594      517         5.0      x ₹1,000,376.10\n",
      "634  13:44:03     ₹384.50  2,592      570         4.5      x ₹996,624.00 \n",
      "635  13:05:22     ₹385.05  2,568      808         3.2      x ₹988,808.40 \n",
      "636  12:21:11     ₹385.55  2,562      666         3.8      x ₹987,779.10 \n",
      "637  10:45:51     ₹387.85  2,555      597         4.3      x ₹990,956.75 \n",
      "638  11:47:41     ₹386.00  2,550      571         4.5      x ₹984,300.00 \n",
      "639  09:22:16     ₹390.20  2,509      716         3.5      x ₹979,011.80 \n",
      "640  15:17:34     ₹387.85  2,499      702         3.6      x ₹969,237.15 \n",
      "641  12:31:14     ₹385.25  2,497      427         5.9      x ₹961,969.25 \n",
      "642  13:17:21     ₹384.40  2,485      545         4.6      x ₹955,234.00 \n",
      "643  15:19:38     ₹387.80  2,484      810         3.1      x ₹963,295.20 \n",
      "644  14:46:17     ₹386.50  2,476      583         4.2      x ₹956,974.00 \n",
      "645  12:14:24     ₹386.00  2,452      509         4.8      x ₹946,472.00 \n",
      "646  13:26:48     ₹384.00  2,447      788         3.1      x ₹939,648.00 \n",
      "647  12:09:10     ₹384.80  2,445      216         11.3     x ₹940,836.00 \n",
      "648  12:07:22     ₹385.30  2,439      593         4.1      x ₹939,746.70 \n",
      "649  11:36:24     ₹386.25  2,439      794         3.1      x ₹942,063.75 \n",
      "650  12:02:31     ₹385.55  2,427      648         3.7      x ₹935,729.85 \n",
      "651  10:55:25     ₹388.00  2,410      457         5.3      x ₹935,080.00 \n",
      "652  09:19:34     ₹389.15  2,406      707         3.4      x ₹936,294.90 \n",
      "653  11:44:19     ₹385.95  2,398      649         3.7      x ₹925,508.10 \n",
      "654  12:22:37     ₹385.70  2,396      708         3.4      x ₹924,137.20 \n",
      "655  14:28:33     ₹385.10  2,387      710         3.4      x ₹919,233.70 \n",
      "656  12:50:09     ₹384.95  2,354      227         10.4     x ₹906,172.30 \n",
      "657  11:41:49     ₹386.45  2,346      241         9.7      x ₹906,611.70 \n",
      "658  09:22:56     ₹389.75  2,314      467         5.0      x ₹901,881.50 \n",
      "659  12:12:25     ₹385.80  2,313      511         4.5      x ₹892,355.40 \n",
      "660  14:17:41     ₹385.75  2,286      631         3.6      x ₹881,824.50 \n",
      "661  14:03:24     ₹384.80  2,281      543         4.2      x ₹877,728.80 \n",
      "662  15:19:15     ₹387.90  2,278      299         7.6      x ₹883,636.20 \n",
      "663  15:26:01     ₹388.45  2,277      393         5.8      x ₹884,500.65 \n",
      "664  12:43:44     ₹384.40  2,272      588         3.9      x ₹873,356.80 \n",
      "665  09:21:36     ₹389.35  2,257      399         5.7      x ₹878,762.95 \n",
      "666  14:00:06     ₹384.85  2,252      547         4.1      x ₹866,682.20 \n",
      "667  12:57:41     ₹385.05  2,248      344         6.5      x ₹865,592.40 \n",
      "668  11:11:37     ₹387.25  2,244      672         3.3      x ₹868,989.00 \n",
      "669  15:24:15     ₹388.55  2,241      627         3.6      x ₹870,740.55 \n",
      "670  14:38:34     ₹386.00  2,240      725         3.1      x ₹864,640.00 \n",
      "671  14:00:43     ₹384.75  2,224      486         4.6      x ₹855,684.00 \n",
      "672  15:23:55     ₹388.45  2,216      478         4.6      x ₹860,805.20 \n",
      "673  11:03:41     ₹387.40  2,215      327         6.8      x ₹858,091.00 \n",
      "674  10:51:58     ₹388.00  2,211      469         4.7      x ₹857,868.00 \n",
      "675  11:22:15     ₹387.35  2,210      374         5.9      x ₹856,043.50 \n",
      "676  13:04:09     ₹384.90  2,199      200         11.0     x ₹846,395.10 \n",
      "677  09:23:02     ₹389.85  2,193      608         3.6      x ₹854,941.05 \n",
      "678  09:19:24     ₹389.15  2,190      454         4.8      x ₹852,238.50 \n",
      "679  15:03:52     ₹387.50  2,184      531         4.1      x ₹846,300.00 \n",
      "680  12:03:07     ₹385.70  2,180      521         4.2      x ₹840,826.00 \n",
      "681  10:19:55     ₹389.15  2,160      706         3.1      x ₹840,564.00 \n",
      "682  10:39:58     ₹388.15  2,140      584         3.7      x ₹830,641.00 \n",
      "683  09:22:40     ₹389.80  2,133      409         5.2      x ₹831,443.40 \n",
      "684  11:14:56     ₹387.25  2,128      402         5.3      x ₹824,068.00 \n",
      "685  13:20:54     ₹384.30  2,119      292         7.3      x ₹814,331.70 \n",
      "686  10:00:14     ₹388.25  2,115      309         6.8      x ₹821,148.75 \n",
      "687  10:32:30     ₹388.00  2,111      297         7.1      x ₹819,068.00 \n",
      "688  12:56:50     ₹384.90  2,089      474         4.4      x ₹804,056.10 \n",
      "689  09:22:55     ₹389.70  2,085      354         5.9      x ₹812,524.50 \n",
      "690  14:57:14     ₹386.90  2,084      342         6.1      x ₹806,299.60 \n",
      "691  14:09:58     ₹385.30  2,073      504         4.1      x ₹798,726.90 \n",
      "692  12:59:42     ₹385.25  2,067      469         4.4      x ₹796,311.75 \n",
      "693  14:01:52     ₹384.90  2,066      636         3.3      x ₹795,203.40 \n",
      "694  10:22:26     ₹388.95  2,061      362         5.7      x ₹801,625.95 \n",
      "695  13:13:50     ₹384.20  2,056      474         4.3      x ₹789,915.20 \n",
      "696  14:47:31     ₹386.60  2,055      232         8.8      x ₹794,463.00 \n",
      "697  15:01:43     ₹387.35  2,055      479         4.3      x ₹796,004.25 \n",
      "698  12:28:11     ₹385.45  2,055      472         4.4      x ₹792,099.75 \n",
      "699  10:32:32     ₹388.00  2,052      369         5.6      x ₹796,176.00 \n",
      "700  10:24:30     ₹388.75  2,051      400         5.1      x ₹797,326.25 \n",
      "701  12:59:08     ₹385.50  2,049      279         7.4      x ₹789,889.50 \n",
      "702  14:35:56     ₹386.00  2,048      533         3.8      x ₹790,528.00 \n",
      "703  11:43:48     ₹386.10  2,047      524         3.9      x ₹790,346.70 \n",
      "704  12:45:06     ₹384.65  2,047      369         5.5      x ₹787,378.55 \n",
      "705  13:46:11     ₹385.05  2,046      287         7.1      x ₹787,812.30 \n",
      "706  10:24:34     ₹388.80  2,043      485         4.2      x ₹794,318.40 \n",
      "707  11:39:24     ₹385.95  2,036      507         4.0      x ₹785,794.20 \n",
      "708  12:12:45     ₹385.85  2,012      651         3.1      x ₹776,330.20 \n",
      "709  15:07:28     ₹387.95  2,009      442         4.5      x ₹779,391.55 \n",
      "710  15:18:54     ₹388.00  2,009      484         4.1      x ₹779,492.00 \n",
      "711  15:11:56     ₹387.75  2,005      299         6.7      x ₹777,438.75 \n",
      "712  11:38:58     ₹385.95  2,005      555         3.6      x ₹773,829.75 \n",
      "713  14:57:11     ₹386.85  2,004      265         7.6      x ₹775,247.40 \n",
      "714  11:27:16     ₹386.90  2,000      175         11.4     x ₹773,800.00 \n",
      "715  14:45:47     ₹386.40  1,998      268         7.5      x ₹772,027.20 \n",
      "716  13:15:17     ₹384.50  1,994      171         11.7     x ₹766,693.00 \n",
      "717  11:57:45     ₹385.70  1,993      440         4.5      x ₹768,700.10 \n",
      "718  09:21:28     ₹389.60  1,985      620         3.2      x ₹773,356.00 \n",
      "719  10:45:11     ₹388.20  1,970      479         4.1      x ₹764,754.00 \n",
      "720  10:38:12     ₹388.35  1,964      650         3.0      x ₹762,719.40 \n",
      "721  13:24:22     ₹383.50  1,948      536         3.6      x ₹747,058.00 \n",
      "722  09:16:00     ₹386.00  1,944      488         4.0      x ₹750,384.00 \n",
      "723  12:06:54     ₹385.60  1,942      483         4.0      x ₹748,835.20 \n",
      "724  12:57:32     ₹385.15  1,931      235         8.2      x ₹743,724.65 \n",
      "725  11:38:17     ₹385.65  1,923      403         4.8      x ₹741,604.95 \n",
      "726  13:02:06     ₹384.75  1,922      511         3.8      x ₹739,489.50 \n",
      "727  14:47:06     ₹386.65  1,922      420         4.6      x ₹743,141.30 \n",
      "728  13:21:38     ₹384.00  1,907      627         3.0      x ₹732,288.00 \n",
      "729  12:32:34     ₹385.10  1,889      387         4.9      x ₹727,453.90 \n",
      "730  10:49:53     ₹387.90  1,870      364         5.1      x ₹725,373.00 \n",
      "731  10:39:57     ₹388.10  1,860      479         3.9      x ₹721,866.00 \n",
      "732  13:20:57     ₹384.30  1,817      414         4.4      x ₹698,273.10 \n",
      "733  10:55:29     ₹388.10  1,817      463         3.9      x ₹705,177.70 \n",
      "734  14:04:32     ₹384.75  1,813      503         3.6      x ₹697,551.75 \n",
      "735  14:57:55     ₹386.70  1,799      274         6.6      x ₹695,673.30 \n",
      "736  11:14:00     ₹387.05  1,797      338         5.3      x ₹695,528.85 \n",
      "737  11:11:08     ₹387.10  1,795      354         5.1      x ₹694,844.50 \n",
      "738  12:50:18     ₹384.95  1,783      363         4.9      x ₹686,365.85 \n",
      "739  10:51:48     ₹388.00  1,777      407         4.4      x ₹689,476.00 \n",
      "740  15:18:22     ₹387.85  1,755      475         3.7      x ₹680,676.75 \n",
      "741  12:32:39     ₹385.00  1,751      543         3.2      x ₹674,135.00 \n",
      "742  12:19:06     ₹386.00  1,745      163         10.7     x ₹673,570.00 \n",
      "743  10:59:15     ₹388.15  1,734      227         7.7      x ₹673,052.10 \n",
      "744  12:56:51     ₹385.05  1,732      550         3.2      x ₹666,906.60 \n",
      "745  15:10:00     ₹387.50  1,727      508         3.4      x ₹669,212.50 \n",
      "746  15:25:06     ₹388.30  1,713      442         3.9      x ₹665,157.90 \n",
      "747  12:06:06     ₹385.55  1,704      332         5.1      x ₹656,977.20 \n",
      "748  13:11:46     ₹384.25  1,691      199         8.5      x ₹649,766.75 \n",
      "749  10:24:36     ₹388.80  1,670      537         3.1      x ₹649,296.00 \n",
      "750  09:21:38     ₹389.55  1,661      470         3.5      x ₹647,042.55 \n",
      "751  15:21:38     ₹388.15  1,660      439         3.8      x ₹644,329.00 \n",
      "752  09:22:57     ₹389.90  1,652      472         3.5      x ₹644,114.80 \n",
      "753  12:01:07     ₹385.55  1,637      406         4.0      x ₹631,145.35 \n",
      "754  15:27:02     ₹388.45  1,632      534         3.1      x ₹633,950.40 \n",
      "755  15:03:01     ₹387.30  1,626      425         3.8      x ₹629,749.80 \n",
      "756  11:13:02     ₹387.20  1,624      512         3.2      x ₹628,812.80 \n",
      "757  15:23:47     ₹388.50  1,621      220         7.4      x ₹629,758.50 \n",
      "758  15:07:26     ₹387.90  1,614      320         5.0      x ₹626,070.60 \n",
      "759  10:36:03     ₹388.05  1,609      330         4.9      x ₹624,372.45 \n",
      "760  14:56:43     ₹386.70  1,601      421         3.8      x ₹619,106.70 \n",
      "761  13:04:14     ₹385.00  1,593      276         5.8      x ₹613,305.00 \n",
      "762  10:04:17     ₹388.90  1,571      503         3.1      x ₹610,961.90 \n",
      "763  15:07:26     ₹387.95  1,568      240         6.5      x ₹608,305.60 \n",
      "764  15:27:21     ₹388.50  1,563      488         3.2      x ₹607,225.50 \n",
      "765  09:22:46     ₹389.75  1,557      377         4.1      x ₹606,840.75 \n",
      "766  12:59:03     ₹385.40  1,556      177         8.8      x ₹599,682.40 \n",
      "767  12:32:35     ₹385.00  1,553      464         3.3      x ₹597,905.00 \n",
      "768  15:23:49     ₹388.45  1,549      316         4.9      x ₹601,709.05 \n",
      "769  11:46:50     ₹385.90  1,530      260         5.9      x ₹590,427.00 \n",
      "770  12:56:45     ₹384.90  1,526      405         3.8      x ₹587,357.40 \n",
      "771  10:49:55     ₹387.75  1,519      493         3.1      x ₹588,992.25 \n",
      "772  14:11:01     ₹385.35  1,513      301         5.0      x ₹583,034.55 \n",
      "773  15:21:25     ₹388.15  1,510      296         5.1      x ₹586,106.50 \n",
      "774  12:44:28     ₹384.50  1,501      173         8.7      x ₹577,134.50 \n",
      "775  11:07:34     ₹387.05  1,501      193         7.8      x ₹580,962.05 \n",
      "776  15:25:45     ₹388.50  1,500      440         3.4      x ₹582,750.00 \n",
      "777  12:50:14     ₹385.15  1,484      276         5.4      x ₹571,562.60 \n",
      "778  10:17:17     ₹388.50  1,465      423         3.5      x ₹569,152.50 \n",
      "779  11:41:50     ₹386.70  1,461      312         4.7      x ₹564,968.70 \n",
      "780  11:47:58     ₹386.05  1,457      373         3.9      x ₹562,474.85 \n",
      "781  09:15:58     ₹386.15  1,452      418         3.5      x ₹560,689.80 \n",
      "782  10:56:39     ₹388.00  1,449      274         5.3      x ₹562,212.00 \n",
      "783  11:53:55     ₹385.85  1,448      208         7.0      x ₹558,710.80 \n",
      "784  13:17:17     ₹384.35  1,444      481         3.0      x ₹555,001.40 \n",
      "785  15:26:44     ₹388.55  1,444      370         3.9      x ₹561,066.20 \n",
      "786  13:16:13     ₹384.45  1,443      209         6.9      x ₹554,761.35 \n",
      "787  10:49:54     ₹387.90  1,430      429         3.3      x ₹554,697.00 \n",
      "788  15:26:53     ₹388.55  1,429      331         4.3      x ₹555,237.95 \n",
      "789  11:04:13     ₹387.10  1,417      446         3.2      x ₹548,520.70 \n",
      "790  10:55:12     ₹388.00  1,415      296         4.8      x ₹549,020.00 \n",
      "791  10:39:31     ₹388.30  1,407      462         3.0      x ₹546,338.10 \n",
      "792  13:25:08     ₹383.55  1,387      409         3.4      x ₹531,983.85 \n",
      "793  10:59:56     ₹388.10  1,378      433         3.2      x ₹534,801.80 \n",
      "794  14:56:46     ₹386.80  1,374      378         3.6      x ₹531,463.20 \n",
      "795  10:00:08     ₹388.20  1,370      378         3.6      x ₹531,834.00 \n",
      "796  10:24:23     ₹388.55  1,347      408         3.3      x ₹523,376.85 \n",
      "797  15:09:17     ₹387.65  1,333      145         9.2      x ₹516,737.45 \n",
      "798  11:11:14     ₹387.10  1,317      435         3.0      x ₹509,810.70 \n",
      "799  12:10:15     ₹385.35  1,314      175         7.5      x ₹506,349.90 \n",
      "800  13:45:31     ₹385.05  1,313      281         4.7      x ₹505,570.65 \n",
      "801  12:30:03     ₹385.35  1,309      380         3.4      x ₹504,423.15 \n",
      "802  15:24:33     ₹388.45  1,305      344         3.8      x ₹506,927.25 \n",
      "803  12:56:44     ₹385.05  1,302      359         3.6      x ₹501,335.10 \n",
      "804  15:25:38     ₹388.40  1,291      398         3.2      x ₹501,424.40 \n",
      "805  14:58:36     ₹386.55  1,284      383         3.4      x ₹496,330.20 \n",
      "806  15:22:37     ₹388.70  1,284      340         3.8      x ₹499,090.80 \n",
      "807  13:12:21     ₹384.10  1,255      300         4.2      x ₹482,045.50 \n",
      "808  11:27:56     ₹386.75  1,251      100         12.5     x ₹483,824.25 \n",
      "809  11:03:42     ₹387.45  1,249      377         3.3      x ₹483,925.05 \n",
      "810  15:24:57     ₹388.35  1,247      316         3.9      x ₹484,272.45 \n",
      "811  15:21:46     ₹388.20  1,243      408         3.0      x ₹482,532.60 \n",
      "812  11:08:19     ₹386.95  1,242      162         7.7      x ₹480,591.90 \n",
      "813  13:16:23     ₹384.45  1,241      411         3.0      x ₹477,102.45 \n",
      "814  11:47:18     ₹385.90  1,234      166         7.4      x ₹476,200.60 \n",
      "815  11:10:52     ₹387.40  1,227      259         4.7      x ₹475,339.80 \n",
      "816  15:23:08     ₹388.50  1,219      278         4.4      x ₹473,581.50 \n",
      "817  13:11:55     ₹384.20  1,216      322         3.8      x ₹467,187.20 \n",
      "818  09:15:39     ₹386.25  1,205      293         4.1      x ₹465,431.25 \n",
      "819  11:53:27     ₹385.40  1,200      155         7.8      x ₹462,480.00 \n",
      "820  12:00:48     ₹385.55  1,199      390         3.1      x ₹462,274.45 \n",
      "821  12:49:37     ₹385.00  1,196      204         5.9      x ₹460,460.00 \n",
      "822  10:21:51     ₹388.90  1,194      383         3.1      x ₹464,346.60 \n",
      "823  12:06:40     ₹385.50  1,191      382         3.1      x ₹459,130.50 \n",
      "824  14:56:41     ₹386.70  1,187      352         3.4      x ₹459,012.90 \n",
      "825  15:11:52     ₹387.75  1,166      229         5.1      x ₹452,116.50 \n",
      "826  15:19:22     ₹387.85  1,164      343         3.4      x ₹451,457.40 \n",
      "827  14:27:52     ₹385.20  1,159      182         6.4      x ₹446,446.80 \n",
      "828  15:23:50     ₹388.45  1,147      340         3.4      x ₹445,552.15 \n",
      "829  11:03:01     ₹387.15  1,143      330         3.5      x ₹442,512.45 \n",
      "830  12:19:17     ₹386.00  1,139      260         4.4      x ₹439,654.00 \n",
      "831  11:28:47     ₹386.75  1,128      296         3.8      x ₹436,254.00 \n",
      "832  13:11:47     ₹384.25  1,122      292         3.8      x ₹431,128.50 \n",
      "833  12:12:05     ₹385.70  1,118      224         5.0      x ₹431,212.60 \n",
      "834  13:54:13     ₹384.70  1,110      201         5.5      x ₹427,017.00 \n",
      "835  09:21:35     ₹389.60  1,100      295         3.7      x ₹428,560.00 \n",
      "836  13:45:33     ₹385.10  1,100      324         3.4      x ₹423,610.00 \n",
      "837  11:57:36     ₹385.60  1,086      151         7.2      x ₹418,761.60 \n",
      "838  11:46:24     ₹386.10  1,073      324         3.3      x ₹414,285.30 \n",
      "839  11:47:03     ₹385.90  1,072      196         5.5      x ₹413,684.80 \n",
      "840  11:46:47     ₹385.90  1,071      166         6.5      x ₹413,298.90 \n",
      "841  13:20:55     ₹384.30  1,069      334         3.2      x ₹410,816.70 \n",
      "842  11:46:53     ₹386.00  1,068      344         3.1      x ₹412,248.00 \n",
      "843  15:18:49     ₹387.90  1,068      272         3.9      x ₹414,277.20 \n",
      "844  11:47:32     ₹386.05  1,068      311         3.4      x ₹412,301.40 \n",
      "845  13:36:31     ₹383.70  1,061      340         3.1      x ₹407,105.70 \n",
      "846  12:06:26     ₹385.50  1,058      336         3.1      x ₹407,859.00 \n",
      "847  13:20:53     ₹384.30  1,052      175         6.0      x ₹404,283.60 \n",
      "848  15:03:19     ₹387.30  1,050      312         3.4      x ₹406,665.00 \n",
      "849  12:06:09     ₹385.60  1,048      321         3.3      x ₹404,108.80 \n",
      "850  13:25:03     ₹383.50  1,045      340         3.1      x ₹400,757.50 \n",
      "851  15:26:51     ₹388.50  1,045      338         3.1      x ₹405,982.50 \n",
      "852  10:47:41     ₹387.70  1,032      127         8.1      x ₹400,106.40 \n",
      "853  15:25:51     ₹388.50  1,027      304         3.4      x ₹398,989.50 \n",
      "854  13:01:30     ₹385.15  1,025      135         7.6      x ₹394,778.75 \n",
      "855  11:40:44     ₹386.60  1,020      132         7.7      x ₹394,332.00 \n",
      "856  15:23:21     ₹388.50  1,019      299         3.4      x ₹395,881.50 \n",
      "857  10:58:17     ₹388.20  1,017      295         3.4      x ₹394,799.40 \n",
      "858  13:11:34     ₹384.15  1,015      335         3.0      x ₹389,912.25 \n",
      "859  12:19:22     ₹386.00  1,013      308         3.3      x ₹391,018.00 \n",
      "860  11:41:15     ₹386.45  1,013      218         4.6      x ₹391,473.85 \n",
      "861  12:26:08     ₹385.50  1,013      300         3.4      x ₹390,511.50 \n",
      "862  13:24:19     ₹383.55  1,011      289         3.5      x ₹387,769.05 \n",
      "863  14:47:37     ₹386.60  1,010      212         4.8      x ₹390,466.00 \n",
      "864  13:11:23     ₹384.30  1,005      296         3.4      x ₹386,221.50 \n",
      "865  12:58:02     ₹385.20  1,003      187         5.4      x ₹386,355.60 \n",
      "866  11:27:58     ₹386.80  1,001      150         6.7      x ₹387,186.80 \n",
      "867  11:46:51     ₹385.90  1,000      308         3.2      x ₹385,900.00 \n",
      "868  10:54:43     ₹388.00  1,000      230         4.4      x ₹388,000.00 \n",
      "869  14:57:41     ₹386.75  1,000      248         4.0      x ₹386,750.00 \n",
      "870  10:54:30     ₹388.20  1,000      195         5.1      x ₹388,200.00 \n",
      "871  13:01:10     ₹385.15  988        277         3.6      x ₹380,528.20 \n",
      "872  15:24:51     ₹388.40  986        237         4.2      x ₹382,962.40 \n",
      "873  13:45:38     ₹385.05  981        325         3.0      x ₹377,734.05 \n",
      "874  13:01:13     ₹385.15  980        276         3.6      x ₹377,447.00 \n",
      "875  15:10:33     ₹387.45  965        245         3.9      x ₹373,889.25 \n",
      "876  10:43:27     ₹387.75  957        306         3.1      x ₹371,076.75 \n",
      "877  12:12:01     ₹385.75  954        168         5.7      x ₹368,005.50 \n",
      "878  13:01:48     ₹384.80  942        174         5.4      x ₹362,481.60 \n",
      "879  11:41:42     ₹386.40  929        116         8.0      x ₹358,965.60 \n",
      "880  15:07:46     ₹388.00  928        184         5.0      x ₹360,064.00 \n",
      "881  09:15:38     ₹386.30  902        244         3.7      x ₹348,442.60 \n",
      "882  14:58:18     ₹386.45  901        300         3.0      x ₹348,191.45 \n",
      "883  13:20:51     ₹384.30  891        127         7.0      x ₹342,411.30 \n",
      "884  12:11:37     ₹385.85  886        185         4.8      x ₹341,863.10 \n",
      "885  13:46:16     ₹385.05  873        277         3.2      x ₹336,148.65 \n",
      "886  15:18:47     ₹387.95  866        219         4.0      x ₹335,964.70 \n",
      "887  15:18:43     ₹387.95  856        271         3.2      x ₹332,085.20 \n",
      "888  10:35:56     ₹388.20  854        235         3.6      x ₹331,522.80 \n",
      "889  13:45:36     ₹385.05  852        237         3.6      x ₹328,062.60 \n",
      "890  15:09:19     ₹387.65  849        242         3.5      x ₹329,114.85 \n",
      "891  11:28:02     ₹386.75  846        167         5.1      x ₹327,190.50 \n",
      "892  10:41:25     ₹387.90  845        166         5.1      x ₹327,775.50 \n",
      "893  11:54:06     ₹385.75  841        203         4.1      x ₹324,415.75 \n",
      "894  13:12:13     ₹384.10  840        221         3.8      x ₹322,644.00 \n",
      "895  10:31:50     ₹387.80  824        157         5.3      x ₹319,547.20 \n",
      "896  14:10:56     ₹385.35  811        198         4.1      x ₹312,518.85 \n",
      "897  12:11:45     ₹385.80  808        165         4.9      x ₹311,726.40 \n",
      "898  12:19:12     ₹386.10  807        203         4.0      x ₹311,582.70 \n",
      "899  15:18:36     ₹387.95  800        184         4.3      x ₹310,360.00 \n",
      "900  15:24:47     ₹388.40  792        222         3.6      x ₹307,612.80 \n",
      "901  14:57:40     ₹386.80  786        199         3.9      x ₹304,024.80 \n",
      "902  14:45:43     ₹386.40  772        201         3.8      x ₹298,300.80 \n",
      "903  13:11:46     ₹384.25  760        236         3.2      x ₹292,030.00 \n",
      "904  13:24:50     ₹383.50  757        117         6.5      x ₹290,309.50 \n",
      "905  15:03:28     ₹387.35  754        249         3.0      x ₹292,061.90 \n",
      "906  15:03:47     ₹387.35  750        156         4.8      x ₹290,512.50 \n",
      "907  11:03:36     ₹387.05  750        67          11.2     x ₹290,287.50 \n",
      "908  13:01:48     ₹385.05  742        128         5.8      x ₹285,707.10 \n",
      "909  14:27:53     ₹385.35  738        219         3.4      x ₹284,388.30 \n",
      "910  14:26:24     ₹385.35  727        233         3.1      x ₹280,149.45 \n",
      "911  12:57:27     ₹385.10  717        190         3.8      x ₹276,116.70 \n",
      "912  15:09:13     ₹387.65  706        187         3.8      x ₹273,680.90 \n",
      "913  14:27:51     ₹385.35  705        128         5.5      x ₹271,671.75 \n",
      "914  15:09:18     ₹387.55  703        200         3.5      x ₹272,447.65 \n",
      "915  14:38:19     ₹385.85  700        220         3.2      x ₹270,095.00 \n",
      "916  11:07:50     ₹387.15  700        136         5.2      x ₹271,005.00 \n",
      "917  14:26:23     ₹385.25  700        198         3.5      x ₹269,675.00 \n",
      "918  14:57:47     ₹386.80  699        211         3.3      x ₹270,373.20 \n",
      "919  14:26:20     ₹385.25  699        145         4.8      x ₹269,289.75 \n",
      "920  14:26:21     ₹385.25  699        167         4.2      x ₹269,289.75 \n",
      "921  13:45:35     ₹385.10  699        206         3.4      x ₹269,184.90 \n",
      "922  13:53:50     ₹384.80  685        84          8.1      x ₹263,588.00 \n",
      "923  12:49:29     ₹385.10  679        96          7.0      x ₹261,482.90 \n",
      "924  11:40:45     ₹386.60  665        160         4.2      x ₹257,089.00 \n",
      "925  13:15:51     ₹384.40  665        103         6.4      x ₹255,626.00 \n",
      "926  11:46:46     ₹385.90  662        112         5.9      x ₹255,465.80 \n",
      "927  14:57:07     ₹386.85  647        166         3.9      x ₹250,291.95 \n",
      "928  15:07:42     ₹388.00  643        190         3.4      x ₹249,484.00 \n",
      "929  13:54:35     ₹384.70  640        209         3.1      x ₹246,208.00 \n",
      "930  13:16:08     ₹384.45  619        136         4.6      x ₹237,974.55 \n",
      "931  12:48:04     ₹384.75  619        150         4.1      x ₹238,160.25 \n",
      "932  14:27:48     ₹385.40  606        93          6.5      x ₹233,552.40 \n",
      "933  15:07:48     ₹388.00  605        183         3.3      x ₹234,740.00 \n",
      "934  13:03:35     ₹385.05  605        94          6.5      x ₹232,955.25 \n",
      "935  14:38:23     ₹385.80  601        191         3.1      x ₹231,865.80 \n",
      "936  14:57:37     ₹386.80  600        165         3.6      x ₹232,080.00 \n",
      "937  10:58:37     ₹388.10  600        196         3.1      x ₹232,860.00 \n",
      "938  11:40:35     ₹386.50  595        136         4.4      x ₹229,967.50 \n",
      "939  12:10:09     ₹385.15  590        135         4.4      x ₹227,238.50 \n",
      "940  12:09:05     ₹384.75  587        129         4.5      x ₹225,848.25 \n",
      "941  12:18:55     ₹386.10  586        99          5.9      x ₹226,254.60 \n",
      "942  15:24:50     ₹388.40  569        188         3.0      x ₹220,999.60 \n",
      "943  10:58:55     ₹388.20  566        163         3.5      x ₹219,721.20 \n",
      "944  14:27:28     ₹385.35  560        75          7.4      x ₹215,796.00 \n",
      "945  10:00:41     ₹388.30  547        85          6.4      x ₹212,400.10 \n",
      "946  11:41:45     ₹386.35  544        132         4.1      x ₹210,174.40 \n",
      "947  10:58:39     ₹388.20  543        166         3.3      x ₹210,792.60 \n",
      "948  13:54:08     ₹384.80  521        143         3.6      x ₹200,480.80 \n",
      "949  15:03:40     ₹387.35  520        171         3.0      x ₹201,422.00 \n",
      "950  10:47:49     ₹387.70  517        117         4.4      x ₹200,440.90 \n",
      "951  15:03:32     ₹387.40  515        154         3.3      x ₹199,511.00 \n",
      "952  12:58:21     ₹385.10  506        129         3.9      x ₹194,860.60 \n",
      "953  12:47:21     ₹384.65  505        163         3.1      x ₹194,248.25 \n",
      "954  11:46:44     ₹385.95  504        85          5.9      x ₹194,518.80 \n",
      "955  13:24:47     ₹383.55  504        122         4.1      x ₹193,309.20 \n",
      "956  11:27:40     ₹386.75  500        66          7.6      x ₹193,375.00 \n",
      "957  10:58:30     ₹388.20  495        160         3.1      x ₹192,159.00 \n",
      "958  13:15:15     ₹384.50  490        80          6.2      x ₹188,405.00 \n",
      "959  14:10:53     ₹385.35  488        158         3.1      x ₹188,050.80 \n",
      "960  13:20:26     ₹384.40  487        149         3.3      x ₹187,202.80 \n",
      "961  13:15:45     ₹384.35  486        92          5.3      x ₹186,794.10 \n",
      "962  13:20:45     ₹384.30  486        92          5.3      x ₹186,769.80 \n",
      "963  12:44:25     ₹384.65  483        102         4.7      x ₹185,785.95 \n",
      "964  10:59:13     ₹388.10  483        142         3.4      x ₹187,452.30 \n",
      "965  10:41:22     ₹387.75  475        123         3.9      x ₹184,181.25 \n",
      "966  13:15:39     ₹384.50  470        62          7.6      x ₹180,715.00 \n",
      "967  13:53:52     ₹384.80  460        99          4.6      x ₹177,008.00 \n",
      "968  10:49:44     ₹387.70  453        97          4.7      x ₹175,628.10 \n",
      "969  13:01:35     ₹385.10  453        139         3.3      x ₹174,450.30 \n",
      "970  12:49:35     ₹385.05  453        142         3.2      x ₹174,427.65 \n",
      "971  11:53:25     ₹385.40  452        109         4.1      x ₹174,200.80 \n",
      "972  11:47:25     ₹385.90  446        123         3.6      x ₹172,111.40 \n",
      "973  13:01:45     ₹385.10  444        142         3.1      x ₹170,984.40 \n",
      "974  13:03:25     ₹385.00  444        80          5.5      x ₹170,940.00 \n",
      "975  11:07:30     ₹387.15  444        142         3.1      x ₹171,894.60 \n",
      "976  12:18:45     ₹385.95  444        88          5.1      x ₹171,361.80 \n",
      "977  12:58:15     ₹385.10  443        128         3.5      x ₹170,599.30 \n",
      "978  13:03:45     ₹384.90  443        138         3.2      x ₹170,510.70 \n",
      "979  12:58:25     ₹385.10  443        127         3.5      x ₹170,599.30 \n",
      "980  12:58:55     ₹385.25  443        145         3.1      x ₹170,665.75 \n",
      "981  12:47:35     ₹384.60  443        126         3.5      x ₹170,377.80 \n",
      "982  11:41:35     ₹386.30  443        78          5.7      x ₹171,130.90 \n",
      "983  13:20:39     ₹384.30  437        115         3.8      x ₹167,939.10 \n",
      "984  13:03:58     ₹385.00  436        137         3.2      x ₹167,860.00 \n",
      "985  10:49:23     ₹387.80  429        91          4.7      x ₹166,366.20 \n",
      "986  12:49:31     ₹385.10  428        130         3.3      x ₹164,822.80 \n",
      "987  10:47:52     ₹387.55  425        119         3.6      x ₹164,708.75 \n",
      "988  13:11:15     ₹384.30  401        79          5.1      x ₹154,104.30 \n",
      "989  11:08:09     ₹387.05  384        80          4.8      x ₹148,627.20 \n",
      "990  13:15:16     ₹384.50  359        73          4.9      x ₹138,035.50 \n",
      "991  13:15:53     ₹384.45  345        93          3.7      x ₹132,635.25 \n",
      "992  11:08:14     ₹387.10  336        94          3.6      x ₹130,065.60 \n",
      "993  11:47:15     ₹385.85  317        102         3.1      x ₹122,314.45 \n",
      "994  12:44:54     ₹384.50  305        79          3.8      x ₹117,272.50 \n",
      "995  10:49:38     ₹387.65  278        88          3.2      x ₹107,766.70 \n",
      "996  13:03:35     ₹385.05  276        64          4.3      x ₹106,273.80 \n",
      "997  10:49:31     ₹387.70  264        78          3.4      x ₹102,352.80 \n",
      "998  14:27:42     ₹385.35  260        80          3.2      x ₹100,191.00 \n",
      "999  14:27:38     ₹385.40  255        64          4.0      x ₹98,277.00  \n",
      "1000 11:26:57     ₹386.80  244        56          4.4      x ₹94,379.20  \n",
      "1001 11:03:19     ₹387.05  242        41          5.8      x ₹93,666.10  \n",
      "1002 13:53:33     ₹384.80  233        58          4.0      x ₹89,658.40  \n",
      "1003 12:44:53     ₹384.50  232        69          3.4      x ₹89,204.00  \n",
      "1004 13:11:13     ₹384.35  230        63          3.6      x ₹88,400.50  \n",
      "1005 11:27:00     ₹386.90  223        71          3.2      x ₹86,278.70  \n",
      "1006 14:27:45     ₹385.40  200        62          3.2      x ₹77,080.00  \n",
      "1007 13:53:41     ₹384.80  173        49          3.5      x ₹66,570.40  \n",
      "1008 11:03:32     ₹387.00  130        29          4.4      x ₹50,310.00  \n",
      "\n",
      "=== DETAILED VOLUME BURST ANALYSIS ===\n",
      "\n",
      "--- BURST MAGNITUDE ANALYSIS ---\n",
      "Burst magnitude statistics:\n",
      "  Average multiple: 5.8x\n",
      "  Median multiple: 4.9x\n",
      "  Maximum multiple: 19.6x\n",
      "  Minimum multiple: 3.0x\n",
      "\n",
      "--- BURST SIZE CATEGORIZATION ---\n",
      "Burst size distribution:\n",
      "  Moderate (3-5x): 526 bursts\n",
      "  High (5-10x): 380 bursts\n",
      "  Very High (10-20x): 102 bursts\n",
      "\n",
      "--- TIME DISTRIBUTION OF BURSTS ---\n",
      "Hourly distribution of volume bursts:\n",
      "  09:00-09:59: 103 bursts\n",
      "  10:00-10:59: 132 bursts\n",
      "  11:00-11:59: 162 bursts\n",
      "  12:00-12:59: 147 bursts\n",
      "  13:00-13:59: 166 bursts\n",
      "  14:00-14:59: 152 bursts\n",
      "  15:00-15:59: 146 bursts\n",
      "\n",
      "--- PRICE ANALYSIS DURING BURSTS ---\n",
      "Average price during bursts: ₹386.55\n",
      "Price range during bursts: ₹383.50 - ₹390.20\n",
      "Average price change during bursts: ₹0.0139\n",
      "Price change range during bursts: ₹-0.4500 - ₹0.5500\n",
      "\n",
      "--- BURST CLUSTERING ANALYSIS ---\n",
      "Bursts within 5 minutes of each other: 1007\n",
      "Clustering percentage: 99.9%\n",
      "\n",
      "--- TOP 10 VOLUME BURSTS BY MULTIPLE ---\n",
      "Rank Time         Quantity   Multiple   Rolling Avg  Price   \n",
      "----------------------------------------------------------------------\n",
      "1    15:01:57     153,858    19.6     x 7,855       ₹387.05 \n",
      "2    14:39:07     32,811     19.4     x 1,687       ₹386.05 \n",
      "3    10:00:55     17,077     18.7     x 912         ₹388.50 \n",
      "4    15:07:53     42,697     18.3     x 2,336       ₹387.80 \n",
      "5    10:31:53     20,921     18.1     x 1,157       ₹387.90 \n",
      "6    11:53:29     20,234     17.4     x 1,163       ₹385.75 \n",
      "7    12:11:15     9,910      16.9     x 586         ₹385.70 \n",
      "8    15:11:00     20,741     16.8     x 1,236       ₹387.30 \n",
      "9    13:10:28     14,025     16.6     x 847         ₹384.35 \n",
      "10   14:11:39     26,355     16.5     x 1,598       ₹385.40 \n",
      "\n",
      "=== COMPARISON WITH OVERALL STATISTICS ===\n",
      "Overall average quantity: 1,051\n",
      "Overall median quantity: 200\n",
      "Average quantity during bursts: 6,023\n",
      "Burst average vs overall average: 5.7x\n",
      "\n",
      "=== ROLLING AVERAGE ANALYSIS ===\n",
      "Rolling average window size: 20 trades\n",
      "Average rolling average: 1,065\n",
      "Rolling average range: 23 - 65,740\n",
      "\n",
      "=== EXPORT DATA ===\n",
      "Volume burst data is available in 'volume_bursts' DataFrame\n",
      "Additional columns added:\n",
      "- 'qty_rolling_avg': Rolling average of quantity\n",
      "- 'qty_rolling_std': Rolling standard deviation of quantity\n",
      "- 'volume_burst_threshold': Burst detection threshold\n",
      "- 'burst_multiple': Multiple of rolling average\n",
      "- 'burst_category': Categorization of burst magnitude\n",
      "\n",
      "=== SAMPLE VOLUME BURST DATA (First 5 rows) ===\n",
      "                    date   price     qty  qty_rolling_avg  burst_multiple  \\\n",
      "9280 2025-08-07 15:01:57  387.05  153858          7855.15       19.586895   \n",
      "345  2025-08-07 09:20:41  389.30   67256          7164.35        9.387593   \n",
      "4361 2025-08-07 12:08:06  385.05   60580          4270.55       14.185526   \n",
      "4371 2025-08-07 12:08:12  384.80   55402          6282.75        8.818113   \n",
      "8591 2025-08-07 14:40:45  385.95   54602          4606.65       11.852865   \n",
      "\n",
      "           trnvr  \n",
      "9280  59550738.9  \n",
      "345   26182760.8  \n",
      "4361  23326329.0  \n",
      "4371  21318689.6  \n",
      "8591  21073641.9  \n"
     ]
    }
   ],
   "source": [
    "# Detect volume bursts: qty > 3× rolling average\n",
    "print(\"=== VOLUME BURST DETECTION ANALYSIS ===\")\n",
    "\n",
    "# Set parameters for volume burst detection\n",
    "MULTIPLIER = 3.0  # Volume burst threshold multiplier\n",
    "ROLLING_WINDOW = 20  # Rolling average window size\n",
    "\n",
    "print(f\"Detecting volume bursts where qty > {MULTIPLIER}× rolling average...\")\n",
    "print(f\"Rolling average window: {ROLLING_WINDOW} trades\")\n",
    "\n",
    "# Ensure data is sorted by datetime\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Calculate rolling average of quantity\n",
    "print(\"Calculating rolling average of quantity...\")\n",
    "df['qty_rolling_avg'] = df['qty'].rolling(window=ROLLING_WINDOW, min_periods=1).mean()\n",
    "\n",
    "# Calculate rolling standard deviation for additional context\n",
    "df['qty_rolling_std'] = df['qty'].rolling(window=ROLLING_WINDOW, min_periods=1).std()\n",
    "\n",
    "# Calculate volume burst threshold\n",
    "df['volume_burst_threshold'] = df['qty_rolling_avg'] * MULTIPLIER\n",
    "\n",
    "# Identify volume bursts\n",
    "volume_bursts = df[df['qty'] > df['volume_burst_threshold']].copy()\n",
    "volume_bursts = volume_bursts.sort_values('qty', ascending=False)\n",
    "\n",
    "print(f\"\\n=== VOLUME BURST DETECTION RESULTS ===\")\n",
    "print(f\"Total volume bursts detected: {len(volume_bursts):,}\")\n",
    "print(f\"Percentage of total trades: {(len(volume_bursts)/len(df)*100):.2f}%\")\n",
    "\n",
    "if len(volume_bursts) > 0:\n",
    "    # Calculate burst statistics\n",
    "    total_burst_volume = volume_bursts['qty'].sum()\n",
    "    total_burst_turnover = volume_bursts['trnvr'].sum()\n",
    "    \n",
    "    print(f\"Total volume in bursts: {total_burst_volume:,}\")\n",
    "    print(f\"Percentage of total volume: {(total_burst_volume/df['qty'].sum()*100):.2f}%\")\n",
    "    print(f\"Total turnover in bursts: ₹{total_burst_turnover:,.2f}\")\n",
    "    print(f\"Percentage of total turnover: {(total_burst_turnover/df['trnvr'].sum()*100):.2f}%\")\n",
    "\n",
    "# Display all volume bursts\n",
    "if len(volume_bursts) > 0:\n",
    "    print(f\"\\n=== ALL VOLUME BURSTS (>{MULTIPLIER}× rolling average) ===\")\n",
    "    print(f\"{'Rank':<4} {'Time':<12} {'Price':<8} {'Quantity':<10} {'Rolling Avg':<12} {'Multiple':<10} {'Turnover':<12}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(volume_bursts.iterrows(), 1):\n",
    "        multiple = row['qty'] / row['qty_rolling_avg']\n",
    "        print(f\"{idx:<4} {row['date'].strftime('%H:%M:%S'):<12} ₹{row['price']:<7.2f} {row['qty']:<10,} {row['qty_rolling_avg']:<11,.0f} {multiple:<9.1f}x ₹{row['trnvr']:<11,.2f}\")\n",
    "\n",
    "# Detailed analysis of volume bursts\n",
    "if len(volume_bursts) > 0:\n",
    "    print(f\"\\n=== DETAILED VOLUME BURST ANALYSIS ===\")\n",
    "    \n",
    "    # 1. Burst magnitude analysis\n",
    "    print(\"\\n--- BURST MAGNITUDE ANALYSIS ---\")\n",
    "    # Calculate multiple directly in the DataFrame\n",
    "    volume_bursts['burst_multiple'] = volume_bursts['qty'] / volume_bursts['qty_rolling_avg']\n",
    "    \n",
    "    print(f\"Burst magnitude statistics:\")\n",
    "    print(f\"  Average multiple: {volume_bursts['burst_multiple'].mean():.1f}x\")\n",
    "    print(f\"  Median multiple: {volume_bursts['burst_multiple'].median():.1f}x\")\n",
    "    print(f\"  Maximum multiple: {volume_bursts['burst_multiple'].max():.1f}x\")\n",
    "    print(f\"  Minimum multiple: {volume_bursts['burst_multiple'].min():.1f}x\")\n",
    "    \n",
    "    # 2. Burst size categorization\n",
    "    print(f\"\\n--- BURST SIZE CATEGORIZATION ---\")\n",
    "    \n",
    "    def categorize_burst_size(multiple):\n",
    "        if multiple <= 5:\n",
    "            return 'Moderate (3-5x)'\n",
    "        elif multiple <= 10:\n",
    "            return 'High (5-10x)'\n",
    "        elif multiple <= 20:\n",
    "            return 'Very High (10-20x)'\n",
    "        else:\n",
    "            return 'Extreme (>20x)'\n",
    "    \n",
    "    volume_bursts['burst_category'] = volume_bursts['burst_multiple'].apply(categorize_burst_size)\n",
    "    burst_categories = volume_bursts['burst_category'].value_counts()\n",
    "    \n",
    "    print(\"Burst size distribution:\")\n",
    "    for category, count in burst_categories.items():\n",
    "        print(f\"  {category}: {count} bursts\")\n",
    "    \n",
    "    # 3. Time distribution of bursts\n",
    "    print(f\"\\n--- TIME DISTRIBUTION OF BURSTS ---\")\n",
    "    volume_bursts['hour'] = volume_bursts['date'].dt.hour\n",
    "    hourly_bursts = volume_bursts['hour'].value_counts().sort_index()\n",
    "    \n",
    "    print(\"Hourly distribution of volume bursts:\")\n",
    "    for hour, count in hourly_bursts.items():\n",
    "        print(f\"  {hour:02d}:00-{hour:02d}:59: {count} bursts\")\n",
    "    \n",
    "    # 4. Price analysis during bursts\n",
    "    print(f\"\\n--- PRICE ANALYSIS DURING BURSTS ---\")\n",
    "    print(f\"Average price during bursts: ₹{volume_bursts['price'].mean():.2f}\")\n",
    "    print(f\"Price range during bursts: ₹{volume_bursts['price'].min():.2f} - ₹{volume_bursts['price'].max():.2f}\")\n",
    "    \n",
    "    # Check if bursts coincide with price movements\n",
    "    if 'price_change' in df.columns:\n",
    "        burst_price_changes = volume_bursts['price_change'].dropna()\n",
    "        if len(burst_price_changes) > 0:\n",
    "            print(f\"Average price change during bursts: ₹{burst_price_changes.mean():.4f}\")\n",
    "            print(f\"Price change range during bursts: ₹{burst_price_changes.min():.4f} - ₹{burst_price_changes.max():.4f}\")\n",
    "    \n",
    "    # 5. Burst clustering analysis\n",
    "    print(f\"\\n--- BURST CLUSTERING ANALYSIS ---\")\n",
    "    if len(volume_bursts) > 1:\n",
    "        bursts_sorted = volume_bursts.sort_values('date')\n",
    "        time_diffs = bursts_sorted['date'].diff().dt.total_seconds() / 60  # in minutes\n",
    "        \n",
    "        clustered_bursts = time_diffs[time_diffs <= 5]  # Within 5 minutes\n",
    "        print(f\"Bursts within 5 minutes of each other: {len(clustered_bursts)}\")\n",
    "        print(f\"Clustering percentage: {(len(clustered_bursts)/len(volume_bursts)*100):.1f}%\")\n",
    "    \n",
    "    # 6. Top volume bursts\n",
    "    print(f\"\\n--- TOP 10 VOLUME BURSTS BY MULTIPLE ---\")\n",
    "    # Use the burst_multiple column directly from the DataFrame\n",
    "    top_bursts = volume_bursts.nlargest(10, 'burst_multiple')\n",
    "    \n",
    "    print(f\"{'Rank':<4} {'Time':<12} {'Quantity':<10} {'Multiple':<10} {'Rolling Avg':<12} {'Price':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_bursts.iterrows(), 1):\n",
    "        print(f\"{idx:<4} {row['date'].strftime('%H:%M:%S'):<12} {row['qty']:<10,} {row['burst_multiple']:<9.1f}x {row['qty_rolling_avg']:<11,.0f} ₹{row['price']:<7.2f}\")\n",
    "\n",
    "# Comparison with overall statistics\n",
    "print(f\"\\n=== COMPARISON WITH OVERALL STATISTICS ===\")\n",
    "overall_avg_qty = df['qty'].mean()\n",
    "overall_median_qty = df['qty'].median()\n",
    "\n",
    "print(f\"Overall average quantity: {overall_avg_qty:,.0f}\")\n",
    "print(f\"Overall median quantity: {overall_median_qty:,.0f}\")\n",
    "\n",
    "if len(volume_bursts) > 0:\n",
    "    burst_avg_qty = volume_bursts['qty'].mean()\n",
    "    print(f\"Average quantity during bursts: {burst_avg_qty:,.0f}\")\n",
    "    print(f\"Burst average vs overall average: {burst_avg_qty/overall_avg_qty:.1f}x\")\n",
    "\n",
    "# Rolling average analysis\n",
    "print(f\"\\n=== ROLLING AVERAGE ANALYSIS ===\")\n",
    "print(f\"Rolling average window size: {ROLLING_WINDOW} trades\")\n",
    "print(f\"Average rolling average: {df['qty_rolling_avg'].mean():,.0f}\")\n",
    "print(f\"Rolling average range: {df['qty_rolling_avg'].min():,.0f} - {df['qty_rolling_avg'].max():,.0f}\")\n",
    "\n",
    "# Export volume burst data\n",
    "print(f\"\\n=== EXPORT DATA ===\")\n",
    "print(\"Volume burst data is available in 'volume_bursts' DataFrame\")\n",
    "print(\"Additional columns added:\")\n",
    "print(\"- 'qty_rolling_avg': Rolling average of quantity\")\n",
    "print(\"- 'qty_rolling_std': Rolling standard deviation of quantity\")\n",
    "print(\"- 'volume_burst_threshold': Burst detection threshold\")\n",
    "print(\"- 'burst_multiple': Multiple of rolling average\")\n",
    "print(\"- 'burst_category': Categorization of burst magnitude\")\n",
    "\n",
    "# Display sample of volume burst data\n",
    "if len(volume_bursts) > 0:\n",
    "    print(f\"\\n=== SAMPLE VOLUME BURST DATA (First 5 rows) ===\")\n",
    "    sample_bursts = volume_bursts[['date', 'price', 'qty', 'qty_rolling_avg', 'burst_multiple', 'trnvr']].head(5)\n",
    "    print(sample_bursts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99420454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZERO TRADING DURATION ANALYSIS ===\n",
      "Detecting trading breaks longer than 5 minutes...\n",
      "Market hours: 09:00 - 15:59\n",
      "Calculating time gaps between trades...\n",
      "\n",
      "=== TRADING BREAK DETECTION RESULTS ===\n",
      "Total potential breaks detected: 0\n",
      "Break threshold: 5 minutes\n",
      "\n",
      "=== MARKET HOURS ANALYSIS ===\n",
      "Market hours: 09:00 - 15:59\n",
      "Total market minutes: 420\n",
      "Trading minutes: 10956\n",
      "Break minutes: -10536\n",
      "Break percentage: -2508.7%\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total trades analyzed: 10,956\n",
      "Total potential breaks: 0\n",
      "Break detection threshold: 5 minutes\n",
      "\n",
      "=== EXPORT DATA ===\n",
      "Trading break data is available in:\n",
      "- 'potential_breaks': DataFrame with all detected breaks\n",
      "- 'break_impacts_df': DataFrame with price impact analysis\n"
     ]
    }
   ],
   "source": [
    "# Flag periods with zero trading for long durations (possible breaks)\n",
    "print(\"=== ZERO TRADING DURATION ANALYSIS ===\")\n",
    "\n",
    "# Set parameters for break detection\n",
    "MIN_BREAK_DURATION_MINUTES = 5  # Minimum duration to consider as a break\n",
    "MARKET_HOURS = (9, 15)  # Market hours (9 AM to 3 PM)\n",
    "\n",
    "print(f\"Detecting trading breaks longer than {MIN_BREAK_DURATION_MINUTES} minutes...\")\n",
    "print(f\"Market hours: {MARKET_HOURS[0]:02d}:00 - {MARKET_HOURS[1]:02d}:59\")\n",
    "\n",
    "# Ensure data is sorted by datetime\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Calculate time differences between consecutive trades\n",
    "print(\"Calculating time gaps between trades...\")\n",
    "df['next_trade_time'] = df['date'].shift(-1)\n",
    "df['time_gap_minutes'] = (df['next_trade_time'] - df['date']).dt.total_seconds() / 60\n",
    "\n",
    "# Identify potential breaks (gaps longer than threshold)\n",
    "potential_breaks = df[df['time_gap_minutes'] > MIN_BREAK_DURATION_MINUTES].copy()\n",
    "potential_breaks = potential_breaks.sort_values('time_gap_minutes', ascending=False)\n",
    "\n",
    "print(f\"\\n=== TRADING BREAK DETECTION RESULTS ===\")\n",
    "print(f\"Total potential breaks detected: {len(potential_breaks):,}\")\n",
    "print(f\"Break threshold: {MIN_BREAK_DURATION_MINUTES} minutes\")\n",
    "\n",
    "if len(potential_breaks) > 0:\n",
    "    # Calculate break statistics\n",
    "    total_break_time = potential_breaks['time_gap_minutes'].sum()\n",
    "    avg_break_duration = potential_breaks['time_gap_minutes'].mean()\n",
    "    max_break_duration = potential_breaks['time_gap_minutes'].max()\n",
    "    \n",
    "    print(f\"Total break time: {total_break_time:.1f} minutes\")\n",
    "    print(f\"Average break duration: {avg_break_duration:.1f} minutes\")\n",
    "    print(f\"Longest break: {max_break_duration:.1f} minutes\")\n",
    "\n",
    "# Display all potential breaks\n",
    "if len(potential_breaks) > 0:\n",
    "    print(f\"\\n=== ALL TRADING BREAKS (>{MIN_BREAK_DURATION_MINUTES} minutes) ===\")\n",
    "    print(f\"{'Rank':<4} {'Start Time':<12} {'End Time':<12} {'Duration':<10} {'Start Price':<12} {'End Price':<12} {'Price Change':<12}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(potential_breaks.iterrows(), 1):\n",
    "        start_time = row['date']\n",
    "        end_time = row['next_trade_time']\n",
    "        duration = row['time_gap_minutes']\n",
    "        start_price = row['price']\n",
    "        \n",
    "        # Find the price at the end of the break\n",
    "        end_price = df[df['date'] == end_time]['price'].iloc[0] if not df[df['date'] == end_time].empty else start_price\n",
    "        price_change = end_price - start_price\n",
    "        price_change_pct = (price_change / start_price) * 100 if start_price != 0 else 0\n",
    "        \n",
    "        print(f\"{idx:<4} {start_time.strftime('%H:%M:%S'):<12} {end_time.strftime('%H:%M:%S'):<12} {duration:<9.1f}m ₹{start_price:<11.2f} ₹{end_price:<11.2f} ₹{price_change:<11.2f} ({price_change_pct:+.2f}%)\")\n",
    "\n",
    "# Detailed analysis of trading breaks\n",
    "if len(potential_breaks) > 0:\n",
    "    print(f\"\\n=== DETAILED BREAK ANALYSIS ===\")\n",
    "    \n",
    "    # 1. Break duration categorization\n",
    "    print(\"\\n--- BREAK DURATION CATEGORIZATION ---\")\n",
    "    \n",
    "    def categorize_break_duration(minutes):\n",
    "        if minutes <= 10:\n",
    "            return 'Short (5-10 min)'\n",
    "        elif minutes <= 30:\n",
    "            return 'Medium (10-30 min)'\n",
    "        elif minutes <= 60:\n",
    "            return 'Long (30-60 min)'\n",
    "        else:\n",
    "            return 'Very Long (>60 min)'\n",
    "    \n",
    "    potential_breaks['break_category'] = potential_breaks['time_gap_minutes'].apply(categorize_break_duration)\n",
    "    break_categories = potential_breaks['break_category'].value_counts()\n",
    "    \n",
    "    print(\"Break duration distribution:\")\n",
    "    for category, count in break_categories.items():\n",
    "        print(f\"  {category}: {count} breaks\")\n",
    "    \n",
    "    # 2. Time distribution of breaks\n",
    "    print(f\"\\n--- TIME DISTRIBUTION OF BREAKS ---\")\n",
    "    potential_breaks['hour'] = potential_breaks['date'].dt.hour\n",
    "    hourly_breaks = potential_breaks['hour'].value_counts().sort_index()\n",
    "    \n",
    "    print(\"Hourly distribution of trading breaks:\")\n",
    "    for hour, count in hourly_breaks.items():\n",
    "        print(f\"  {hour:02d}:00-{hour:02d}:59: {count} breaks\")\n",
    "    \n",
    "    # 3. Break impact analysis\n",
    "    print(f\"\\n--- BREAK IMPACT ANALYSIS ---\")\n",
    "    \n",
    "    # Calculate price changes across breaks\n",
    "    break_impacts = []\n",
    "    for idx, (_, row) in enumerate(potential_breaks.iterrows()):\n",
    "        start_time = row['date']\n",
    "        end_time = row['next_trade_time']\n",
    "        duration = row['time_gap_minutes']\n",
    "        start_price = row['price']\n",
    "        \n",
    "        # Find the price at the end of the break\n",
    "        end_price = df[df['date'] == end_time]['price'].iloc[0] if not df[df['date'] == end_time].empty else start_price\n",
    "        price_change = end_price - start_price\n",
    "        price_change_pct = (price_change / start_price) * 100 if start_price != 0 else 0\n",
    "        \n",
    "        break_impacts.append({\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'duration': duration,\n",
    "            'start_price': start_price,\n",
    "            'end_price': end_price,\n",
    "            'price_change': price_change,\n",
    "            'price_change_pct': price_change_pct\n",
    "        })\n",
    "    \n",
    "    break_impacts_df = pd.DataFrame(break_impacts)\n",
    "    \n",
    "    if len(break_impacts_df) > 0:\n",
    "        print(f\"Price change statistics across breaks:\")\n",
    "        print(f\"  Average price change: ₹{break_impacts_df['price_change'].mean():.4f}\")\n",
    "        print(f\"  Average percentage change: {break_impacts_df['price_change_pct'].mean():.2f}%\")\n",
    "        print(f\"  Largest price increase: ₹{break_impacts_df['price_change'].max():.4f}\")\n",
    "        print(f\"  Largest price decrease: ₹{break_impacts_df['price_change'].min():.4f}\")\n",
    "        \n",
    "        # Count positive vs negative price changes\n",
    "        positive_changes = (break_impacts_df['price_change'] > 0).sum()\n",
    "        negative_changes = (break_impacts_df['price_change'] < 0).sum()\n",
    "        no_changes = (break_impacts_df['price_change'] == 0).sum()\n",
    "        \n",
    "        print(f\"\\nPrice change direction across breaks:\")\n",
    "        print(f\"  Price increases: {positive_changes} breaks\")\n",
    "        print(f\"  Price decreases: {negative_changes} breaks\")\n",
    "        print(f\"  No change: {no_changes} breaks\")\n",
    "    \n",
    "    # 4. Longest breaks analysis\n",
    "    print(f\"\\n--- LONGEST BREAKS ANALYSIS ---\")\n",
    "    longest_breaks = potential_breaks.nlargest(5, 'time_gap_minutes')\n",
    "    \n",
    "    print(\"Top 5 longest trading breaks:\")\n",
    "    for idx, (_, row) in enumerate(longest_breaks.iterrows(), 1):\n",
    "        print(f\"{idx}. {row['date'].strftime('%H:%M:%S')} - {row['next_trade_time'].strftime('%H:%M:%S')} ({row['time_gap_minutes']:.1f} minutes)\")\n",
    "    \n",
    "    # 5. Break clustering analysis\n",
    "    print(f\"\\n--- BREAK CLUSTERING ANALYSIS ---\")\n",
    "    if len(potential_breaks) > 1:\n",
    "        breaks_sorted = potential_breaks.sort_values('date')\n",
    "        break_time_diffs = breaks_sorted['date'].diff().dt.total_seconds() / 60  # in minutes\n",
    "        \n",
    "        clustered_breaks = break_time_diffs[break_time_diffs <= 30]  # Within 30 minutes\n",
    "        print(f\"Breaks within 30 minutes of each other: {len(clustered_breaks)}\")\n",
    "        print(f\"Clustering percentage: {(len(clustered_breaks)/len(potential_breaks)*100):.1f}%\")\n",
    "\n",
    "# Market hours analysis\n",
    "print(f\"\\n=== MARKET HOURS ANALYSIS ===\")\n",
    "market_start = pd.Timestamp(df['date'].dt.date.iloc[0]).replace(hour=MARKET_HOURS[0], minute=0, second=0)\n",
    "market_end = pd.Timestamp(df['date'].dt.date.iloc[0]).replace(hour=MARKET_HOURS[1], minute=59, second=59)\n",
    "\n",
    "total_market_minutes = (market_end - market_start).total_seconds() / 60\n",
    "trading_minutes = len(df)  # Assuming 1 tick = 1 minute (approximate)\n",
    "break_minutes = total_market_minutes - trading_minutes\n",
    "\n",
    "print(f\"Market hours: {market_start.strftime('%H:%M')} - {market_end.strftime('%H:%M')}\")\n",
    "print(f\"Total market minutes: {total_market_minutes:.0f}\")\n",
    "print(f\"Trading minutes: {trading_minutes}\")\n",
    "print(f\"Break minutes: {break_minutes:.0f}\")\n",
    "print(f\"Break percentage: {(break_minutes/total_market_minutes*100):.1f}%\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Total trades analyzed: {len(df):,}\")\n",
    "print(f\"Total potential breaks: {len(potential_breaks):,}\")\n",
    "print(f\"Break detection threshold: {MIN_BREAK_DURATION_MINUTES} minutes\")\n",
    "\n",
    "if len(potential_breaks) > 0:\n",
    "    print(f\"Average break duration: {potential_breaks['time_gap_minutes'].mean():.1f} minutes\")\n",
    "    print(f\"Total break time: {potential_breaks['time_gap_minutes'].sum():.1f} minutes\")\n",
    "    print(f\"Break frequency: {len(potential_breaks)/len(df)*100:.2f}%\")\n",
    "\n",
    "# Export break data\n",
    "print(f\"\\n=== EXPORT DATA ===\")\n",
    "print(\"Trading break data is available in:\")\n",
    "print(\"- 'potential_breaks': DataFrame with all detected breaks\")\n",
    "print(\"- 'break_impacts_df': DataFrame with price impact analysis\")\n",
    "\n",
    "# Display sample of break data\n",
    "if len(potential_breaks) > 0:\n",
    "    print(f\"\\n=== SAMPLE BREAK DATA (First 5 rows) ===\")\n",
    "    sample_breaks = potential_breaks[['date', 'next_trade_time', 'time_gap_minutes', 'price', 'break_category']].head(5)\n",
    "    print(sample_breaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c54a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a577c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a9292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6a4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
