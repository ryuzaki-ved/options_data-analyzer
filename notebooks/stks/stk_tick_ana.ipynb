{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45861f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "File path: D:\\Market Projects\\options_data_analyzer\\Aug '25\\Aug 07 Exp\\07 Aug\\BEL_EQ.csv\n",
      "Shape: (18250, 5)\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr']\n",
      "\n",
      "First few rows:\n",
      "                     date   price    qty        trnvr    cum_trnvr\n",
      "0  2025-08-07 09:15:00 AM  386.85  65740  25431519.00  25431519.00\n",
      "1  2025-08-07 09:15:01 AM  386.65      0         0.00  25431519.00\n",
      "2  2025-08-07 09:15:01 AM  386.30      0         0.00  25431519.00\n",
      "3  2025-08-07 09:15:01 AM  386.30    895    345738.50  25777257.50\n",
      "4  2025-08-07 09:15:01 AM  386.75   1401    541836.75  26319094.25\n",
      "\n",
      "Data types:\n",
      "date          object\n",
      "price        float64\n",
      "qty            int64\n",
      "trnvr        float64\n",
      "cum_trnvr    float64\n",
      "dtype: object\n",
      "\n",
      "Basic statistics:\n",
      "              price            qty         trnvr     cum_trnvr\n",
      "count  18250.000000   18250.000000  1.825000e+04  1.825000e+04\n",
      "mean     386.537181     630.694301  2.439435e+05  2.317732e+09\n",
      "std        1.570300    2651.792039  1.026096e+06  1.129666e+09\n",
      "min      383.500000       0.000000  0.000000e+00  2.543152e+07\n",
      "25%      385.150000       0.000000  0.000000e+00  1.473757e+09\n",
      "50%      386.400000      10.000000  3.850250e+03  2.248665e+09\n",
      "75%      387.950000     331.000000  1.284426e+05  3.123428e+09\n",
      "max      390.200000  153858.000000  5.955074e+07  4.451969e+09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"D:\\Market Projects\\options_data_analyzer\\Aug '25\\Aug 07 Exp\\07 Aug\\BEL_EQ.csv\"\n",
    "\n",
    "# Load CSV with pandas\n",
    "# Using default encoding (utf-8) and comma delimiter\n",
    "# The file appears to have standard CSV format\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the loaded data\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"File path: {file_path}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc1406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FIRST 10 ROWS ===\n",
      "                     date   price    qty        trnvr    cum_trnvr\n",
      "0  2025-08-07 09:15:00 AM  386.85  65740  25431519.00  25431519.00\n",
      "1  2025-08-07 09:15:01 AM  386.65      0         0.00  25431519.00\n",
      "2  2025-08-07 09:15:01 AM  386.30      0         0.00  25431519.00\n",
      "3  2025-08-07 09:15:01 AM  386.30    895    345738.50  25777257.50\n",
      "4  2025-08-07 09:15:01 AM  386.75   1401    541836.75  26319094.25\n",
      "5  2025-08-07 09:15:02 AM  386.80   1795    694306.00  27013400.25\n",
      "6  2025-08-07 09:15:02 AM  386.95    741    286729.95  27300130.20\n",
      "7  2025-08-07 09:15:03 AM  386.85      0         0.00  27300130.20\n",
      "8  2025-08-07 09:15:03 AM  386.50      0         0.00  27300130.20\n",
      "9  2025-08-07 09:15:03 AM  386.90   2717   1051207.30  28351337.50\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== LAST 10 ROWS ===\n",
      "                         date   price   qty       trnvr     cum_trnvr\n",
      "18240  2025-08-07 03:29:31 PM  388.25   226    87744.50  4.446928e+09\n",
      "18241  2025-08-07 03:29:31 PM  388.10     0        0.00  4.446928e+09\n",
      "18242  2025-08-07 03:29:37 PM  388.25  2075   805618.75  4.447734e+09\n",
      "18243  2025-08-07 03:29:39 PM  388.30  1157   449263.10  4.448183e+09\n",
      "18244  2025-08-07 03:29:41 PM  388.10     0        0.00  4.448183e+09\n",
      "18245  2025-08-07 03:29:44 PM  388.25  1183   459299.75  4.448643e+09\n",
      "18246  2025-08-07 03:29:46 PM  388.25   958   371943.50  4.449015e+09\n",
      "18247  2025-08-07 03:29:51 PM  388.25  5331  2069760.75  4.451084e+09\n",
      "18248  2025-08-07 03:29:52 PM  388.25   539   209266.75  4.451294e+09\n",
      "18249  2025-08-07 03:29:58 PM  388.25  1740   675555.00  4.451969e+09\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== CHRONOLOGICAL ORDER CHECK ===\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "✓ Data is in CHRONOLOGICAL order (ascending)\n",
      "  - First row: Earliest time\n",
      "  - Last row: Latest time\n",
      "\n",
      "Total time range: 0 days 06:14:58\n"
     ]
    }
   ],
   "source": [
    "# Preview first and last 10 rows to check ordering\n",
    "print(\"=== FIRST 10 ROWS ===\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"=== LAST 10 ROWS ===\")\n",
    "print(df.tail(10))\n",
    "\n",
    "# Check if data is in chronological order\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"=== CHRONOLOGICAL ORDER CHECK ===\")\n",
    "\n",
    "# Convert date column to datetime if not already\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Check first and last timestamps\n",
    "first_time = df['date'].iloc[0]\n",
    "last_time = df['date'].iloc[-1]\n",
    "\n",
    "print(f\"First timestamp: {first_time}\")\n",
    "print(f\"Last timestamp: {last_time}\")\n",
    "\n",
    "# Check if chronological (ascending) or reverse chronological (descending)\n",
    "if first_time < last_time:\n",
    "    print(\"✓ Data is in CHRONOLOGICAL order (ascending)\")\n",
    "    print(\"  - First row: Earliest time\")\n",
    "    print(\"  - Last row: Latest time\")\n",
    "else:\n",
    "    print(\"✗ Data is in REVERSE CHRONOLOGICAL order (descending)\")\n",
    "    print(\"  - First row: Latest time\")\n",
    "    print(\"  - Last row: Earliest time\")\n",
    "\n",
    "# Show time range\n",
    "time_range = last_time - first_time\n",
    "print(f\"\\nTotal time range: {time_range}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17543f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATETIME CONVERSION AND FEATURE EXTRACTION ===\n",
      "New datetime features added:\n",
      "  - date_only: object\n",
      "  - time: object\n",
      "  - hour: int32\n",
      "  - minute: int32\n",
      "  - second: int32\n",
      "\n",
      "=== SAMPLE DATA WITH NEW FEATURES ===\n",
      "                 date   date_only      time  hour  minute  second   price  \\\n",
      "0 2025-08-07 09:15:00  2025-08-07  09:15:00     9      15       0  386.85   \n",
      "1 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.65   \n",
      "2 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.30   \n",
      "3 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.30   \n",
      "4 2025-08-07 09:15:01  2025-08-07  09:15:01     9      15       1  386.75   \n",
      "5 2025-08-07 09:15:02  2025-08-07  09:15:02     9      15       2  386.80   \n",
      "6 2025-08-07 09:15:02  2025-08-07  09:15:02     9      15       2  386.95   \n",
      "7 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.85   \n",
      "8 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.50   \n",
      "9 2025-08-07 09:15:03  2025-08-07  09:15:03     9      15       3  386.90   \n",
      "\n",
      "     qty  \n",
      "0  65740  \n",
      "1      0  \n",
      "2      0  \n",
      "3    895  \n",
      "4   1401  \n",
      "5   1795  \n",
      "6    741  \n",
      "7      0  \n",
      "8      0  \n",
      "9   2717  \n",
      "\n",
      "=== DATETIME VERIFICATION ===\n",
      "Original date column dtype: datetime64[ns]\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "Total unique dates: 1\n",
      "Date range: 2025-08-07 to 2025-08-07\n"
     ]
    }
   ],
   "source": [
    "# Convert date to datetime64[ns] and extract datetime features\n",
    "print(\"=== DATETIME CONVERSION AND FEATURE EXTRACTION ===\")\n",
    "\n",
    "# Convert date column to datetime64[ns]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract additional datetime features\n",
    "df['date_only'] = df['date'].dt.date\n",
    "df['time'] = df['date'].dt.time\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "df['second'] = df['date'].dt.second\n",
    "\n",
    "# Display the new datetime features\n",
    "print(\"New datetime features added:\")\n",
    "print(f\"  - date_only: {df['date_only'].dtype}\")\n",
    "print(f\"  - time: {df['time'].dtype}\")\n",
    "print(f\"  - hour: {df['hour'].dtype}\")\n",
    "print(f\"  - minute: {df['minute'].dtype}\")\n",
    "print(f\"  - second: {df['second'].dtype}\")\n",
    "\n",
    "# Show sample of the enhanced dataframe\n",
    "print(\"\\n=== SAMPLE DATA WITH NEW FEATURES ===\")\n",
    "print(df[['date', 'date_only', 'time', 'hour', 'minute', 'second', 'price', 'qty']].head(10))\n",
    "\n",
    "# Verify datetime conversion\n",
    "print(f\"\\n=== DATETIME VERIFICATION ===\")\n",
    "print(f\"Original date column dtype: {df['date'].dtype}\")\n",
    "print(f\"First timestamp: {df['date'].iloc[0]}\")\n",
    "print(f\"Last timestamp: {df['date'].iloc[-1]}\")\n",
    "print(f\"Total unique dates: {df['date_only'].nunique()}\")\n",
    "print(f\"Date range: {df['date_only'].min()} to {df['date_only'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2229a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HANDLING ZERO-QUANTITY TRADES ===\n",
      "Original data shape: (18250, 10)\n",
      "Rows with zero quantity: 7294\n",
      "Percentage of zero qty rows: 39.97%\n",
      "\n",
      "=== SAMPLE OF ZERO QTY ROWS (BEFORE REMOVAL) ===\n",
      "                  date   price  qty  trnvr    cum_trnvr\n",
      "1  2025-08-07 09:15:01  386.65    0    0.0  25431519.00\n",
      "2  2025-08-07 09:15:01  386.30    0    0.0  25431519.00\n",
      "7  2025-08-07 09:15:03  386.85    0    0.0  27300130.20\n",
      "8  2025-08-07 09:15:03  386.50    0    0.0  27300130.20\n",
      "13 2025-08-07 09:15:05  386.45    0    0.0  32995767.85\n",
      "\n",
      "=== AFTER CLEANING ===\n",
      "Cleaned data shape: (10956, 10)\n",
      "Rows removed: 7294\n",
      "Remaining rows: 10956\n",
      "\n",
      "=== SAMPLE OF CLEANED DATA ===\n",
      "                 date   price    qty        trnvr    cum_trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30    895    345738.50  25777257.50\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75  26319094.25\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00  27013400.25\n",
      "4 2025-08-07 09:15:02  386.95    741    286729.95  27300130.20\n",
      "5 2025-08-07 09:15:03  386.90   2717   1051207.30  28351337.50\n",
      "6 2025-08-07 09:15:03  386.80   9068   3507502.40  31858839.90\n",
      "7 2025-08-07 09:15:04  386.75   1141    441281.75  32300121.65\n",
      "8 2025-08-07 09:15:04  386.90   1798    695646.20  32995767.85\n",
      "9 2025-08-07 09:15:05  386.65   2092    808871.80  33804639.65\n",
      "\n",
      "Zero qty rows remaining: 0\n",
      "\n",
      "✓ Main dataframe 'df' now contains 10956 rows with non-zero quantities\n"
     ]
    }
   ],
   "source": [
    "# Handle zero-quantity trades - remove rows with 0 qty\n",
    "print(\"=== HANDLING ZERO-QUANTITY TRADES ===\")\n",
    "\n",
    "# Check current data shape and zero qty count\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "zero_qty_count = (df['qty'] == 0).sum()\n",
    "print(f\"Rows with zero quantity: {zero_qty_count}\")\n",
    "print(f\"Percentage of zero qty rows: {(zero_qty_count/len(df)*100):.2f}%\")\n",
    "\n",
    "# Show sample of zero qty rows before removal\n",
    "print(\"\\n=== SAMPLE OF ZERO QTY ROWS (BEFORE REMOVAL) ===\")\n",
    "zero_qty_sample = df[df['qty'] == 0][['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(5)\n",
    "print(zero_qty_sample)\n",
    "\n",
    "# Remove rows with zero quantity\n",
    "df_clean = df[df['qty'] > 0].copy()\n",
    "\n",
    "# Reset index after filtering\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "# Display results after cleaning\n",
    "print(f\"\\n=== AFTER CLEANING ===\")\n",
    "print(f\"Cleaned data shape: {df_clean.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")\n",
    "print(f\"Remaining rows: {len(df_clean)}\")\n",
    "\n",
    "# Show sample of cleaned data\n",
    "print(\"\\n=== SAMPLE OF CLEANED DATA ===\")\n",
    "print(df_clean[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(10))\n",
    "\n",
    "# Verify no zero qty rows remain\n",
    "remaining_zero_qty = (df_clean['qty'] == 0).sum()\n",
    "print(f\"\\nZero qty rows remaining: {remaining_zero_qty}\")\n",
    "\n",
    "# Update the main dataframe reference\n",
    "df = df_clean\n",
    "print(f\"\\n✓ Main dataframe 'df' now contains {len(df)} rows with non-zero quantities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73b099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NUMERIC COLUMN VALIDATION ===\n",
      "=== NEGATIVE VALUE CHECK ===\n",
      "price: 0 negative values\n",
      "qty: 0 negative values\n",
      "trnvr: 0 negative values\n",
      "cum_trnvr: 0 negative values\n",
      "\n",
      "=== ZERO VALUE CHECK ===\n",
      "price: 0 zero values\n",
      "qty: 0 zero values\n",
      "trnvr: 0 zero values\n",
      "cum_trnvr: 0 zero values\n",
      "\n",
      "=== STATISTICAL SUMMARY ===\n",
      "              price            qty         trnvr     cum_trnvr\n",
      "count  10956.000000   10956.000000  1.095600e+04  1.095600e+04\n",
      "mean     386.561094    1050.581508  4.063499e+05  2.377823e+09\n",
      "std        1.574324    3357.505716  1.299189e+06  1.165181e+09\n",
      "min      383.500000       1.000000  3.836000e+02  2.543152e+07\n",
      "25%      385.150000      26.000000  1.003177e+04  1.490814e+09\n",
      "50%      386.450000     200.000000  7.732500e+04  2.355502e+09\n",
      "75%      387.950000     799.000000  3.085895e+05  3.321858e+09\n",
      "max      390.200000  153858.000000  5.955074e+07  4.451969e+09\n",
      "\n",
      "=== OUTLIER DETECTION (IQR METHOD) ===\n",
      "\n",
      "price:\n",
      "  Q1: 385.15, Q3: 387.95, IQR: 2.80\n",
      "  Lower bound: 380.95, Upper bound: 392.15\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 0\n",
      "\n",
      "qty:\n",
      "  Q1: 26.00, Q3: 799.00, IQR: 773.00\n",
      "  Lower bound: -1133.50, Upper bound: 1958.50\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 1337\n",
      "\n",
      "trnvr:\n",
      "  Q1: 10031.77, Q3: 308589.53, IQR: 298557.75\n",
      "  Lower bound: -437804.85, Upper bound: 756426.15\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 1340\n",
      "\n",
      "cum_trnvr:\n",
      "  Q1: 1490814230.85, Q3: 3321857538.50, IQR: 1831043307.65\n",
      "  Lower bound: -1255750730.62, Upper bound: 6068422499.97\n",
      "  Outliers below lower bound: 0\n",
      "  Outliers above upper bound: 0\n",
      "\n",
      "=== EXTREME VALUE CHECK (3 STD DEV) ===\n",
      "\n",
      "price:\n",
      "  Mean: 386.56, Std: 1.57\n",
      "  Lower 3σ: 381.84, Upper 3σ: 391.28\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 0\n",
      "\n",
      "qty:\n",
      "  Mean: 1050.58, Std: 3357.51\n",
      "  Lower 3σ: -9021.94, Upper 3σ: 11123.10\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 148\n",
      "\n",
      "trnvr:\n",
      "  Mean: 406349.86, Std: 1299188.95\n",
      "  Lower 3σ: -3491216.99, Upper 3σ: 4303916.71\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 149\n",
      "\n",
      "cum_trnvr:\n",
      "  Mean: 2377822586.83, Std: 1165180692.88\n",
      "  Lower 3σ: -1117719491.81, Upper 3σ: 5873364665.46\n",
      "  Extreme values below: 0\n",
      "  Extreme values above: 0\n",
      "\n",
      "=== SAMPLE OF POTENTIAL OUTLIERS ===\n",
      "\n",
      "qty outliers (top 5):\n",
      "                  date    qty    qty        trnvr\n",
      "0  2025-08-07 09:15:00  65740  65740  25431519.00\n",
      "5  2025-08-07 09:15:03   2717   2717   1051207.30\n",
      "6  2025-08-07 09:15:03   9068   9068   3507502.40\n",
      "9  2025-08-07 09:15:05   2092   2092    808871.80\n",
      "11 2025-08-07 09:15:06   4519   4519   1747271.35\n",
      "\n",
      "trnvr outliers (top 5):\n",
      "                  date        trnvr    qty        trnvr\n",
      "0  2025-08-07 09:15:00  25431519.00  65740  25431519.00\n",
      "5  2025-08-07 09:15:03   1051207.30   2717   1051207.30\n",
      "6  2025-08-07 09:15:03   3507502.40   9068   3507502.40\n",
      "9  2025-08-07 09:15:05    808871.80   2092    808871.80\n",
      "11 2025-08-07 09:15:06   1747271.35   4519   1747271.35\n",
      "\n",
      "=== DATA QUALITY SUMMARY ===\n",
      "Total rows: 10956\n",
      "Columns with potential issues:\n",
      "  price: ✓ clean\n",
      "  qty: ✓ clean\n",
      "  trnvr: ✓ clean\n",
      "  cum_trnvr: ✓ clean\n"
     ]
    }
   ],
   "source": [
    "# Validate numeric columns for negatives or outliers\n",
    "print(\"=== NUMERIC COLUMN VALIDATION ===\")\n",
    "\n",
    "# List of numeric columns to validate\n",
    "numeric_cols = ['price', 'qty', 'trnvr', 'cum_trnvr']\n",
    "\n",
    "# Check for negative values\n",
    "print(\"=== NEGATIVE VALUE CHECK ===\")\n",
    "for col in numeric_cols:\n",
    "    negative_count = (df[col] < 0).sum()\n",
    "    print(f\"{col}: {negative_count} negative values\")\n",
    "\n",
    "# Check for zero values (after qty cleaning)\n",
    "print(\"\\n=== ZERO VALUE CHECK ===\")\n",
    "for col in numeric_cols:\n",
    "    zero_count = (df[col] == 0).sum()\n",
    "    print(f\"{col}: {zero_count} zero values\")\n",
    "\n",
    "# Statistical summary for outlier detection\n",
    "print(\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Outlier detection using IQR method\n",
    "print(\"\\n=== OUTLIER DETECTION (IQR METHOD) ===\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_lower = (df[col] < lower_bound).sum()\n",
    "    outliers_upper = (df[col] > upper_bound).sum()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "    print(f\"  Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
    "    print(f\"  Outliers below lower bound: {outliers_lower}\")\n",
    "    print(f\"  Outliers above upper bound: {outliers_upper}\")\n",
    "\n",
    "# Check for extreme values (beyond 3 standard deviations)\n",
    "print(\"\\n=== EXTREME VALUE CHECK (3 STD DEV) ===\")\n",
    "for col in numeric_cols:\n",
    "    mean_val = df[col].mean()\n",
    "    std_val = df[col].std()\n",
    "    \n",
    "    lower_3std = mean_val - 3 * std_val\n",
    "    upper_3std = mean_val + 3 * std_val\n",
    "    \n",
    "    extreme_lower = (df[col] < lower_3std).sum()\n",
    "    extreme_upper = (df[col] > upper_3std).sum()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {mean_val:.2f}, Std: {std_val:.2f}\")\n",
    "    print(f\"  Lower 3σ: {lower_3std:.2f}, Upper 3σ: {upper_3std:.2f}\")\n",
    "    print(f\"  Extreme values below: {extreme_lower}\")\n",
    "    print(f\"  Extreme values above: {extreme_upper}\")\n",
    "\n",
    "# Show sample of potential outliers\n",
    "print(\"\\n=== SAMPLE OF POTENTIAL OUTLIERS ===\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[df[col] > upper_bound]\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"\\n{col} outliers (top 5):\")\n",
    "        print(outliers[['date', col, 'qty', 'trnvr']].head())\n",
    "\n",
    "# Data quality summary\n",
    "print(\"\\n=== DATA QUALITY SUMMARY ===\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Columns with potential issues:\")\n",
    "for col in numeric_cols:\n",
    "    issues = []\n",
    "    if (df[col] < 0).any():\n",
    "        issues.append(\"negative values\")\n",
    "    if (df[col] == 0).any() and col != 'qty':  # qty can legitimately be 0\n",
    "        issues.append(\"zero values\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"  {col}: {', '.join(issues)}\")\n",
    "    else:\n",
    "        print(f\"  {col}: ✓ clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fe8c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TIME-SERIES INTEGRITY CHECK AND SORTING ===\n",
      "=== CURRENT SORTING STATUS ===\n",
      "First timestamp: 2025-08-07 09:15:00\n",
      "Last timestamp: 2025-08-07 15:29:58\n",
      "Data is already sorted chronologically: True\n",
      "Duplicate timestamps: 1961\n",
      "\n",
      "=== DUPLICATE TIMESTAMP ANALYSIS ===\n",
      "Sample duplicate timestamps:\n",
      "                  date   price   qty       trnvr\n",
      "1  2025-08-07 09:15:01  386.30   895   345738.50\n",
      "2  2025-08-07 09:15:01  386.75  1401   541836.75\n",
      "3  2025-08-07 09:15:02  386.80  1795   694306.00\n",
      "4  2025-08-07 09:15:02  386.95   741   286729.95\n",
      "5  2025-08-07 09:15:03  386.90  2717  1051207.30\n",
      "6  2025-08-07 09:15:03  386.80  9068  3507502.40\n",
      "7  2025-08-07 09:15:04  386.75  1141   441281.75\n",
      "8  2025-08-07 09:15:04  386.90  1798   695646.20\n",
      "9  2025-08-07 09:15:05  386.65  2092   808871.80\n",
      "10 2025-08-07 09:15:05  386.75  1679   649353.25\n",
      "\n",
      "=== SORTING DATA BY DATETIME ===\n",
      "Data is now sorted chronologically: True\n",
      "\n",
      "=== SORTING VERIFICATION ===\n",
      "First 5 rows after sorting:\n",
      "                 date   price    qty        trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30    895    345738.50\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00\n",
      "4 2025-08-07 09:15:02  386.95    741    286729.95\n",
      "\n",
      "Last 5 rows after sorting:\n",
      "                     date   price   qty       trnvr\n",
      "10951 2025-08-07 15:29:44  388.25  1183   459299.75\n",
      "10952 2025-08-07 15:29:46  388.25   958   371943.50\n",
      "10953 2025-08-07 15:29:51  388.25  5331  2069760.75\n",
      "10954 2025-08-07 15:29:52  388.25   539   209266.75\n",
      "10955 2025-08-07 15:29:58  388.25  1740   675555.00\n",
      "\n",
      "=== TIME SERIES CONTINUITY CHECK ===\n",
      "Time differences between consecutive rows:\n",
      "  Min: 0 days 00:00:00\n",
      "  Max: 0 days 00:00:12\n",
      "  Mean: 0 days 00:00:02.053674121\n",
      "  Most common: 0 days 00:00:01\n",
      "\n",
      "✓ Main dataframe 'df' is now properly sorted chronologically\n",
      "✓ Total rows: 10956\n",
      "✓ Time range: 2025-08-07 09:15:00 to 2025-08-07 15:29:58\n",
      "\n",
      "=== FINAL VERIFICATION ===\n",
      "✓ Data is sorted chronologically\n",
      "✓ Index is reset and sequential\n",
      "✓ Ready for time-series analysis\n"
     ]
    }
   ],
   "source": [
    "# Ensure sorting by datetime for time-series integrity\n",
    "print(\"=== TIME-SERIES INTEGRITY CHECK AND SORTING ===\")\n",
    "\n",
    "# Check current sorting status\n",
    "print(\"=== CURRENT SORTING STATUS ===\")\n",
    "print(f\"First timestamp: {df['date'].iloc[0]}\")\n",
    "print(f\"Last timestamp: {df['date'].iloc[-1]}\")\n",
    "\n",
    "# Check if data is already sorted\n",
    "is_sorted = df['date'].is_monotonic_increasing\n",
    "print(f\"Data is already sorted chronologically: {is_sorted}\")\n",
    "\n",
    "# Check for any duplicate timestamps\n",
    "duplicate_timestamps = df['date'].duplicated().sum()\n",
    "print(f\"Duplicate timestamps: {duplicate_timestamps}\")\n",
    "\n",
    "if duplicate_timestamps > 0:\n",
    "    print(\"\\n=== DUPLICATE TIMESTAMP ANALYSIS ===\")\n",
    "    duplicate_samples = df[df['date'].duplicated(keep=False)].sort_values('date')\n",
    "    print(\"Sample duplicate timestamps:\")\n",
    "    print(duplicate_samples[['date', 'price', 'qty', 'trnvr']].head(10))\n",
    "\n",
    "# Sort the dataframe by datetime\n",
    "print(\"\\n=== SORTING DATA BY DATETIME ===\")\n",
    "df_sorted = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Verify sorting\n",
    "is_now_sorted = df_sorted['date'].is_monotonic_increasing\n",
    "print(f\"Data is now sorted chronologically: {is_now_sorted}\")\n",
    "\n",
    "# Display sorting verification\n",
    "print(f\"\\n=== SORTING VERIFICATION ===\")\n",
    "print(\"First 5 rows after sorting:\")\n",
    "print(df_sorted[['date', 'price', 'qty', 'trnvr']].head())\n",
    "print(f\"\\nLast 5 rows after sorting:\")\n",
    "print(df_sorted[['date', 'price', 'qty', 'trnvr']].tail())\n",
    "\n",
    "# Check for any time gaps or irregularities\n",
    "print(f\"\\n=== TIME SERIES CONTINUITY CHECK ===\")\n",
    "time_diffs = df_sorted['date'].diff().dropna()\n",
    "print(f\"Time differences between consecutive rows:\")\n",
    "print(f\"  Min: {time_diffs.min()}\")\n",
    "print(f\"  Max: {time_diffs.max()}\")\n",
    "print(f\"  Mean: {time_diffs.mean()}\")\n",
    "print(f\"  Most common: {time_diffs.mode().iloc[0] if len(time_diffs.mode()) > 0 else 'N/A'}\")\n",
    "\n",
    "# Check for any large time gaps\n",
    "large_gaps = time_diffs[time_diffs > pd.Timedelta(minutes=5)]\n",
    "if len(large_gaps) > 0:\n",
    "    print(f\"\\n⚠️  Found {len(large_gaps)} time gaps larger than 5 minutes:\")\n",
    "    gap_indices = time_diffs[time_diffs > pd.Timedelta(minutes=5)].index\n",
    "    for idx in gap_indices[:5]:  # Show first 5 gaps\n",
    "        gap_start = df_sorted.loc[idx-1, 'date']\n",
    "        gap_end = df_sorted.loc[idx, 'date']\n",
    "        gap_duration = gap_end - gap_start\n",
    "        print(f\"  Gap: {gap_start} to {gap_end} (Duration: {gap_duration})\")\n",
    "\n",
    "# Update the main dataframe with sorted version\n",
    "df = df_sorted\n",
    "print(f\"\\n✓ Main dataframe 'df' is now properly sorted chronologically\")\n",
    "print(f\"✓ Total rows: {len(df)}\")\n",
    "print(f\"✓ Time range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "# Final verification\n",
    "print(f\"\\n=== FINAL VERIFICATION ===\")\n",
    "print(\"✓ Data is sorted chronologically\")\n",
    "print(\"✓ Index is reset and sequential\")\n",
    "print(\"✓ Ready for time-series analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64545d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE DESCRIPTIVE STATISTICS ===\n",
      "=== BASIC DESCRIPTIVE STATISTICS ===\n",
      "                                date         price            qty  \\\n",
      "count                          10956  10956.000000   10956.000000   \n",
      "mean   2025-08-07 12:40:58.929810176    386.561094    1050.581508   \n",
      "min              2025-08-07 09:15:00    383.500000       1.000000   \n",
      "25%       2025-08-07 11:06:26.500000    385.150000      26.000000   \n",
      "50%              2025-08-07 12:45:14    386.450000     200.000000   \n",
      "75%    2025-08-07 14:26:31.249999872    387.950000     799.000000   \n",
      "max              2025-08-07 15:29:58    390.200000  153858.000000   \n",
      "std                              NaN      1.574324    3357.505716   \n",
      "\n",
      "              trnvr     cum_trnvr          hour        minute        second  \n",
      "count  1.095600e+04  1.095600e+04  10956.000000  10956.000000  10956.000000  \n",
      "mean   4.063499e+05  2.377823e+09     12.209383     27.926798     29.543173  \n",
      "min    3.836000e+02  2.543152e+07      9.000000      0.000000      0.000000  \n",
      "25%    1.003177e+04  1.490814e+09     11.000000     13.000000     15.000000  \n",
      "50%    7.732500e+04  2.355502e+09     12.000000     26.000000     30.000000  \n",
      "75%    3.085895e+05  3.321858e+09     14.000000     43.000000     45.000000  \n",
      "max    5.955074e+07  4.451969e+09     15.000000     59.000000     59.000000  \n",
      "std    1.299189e+06  1.165181e+09      1.916078     17.252424     17.315855  \n",
      "\n",
      "============================================================\n",
      "=== DETAILED STATISTICS BY COLUMN ===\n",
      "\n",
      "--- PRICE ---\n",
      "Count: 10,956\n",
      "Mean: 386.56\n",
      "Std: 1.57\n",
      "Min: 383.50\n",
      "25%: 385.15\n",
      "50% (Median): 386.45\n",
      "75%: 387.95\n",
      "Max: 390.20\n",
      "Range: 6.70\n",
      "IQR: 2.80\n",
      "Coefficient of Variation: 0.41%\n",
      "\n",
      "--- QTY ---\n",
      "Count: 10,956\n",
      "Mean: 1,050.58\n",
      "Std: 3,357.51\n",
      "Min: 1.00\n",
      "25%: 26.00\n",
      "50% (Median): 200.00\n",
      "75%: 799.00\n",
      "Max: 153,858.00\n",
      "Range: 153,857.00\n",
      "IQR: 773.00\n",
      "Coefficient of Variation: 319.59%\n",
      "\n",
      "--- TRNVR ---\n",
      "Count: 10,956\n",
      "Mean: 406,349.86\n",
      "Std: 1,299,188.95\n",
      "Min: 383.60\n",
      "25%: 10,031.77\n",
      "50% (Median): 77,325.00\n",
      "75%: 308,589.53\n",
      "Max: 59,550,738.90\n",
      "Range: 59,550,355.30\n",
      "IQR: 298,557.75\n",
      "Coefficient of Variation: 319.72%\n",
      "\n",
      "--- CUM_TRNVR ---\n",
      "Count: 10,956\n",
      "Mean: 2,377,822,586.83\n",
      "Std: 1,165,180,692.88\n",
      "Min: 25,431,519.00\n",
      "25%: 1,490,814,230.85\n",
      "50% (Median): 2,355,501,798.67\n",
      "75%: 3,321,857,538.50\n",
      "Max: 4,451,969,111.70\n",
      "Range: 4,426,537,592.70\n",
      "IQR: 1,831,043,307.65\n",
      "Coefficient of Variation: 49.00%\n",
      "\n",
      "============================================================\n",
      "=== DATETIME FEATURE STATISTICS ===\n",
      "\n",
      "--- HOUR DISTRIBUTION ---\n",
      "hour\n",
      "9     1047\n",
      "10    1476\n",
      "11    1653\n",
      "12    1807\n",
      "13    1679\n",
      "14    1521\n",
      "15    1773\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- MINUTE DISTRIBUTION (Sample) ---\n",
      "minute\n",
      "0     165\n",
      "1     239\n",
      "2     221\n",
      "3     264\n",
      "4     115\n",
      "5     108\n",
      "6     111\n",
      "7     219\n",
      "8     280\n",
      "9     258\n",
      "10    271\n",
      "11    260\n",
      "12    114\n",
      "13    118\n",
      "14    120\n",
      "15    305\n",
      "16    208\n",
      "17    209\n",
      "18    228\n",
      "19    249\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "=== TIME PERIOD ANALYSIS ===\n",
      "Trades during market hours (9 AM - 3 PM): 10,956\n",
      "Trades outside market hours: 0\n",
      "\n",
      "--- PRICE ANALYSIS ---\n",
      "Price range: ₹383.50 to ₹390.20\n",
      "Price spread: ₹6.70\n",
      "\n",
      "--- VOLUME ANALYSIS ---\n",
      "Total volume traded: 11,510,171\n",
      "Average trade size: 1051\n",
      "Largest single trade: 153,858\n",
      "\n",
      "--- TURNOVER ANALYSIS ---\n",
      "Total turnover: ₹4,451,969,111.70\n",
      "Average trade value: ₹406,349.86\n",
      "Largest single trade value: ₹59,550,738.90\n",
      "\n",
      "============================================================\n",
      "=== SUMMARY TABLE ===\n",
      "        Metric                Value\n",
      "    Total Rows               10,956\n",
      "   Price Range    ₹383.50 - ₹390.20\n",
      "  Total Volume           11,510,171\n",
      "Total Turnover    ₹4,451,969,111.70\n",
      "    Time Range 09:15:00 to 15:29:58\n"
     ]
    }
   ],
   "source": [
    "# Get comprehensive descriptive statistics for numeric fields\n",
    "print(\"=== COMPREHENSIVE DESCRIPTIVE STATISTICS ===\")\n",
    "\n",
    "# Get basic describe() for all numeric columns\n",
    "print(\"=== BASIC DESCRIPTIVE STATISTICS ===\")\n",
    "print(df.describe())\n",
    "\n",
    "# Get detailed statistics for each numeric column\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== DETAILED STATISTICS BY COLUMN ===\")\n",
    "\n",
    "numeric_cols = ['price', 'qty', 'trnvr', 'cum_trnvr']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    col_stats = df[col].describe()\n",
    "    \n",
    "    print(f\"Count: {col_stats['count']:,.0f}\")\n",
    "    print(f\"Mean: {col_stats['mean']:,.2f}\")\n",
    "    print(f\"Std: {col_stats['std']:,.2f}\")\n",
    "    print(f\"Min: {col_stats['min']:,.2f}\")\n",
    "    print(f\"25%: {col_stats['25%']:,.2f}\")\n",
    "    print(f\"50% (Median): {col_stats['50%']:,.2f}\")\n",
    "    print(f\"75%: {col_stats['75%']:,.2f}\")\n",
    "    print(f\"Max: {col_stats['max']:,.2f}\")\n",
    "    \n",
    "    # Additional useful statistics\n",
    "    print(f\"Range: {col_stats['max'] - col_stats['min']:,.2f}\")\n",
    "    print(f\"IQR: {col_stats['75%'] - col_stats['25%']:,.2f}\")\n",
    "    print(f\"Coefficient of Variation: {(col_stats['std']/col_stats['mean']*100):,.2f}%\")\n",
    "\n",
    "# Get statistics for datetime features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== DATETIME FEATURE STATISTICS ===\")\n",
    "\n",
    "print(\"\\n--- HOUR DISTRIBUTION ---\")\n",
    "hour_counts = df['hour'].value_counts().sort_index()\n",
    "print(hour_counts)\n",
    "\n",
    "print(\"\\n--- MINUTE DISTRIBUTION (Sample) ---\")\n",
    "minute_counts = df['minute'].value_counts().sort_index().head(20)\n",
    "print(minute_counts)\n",
    "\n",
    "# Get statistics for specific time periods\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== TIME PERIOD ANALYSIS ===\")\n",
    "\n",
    "# Market hours analysis (assuming 9:15 AM to 3:30 PM)\n",
    "market_hours = df[(df['hour'] >= 9) & (df['hour'] <= 15)]\n",
    "print(f\"Trades during market hours (9 AM - 3 PM): {len(market_hours):,}\")\n",
    "print(f\"Trades outside market hours: {len(df) - len(market_hours):,}\")\n",
    "\n",
    "# Price range analysis\n",
    "print(f\"\\n--- PRICE ANALYSIS ---\")\n",
    "print(f\"Price range: ₹{df['price'].min():.2f} to ₹{df['price'].max():.2f}\")\n",
    "print(f\"Price spread: ₹{df['price'].max() - df['price'].min():.2f}\")\n",
    "\n",
    "# Volume analysis\n",
    "print(f\"\\n--- VOLUME ANALYSIS ---\")\n",
    "print(f\"Total volume traded: {df['qty'].sum():,}\")\n",
    "print(f\"Average trade size: {df['qty'].mean():.0f}\")\n",
    "print(f\"Largest single trade: {df['qty'].max():,}\")\n",
    "\n",
    "# Turnover analysis\n",
    "print(f\"\\n--- TURNOVER ANALYSIS ---\")\n",
    "print(f\"Total turnover: ₹{df['trnvr'].sum():,.2f}\")\n",
    "print(f\"Average trade value: ₹{df['trnvr'].mean():,.2f}\")\n",
    "print(f\"Largest single trade value: ₹{df['trnvr'].max():,.2f}\")\n",
    "\n",
    "# Display summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== SUMMARY TABLE ===\")\n",
    "summary_data = {\n",
    "    'Metric': ['Total Rows', 'Price Range', 'Total Volume', 'Total Turnover', 'Time Range'],\n",
    "    'Value': [\n",
    "        f\"{len(df):,}\",\n",
    "        f\"₹{df['price'].min():.2f} - ₹{df['price'].max():.2f}\",\n",
    "        f\"{df['qty'].sum():,}\",\n",
    "        f\"₹{df['trnvr'].sum():,.2f}\",\n",
    "        f\"{df['date'].min().strftime('%H:%M:%S')} to {df['date'].max().strftime('%H:%M:%S')}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffcd6431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADING DAYS ANALYSIS ===\n",
      "Total unique trading days: 1\n",
      "\n",
      "=== ALL TRADING DATES ===\n",
      " 1. 2025-08-07\n",
      "\n",
      "Trading date range: 2025-08-07 to 2025-08-07\n",
      "\n",
      "=== DATE ANALYSIS ===\n",
      "Single trading day data\n",
      "Date: 2025-08-07\n",
      "\n",
      "=== DATA CONSISTENCY CHECK ===\n",
      "Total rows in dataset: 10,956\n",
      "Average rows per trading day: 10956.0\n",
      "\n",
      "=== SUMMARY ===\n",
      "✓ Total unique trading days: 1\n",
      "✓ Date range: 2025-08-07 to 2025-08-07\n",
      "✓ Ready for daily analysis and aggregation\n"
     ]
    }
   ],
   "source": [
    "# Count total unique trading days\n",
    "print(\"=== TRADING DAYS ANALYSIS ===\")\n",
    "\n",
    "# Extract unique dates from the datetime column\n",
    "unique_dates = df['date_only'].unique()\n",
    "total_trading_days = len(unique_dates)\n",
    "\n",
    "print(f\"Total unique trading days: {total_trading_days}\")\n",
    "\n",
    "# Display all unique trading dates\n",
    "print(f\"\\n=== ALL TRADING DATES ===\")\n",
    "for i, date in enumerate(sorted(unique_dates), 1):\n",
    "    print(f\"{i:2d}. {date}\")\n",
    "\n",
    "# Get date range\n",
    "date_range = f\"{min(unique_dates)} to {max(unique_dates)}\"\n",
    "print(f\"\\nTrading date range: {date_range}\")\n",
    "\n",
    "# Check if all dates are from the same month/year\n",
    "print(f\"\\n=== DATE ANALYSIS ===\")\n",
    "if total_trading_days == 1:\n",
    "    print(\"Single trading day data\")\n",
    "    print(f\"Date: {unique_dates[0]}\")\n",
    "    # Initialize these variables for single day to avoid errors\n",
    "    months = {unique_dates[0].month}\n",
    "    years = {unique_dates[0].year}\n",
    "elif total_trading_days > 1:\n",
    "    # Check month and year consistency\n",
    "    months = set(date.month for date in unique_dates)\n",
    "    years = set(date.year for date in unique_dates)\n",
    "    \n",
    "    print(f\"Multiple trading days: {total_trading_days}\")\n",
    "    print(f\"Months covered: {sorted(months)}\")\n",
    "    print(f\"Years covered: {sorted(years)}\")\n",
    "    \n",
    "    if len(months) == 1:\n",
    "        month_name = pd.Timestamp(unique_dates[0]).strftime('%B')\n",
    "        print(f\"All dates are from: {month_name} {list(years)[0]}\")\n",
    "    \n",
    "    if len(years) == 1:\n",
    "        print(f\"All dates are from year: {list(years)[0]}\")\n",
    "\n",
    "# Trading days by month (if multiple months)\n",
    "if len(months) > 1:\n",
    "    print(f\"\\n=== TRADING DAYS BY MONTH ===\")\n",
    "    monthly_counts = {}\n",
    "    for date in unique_dates:\n",
    "        month_key = f\"{date.year}-{date.month:02d}\"\n",
    "        monthly_counts[month_key] = monthly_counts.get(month_key, 0) + 1\n",
    "    \n",
    "    for month_key in sorted(monthly_counts.keys()):\n",
    "        year, month = month_key.split('-')\n",
    "        month_name = pd.Timestamp(f\"{year}-{month}-01\").strftime('%B %Y')\n",
    "        print(f\"{month_name}: {monthly_counts[month_key]} trading days\")\n",
    "\n",
    "# Verify data consistency\n",
    "print(f\"\\n=== DATA CONSISTENCY CHECK ===\")\n",
    "print(f\"Total rows in dataset: {len(df):,}\")\n",
    "print(f\"Average rows per trading day: {len(df)/total_trading_days:.1f}\")\n",
    "\n",
    "# Check for any missing dates in sequence (if multiple days)\n",
    "if total_trading_days > 1:\n",
    "    sorted_dates = sorted(unique_dates)\n",
    "    date_diffs = []\n",
    "    for i in range(1, len(sorted_dates)):\n",
    "        diff = (sorted_dates[i] - sorted_dates[i-1]).days\n",
    "        date_diffs.append(diff)\n",
    "    \n",
    "    if any(diff > 1 for diff in date_diffs):\n",
    "        print(f\"\\n⚠️  Gaps detected in trading days:\")\n",
    "        for i, diff in enumerate(date_diffs):\n",
    "            if diff > 1:\n",
    "                gap_start = sorted_dates[i-1]\n",
    "                gap_end = sorted_dates[i]\n",
    "                print(f\"  Gap: {gap_start} to {gap_end} ({diff-1} missing days)\")\n",
    "    else:\n",
    "        print(f\"\\n✓ No gaps in trading days - consecutive trading days\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"✓ Total unique trading days: {total_trading_days}\")\n",
    "print(f\"✓ Date range: {date_range}\")\n",
    "print(f\"✓ Ready for daily analysis and aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6881a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TIMESTAMP RANGE ANALYSIS ===\n",
      "Earliest timestamp: 2025-08-07 09:15:00\n",
      "Latest timestamp: 2025-08-07 15:29:58\n",
      "Total time duration: 0 days 06:14:58\n",
      "Duration in hours: 6.25 hours\n",
      "Duration in minutes: 375 minutes\n",
      "\n",
      "=== EARLIEST TIMESTAMP ROW ===\n",
      "               date  price   qty      trnvr  cum_trnvr\n",
      "2025-08-07 09:15:00 386.85 65740 25431519.0 25431519.0\n",
      "\n",
      "=== LATEST TIMESTAMP ROW ===\n",
      "               date  price  qty    trnvr    cum_trnvr\n",
      "2025-08-07 15:29:58 388.25 1740 675555.0 4.451969e+09\n",
      "\n",
      "=== TIME PERIOD ANALYSIS ===\n",
      "Earliest: 09:15\n",
      "Latest: 15:29\n",
      "\n",
      "Market hours: 09:15:00 to 15:30:00\n",
      "Data coverage:\n",
      "\n",
      "=== TIME SERIES CONTINUITY ===\n",
      "Minimum time difference between consecutive rows: 0 days 00:00:00\n",
      "Maximum time difference between consecutive rows: 0 days 00:00:12\n",
      "\n",
      "=== SUMMARY ===\n",
      "✓ Data spans: 2025-08-07 09:15:00 to 2025-08-07 15:29:58\n",
      "✓ Total duration: 6.25 hours (375 minutes)\n",
      "✓ Total rows: 10,956\n",
      "✓ Average frequency: 1753.1 ticks per hour\n"
     ]
    }
   ],
   "source": [
    "# Identify earliest and latest timestamps\n",
    "print(\"=== TIMESTAMP RANGE ANALYSIS ===\")\n",
    "\n",
    "# Get earliest and latest timestamps\n",
    "earliest_timestamp = df['date'].min()\n",
    "latest_timestamp = df['date'].max()\n",
    "\n",
    "print(f\"Earliest timestamp: {earliest_timestamp}\")\n",
    "print(f\"Latest timestamp: {latest_timestamp}\")\n",
    "\n",
    "# Calculate total time duration\n",
    "total_duration = latest_timestamp - earliest_timestamp\n",
    "print(f\"Total time duration: {total_duration}\")\n",
    "\n",
    "# Convert duration to more readable format\n",
    "duration_hours = total_duration.total_seconds() / 3600\n",
    "duration_minutes = total_duration.total_seconds() / 60\n",
    "\n",
    "print(f\"Duration in hours: {duration_hours:.2f} hours\")\n",
    "print(f\"Duration in minutes: {duration_minutes:.0f} minutes\")\n",
    "\n",
    "# Display the actual rows with earliest and latest timestamps\n",
    "print(f\"\\n=== EARLIEST TIMESTAMP ROW ===\")\n",
    "earliest_row = df[df['date'] == earliest_timestamp]\n",
    "print(earliest_row[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== LATEST TIMESTAMP ROW ===\")\n",
    "latest_row = df[df['date'] == latest_timestamp]\n",
    "print(latest_row[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].to_string(index=False))\n",
    "\n",
    "# Check if timestamps span across different time periods\n",
    "print(f\"\\n=== TIME PERIOD ANALYSIS ===\")\n",
    "earliest_hour = earliest_timestamp.hour\n",
    "earliest_minute = earliest_timestamp.minute\n",
    "latest_hour = latest_timestamp.hour\n",
    "latest_minute = latest_timestamp.minute\n",
    "\n",
    "print(f\"Earliest: {earliest_hour:02d}:{earliest_minute:02d}\")\n",
    "print(f\"Latest: {latest_hour:02d}:{latest_minute:02d}\")\n",
    "\n",
    "# Market hours analysis (assuming 9:15 AM to 3:30 PM)\n",
    "market_start = pd.Timestamp('2025-08-07 09:15:00')\n",
    "market_end = pd.Timestamp('2025-08-07 15:30:00')\n",
    "\n",
    "print(f\"\\nMarket hours: 09:15:00 to 15:30:00\")\n",
    "print(f\"Data coverage:\")\n",
    "\n",
    "if earliest_timestamp < market_start:\n",
    "    pre_market_duration = market_start - earliest_timestamp\n",
    "    print(f\"  Pre-market: {earliest_timestamp.strftime('%H:%M:%S')} to {market_start.strftime('%H:%M:%S')} ({pre_market_duration})\")\n",
    "\n",
    "if earliest_timestamp <= market_start and latest_timestamp >= market_end:\n",
    "    market_duration = market_end - market_start\n",
    "    print(f\"  Market hours: {market_start.strftime('%H:%M:%S')} to {market_end.strftime('%H:%M:%S')} ({market_duration})\")\n",
    "\n",
    "if latest_timestamp > market_end:\n",
    "    post_market_duration = latest_timestamp - market_end\n",
    "    print(f\"  Post-market: {market_end.strftime('%H:%M:%S')} to {latest_timestamp.strftime('%H:%M:%S')} ({post_market_duration})\")\n",
    "\n",
    "# Check for any gaps in the time series\n",
    "print(f\"\\n=== TIME SERIES CONTINUITY ===\")\n",
    "time_diffs = df['date'].diff().dropna()\n",
    "min_time_diff = time_diffs.min()\n",
    "max_time_diff = time_diffs.max()\n",
    "\n",
    "print(f\"Minimum time difference between consecutive rows: {min_time_diff}\")\n",
    "print(f\"Maximum time difference between consecutive rows: {max_time_diff}\")\n",
    "\n",
    "# Identify any unusually large time gaps\n",
    "large_gaps = time_diffs[time_diffs > pd.Timedelta(minutes=1)]\n",
    "if len(large_gaps) > 0:\n",
    "    print(f\"\\n⚠️  Found {len(large_gaps)} time gaps larger than 1 minute:\")\n",
    "    gap_indices = large_gaps.index[:5]  # Show first 5 gaps\n",
    "    for idx in gap_indices:\n",
    "        gap_start = df.loc[idx-1, 'date']\n",
    "        gap_end = df.loc[idx, 'date']\n",
    "        gap_duration = gap_end - gap_start\n",
    "        print(f\"  Gap: {gap_start.strftime('%H:%M:%S')} to {gap_end.strftime('%H:%M:%S')} (Duration: {gap_duration})\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"✓ Data spans: {earliest_timestamp.strftime('%Y-%m-%d %H:%M:%S')} to {latest_timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"✓ Total duration: {duration_hours:.2f} hours ({duration_minutes:.0f} minutes)\")\n",
    "print(f\"✓ Total rows: {len(df):,}\")\n",
    "print(f\"✓ Average frequency: {len(df)/duration_hours:.1f} ticks per hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a43503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VOLUME AND TURNOVER ANALYSIS ===\n",
      "Total traded volume: 11,510,171\n",
      "Total turnover: ₹4,451,969,111.70\n",
      "\n",
      "=== DETAILED METRICS ===\n",
      "--- VOLUME ANALYSIS ---\n",
      "Average trade size: 1,051\n",
      "Median trade size: 200\n",
      "Largest single trade: 153,858\n",
      "Smallest single trade: 1\n",
      "\n",
      "--- TURNOVER ANALYSIS ---\n",
      "Average trade value: ₹406,349.86\n",
      "Median trade value: ₹77,325.00\n",
      "Largest single trade value: ₹59,550,738.90\n",
      "Smallest single trade value: ₹383.60\n",
      "\n",
      "--- PRICE ANALYSIS ---\n",
      "Simple average price: ₹386.56\n",
      "Weighted average price (by volume): ₹386.79\n",
      "Price range: ₹6.70\n",
      "\n",
      "--- VOLUME-WEIGHTED METRICS ---\n",
      "Volume Weighted Average Price (VWAP): ₹386.79\n",
      "\n",
      "--- EFFICIENCY METRICS ---\n",
      "Total number of trades: 10,956\n",
      "Average volume per trade: 1,051\n",
      "Average turnover per trade: ₹406,349.86\n",
      "\n",
      "=== TIME-BASED ANALYSIS ===\n",
      "Trading duration: 6.25 hours\n",
      "Volume per hour: 1,841,791\n",
      "Turnover per hour: ₹712,378,380.39\n",
      "\n",
      "--- MARKET ACTIVITY INTENSITY ---\n",
      "Trades per hour: 1753.1\n",
      "Volume per trade: 1,051\n",
      "Turnover per trade: ₹406,349.86\n",
      "\n",
      "============================================================\n",
      "=== SUMMARY TABLE ===\n",
      "         Metric             Value\n",
      "   Total Volume        11,510,171\n",
      " Total Turnover ₹4,451,969,111.70\n",
      "   Total Trades            10,956\n",
      " Avg Trade Size             1,051\n",
      "Avg Trade Value       ₹406,349.86\n",
      "           VWAP           ₹386.79\n",
      "\n",
      "=== KEY INSIGHTS ===\n",
      "✓ Total volume traded: 11,510,171 shares\n",
      "✓ Total market value: ₹4,451,969,111.70\n",
      "✓ Market activity: 10,956 individual trades\n",
      "✓ Trading efficiency: ₹386.79 per share\n"
     ]
    }
   ],
   "source": [
    "# Calculate total traded volume and total turnover\n",
    "print(\"=== VOLUME AND TURNOVER ANALYSIS ===\")\n",
    "\n",
    "# Calculate totals\n",
    "total_volume = df['qty'].sum()\n",
    "total_turnover = df['trnvr'].sum()\n",
    "\n",
    "print(f\"Total traded volume: {total_volume:,}\")\n",
    "print(f\"Total turnover: ₹{total_turnover:,.2f}\")\n",
    "\n",
    "# Additional volume and turnover metrics\n",
    "print(f\"\\n=== DETAILED METRICS ===\")\n",
    "\n",
    "# Volume analysis\n",
    "print(\"--- VOLUME ANALYSIS ---\")\n",
    "avg_trade_size = df['qty'].mean()\n",
    "median_trade_size = df['qty'].median()\n",
    "max_trade_size = df['qty'].max()\n",
    "min_trade_size = df['qty'].min()\n",
    "\n",
    "print(f\"Average trade size: {avg_trade_size:,.0f}\")\n",
    "print(f\"Median trade size: {median_trade_size:,.0f}\")\n",
    "print(f\"Largest single trade: {max_trade_size:,}\")\n",
    "print(f\"Smallest single trade: {min_trade_size:,}\")\n",
    "\n",
    "# Turnover analysis\n",
    "print(f\"\\n--- TURNOVER ANALYSIS ---\")\n",
    "avg_trade_value = df['trnvr'].mean()\n",
    "median_trade_value = df['trnvr'].median()\n",
    "max_trade_value = df['trnvr'].max()\n",
    "min_trade_value = df['trnvr'].min()\n",
    "\n",
    "print(f\"Average trade value: ₹{avg_trade_value:,.2f}\")\n",
    "print(f\"Median trade value: ₹{median_trade_value:,.2f}\")\n",
    "print(f\"Largest single trade value: ₹{max_trade_value:,.2f}\")\n",
    "print(f\"Smallest single trade value: ₹{min_trade_value:,.2f}\")\n",
    "\n",
    "# Price analysis\n",
    "print(f\"\\n--- PRICE ANALYSIS ---\")\n",
    "avg_price = df['price'].mean()\n",
    "weighted_avg_price = (df['price'] * df['qty']).sum() / df['qty'].sum()\n",
    "price_range = df['price'].max() - df['price'].min()\n",
    "\n",
    "print(f\"Simple average price: ₹{avg_price:.2f}\")\n",
    "print(f\"Weighted average price (by volume): ₹{weighted_avg_price:.2f}\")\n",
    "print(f\"Price range: ₹{price_range:.2f}\")\n",
    "\n",
    "# Volume-weighted metrics\n",
    "print(f\"\\n--- VOLUME-WEIGHTED METRICS ---\")\n",
    "vwap = (df['price'] * df['qty']).sum() / df['qty'].sum()\n",
    "print(f\"Volume Weighted Average Price (VWAP): ₹{vwap:.2f}\")\n",
    "\n",
    "# Efficiency metrics\n",
    "print(f\"\\n--- EFFICIENCY METRICS ---\")\n",
    "trades_count = len(df)\n",
    "print(f\"Total number of trades: {trades_count:,}\")\n",
    "print(f\"Average volume per trade: {total_volume/trades_count:,.0f}\")\n",
    "print(f\"Average turnover per trade: ₹{total_turnover/trades_count:,.2f}\")\n",
    "\n",
    "# Time-based analysis\n",
    "print(f\"\\n=== TIME-BASED ANALYSIS ===\")\n",
    "earliest_time = df['date'].min()\n",
    "latest_time = df['date'].max()\n",
    "duration_hours = (latest_time - earliest_time).total_seconds() / 3600\n",
    "\n",
    "print(f\"Trading duration: {duration_hours:.2f} hours\")\n",
    "print(f\"Volume per hour: {total_volume/duration_hours:,.0f}\")\n",
    "print(f\"Turnover per hour: ₹{total_turnover/duration_hours:,.2f}\")\n",
    "\n",
    "# Market activity intensity\n",
    "print(f\"\\n--- MARKET ACTIVITY INTENSITY ---\")\n",
    "print(f\"Trades per hour: {trades_count/duration_hours:.1f}\")\n",
    "print(f\"Volume per trade: {total_volume/trades_count:,.0f}\")\n",
    "print(f\"Turnover per trade: ₹{total_turnover/trades_count:,.2f}\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"=== SUMMARY TABLE ===\")\n",
    "summary_data = {\n",
    "    'Metric': ['Total Volume', 'Total Turnover', 'Total Trades', 'Avg Trade Size', 'Avg Trade Value', 'VWAP'],\n",
    "    'Value': [\n",
    "        f\"{total_volume:,}\",\n",
    "        f\"₹{total_turnover:,.2f}\",\n",
    "        f\"{trades_count:,}\",\n",
    "        f\"{avg_trade_size:,.0f}\",\n",
    "        f\"₹{avg_trade_value:,.2f}\",\n",
    "        f\"₹{vwap:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== KEY INSIGHTS ===\")\n",
    "print(f\"✓ Total volume traded: {total_volume:,} shares\")\n",
    "print(f\"✓ Total market value: ₹{total_turnover:,.2f}\")\n",
    "print(f\"✓ Market activity: {trades_count:,} individual trades\")\n",
    "print(f\"✓ Trading efficiency: ₹{total_turnover/total_volume:.2f} per share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e17d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADE TYPE ANALYSIS ===\n",
      "Total records in dataset: 10,956\n",
      "Actual trades (qty > 0): 10,956\n",
      "Zero-quantity updates (qty = 0): 0\n",
      "\n",
      "=== PERCENTAGE BREAKDOWN ===\n",
      "Actual trades: 100.00%\n",
      "Zero-quantity updates: 0.00%\n",
      "\n",
      "=== DATA COMPOSITION ANALYSIS ===\n",
      "✓ Dataset contains only actual trades (all qty > 0)\n",
      "\n",
      "=== SAMPLE OF ACTUAL TRADES (qty > 0) ===\n",
      "                 date   price    qty        trnvr    cum_trnvr\n",
      "0 2025-08-07 09:15:00  386.85  65740  25431519.00  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30    895    345738.50  25777257.50\n",
      "2 2025-08-07 09:15:01  386.75   1401    541836.75  26319094.25\n",
      "3 2025-08-07 09:15:02  386.80   1795    694306.00  27013400.25\n",
      "4 2025-08-07 09:15:02  386.95    741    286729.95  27300130.20\n",
      "5 2025-08-07 09:15:03  386.90   2717   1051207.30  28351337.50\n",
      "6 2025-08-07 09:15:03  386.80   9068   3507502.40  31858839.90\n",
      "7 2025-08-07 09:15:04  386.75   1141    441281.75  32300121.65\n",
      "8 2025-08-07 09:15:04  386.90   1798    695646.20  32995767.85\n",
      "9 2025-08-07 09:15:05  386.75   1679    649353.25  34453992.90\n",
      "\n",
      "=== CHARACTERISTICS ANALYSIS ===\n",
      "--- ACTUAL TRADES (qty > 0) ---\n",
      "  Total volume: 11,510,171\n",
      "  Total turnover: ₹4,451,969,111.70\n",
      "  Average trade size: 1,051\n",
      "  Average trade value: ₹406,349.86\n",
      "  Price range: ₹383.50 - ₹390.20\n",
      "\n",
      "=== DATA QUALITY IMPLICATIONS ===\n",
      "✓ Clean dataset with only actual trades\n",
      "\n",
      "=== RECOMMENDATIONS ===\n",
      "  ✓ Dataset is ready for all types of analysis\n",
      "\n",
      "=== SUMMARY ===\n",
      "✓ Total records: 10,956\n",
      "✓ Actual trades: 10,956 (100.0%)\n",
      "✓ Zero-qty updates: 0 (0.0%)\n",
      "✓ Data type: Pure trades only\n"
     ]
    }
   ],
   "source": [
    "# Check number of trades with qty > 0 (actual trades vs. zero-qty updates)\n",
    "print(\"=== TRADE TYPE ANALYSIS ===\")\n",
    "\n",
    "# Count different types of records\n",
    "total_records = len(df)\n",
    "actual_trades = (df['qty'] > 0).sum()\n",
    "zero_qty_updates = (df['qty'] == 0).sum()\n",
    "\n",
    "print(f\"Total records in dataset: {total_records:,}\")\n",
    "print(f\"Actual trades (qty > 0): {actual_trades:,}\")\n",
    "print(f\"Zero-quantity updates (qty = 0): {zero_qty_updates:,}\")\n",
    "\n",
    "# Calculate percentages\n",
    "actual_trades_pct = (actual_trades / total_records) * 100\n",
    "zero_qty_pct = (zero_qty_updates / total_records) * 100\n",
    "\n",
    "print(f\"\\n=== PERCENTAGE BREAKDOWN ===\")\n",
    "print(f\"Actual trades: {actual_trades_pct:.2f}%\")\n",
    "print(f\"Zero-quantity updates: {zero_qty_pct:.2f}%\")\n",
    "\n",
    "# Analyze the data composition\n",
    "print(f\"\\n=== DATA COMPOSITION ANALYSIS ===\")\n",
    "if zero_qty_updates > 0:\n",
    "    print(\"⚠️  Dataset contains both actual trades and zero-quantity updates\")\n",
    "    print(\"   This suggests the data includes bid-ask spread updates\")\n",
    "else:\n",
    "    print(\"✓ Dataset contains only actual trades (all qty > 0)\")\n",
    "\n",
    "# Show sample of actual trades\n",
    "print(f\"\\n=== SAMPLE OF ACTUAL TRADES (qty > 0) ===\")\n",
    "actual_trades_df = df[df['qty'] > 0]\n",
    "print(actual_trades_df[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(10))\n",
    "\n",
    "# Show sample of zero-quantity updates (if any exist)\n",
    "if zero_qty_updates > 0:\n",
    "    print(f\"\\n=== SAMPLE OF ZERO-QUANTITY UPDATES (qty = 0) ===\")\n",
    "    zero_qty_df = df[df['qty'] == 0]\n",
    "    print(zero_qty_df[['date', 'price', 'qty', 'trnvr', 'cum_trnvr']].head(10))\n",
    "\n",
    "# Analyze characteristics of each type\n",
    "print(f\"\\n=== CHARACTERISTICS ANALYSIS ===\")\n",
    "\n",
    "# Actual trades characteristics\n",
    "if actual_trades > 0:\n",
    "    print(\"--- ACTUAL TRADES (qty > 0) ---\")\n",
    "    actual_trades_data = df[df['qty'] > 0]\n",
    "    print(f\"  Total volume: {actual_trades_data['qty'].sum():,}\")\n",
    "    print(f\"  Total turnover: ₹{actual_trades_data['trnvr'].sum():,.2f}\")\n",
    "    print(f\"  Average trade size: {actual_trades_data['qty'].mean():,.0f}\")\n",
    "    print(f\"  Average trade value: ₹{actual_trades_data['trnvr'].mean():,.2f}\")\n",
    "    print(f\"  Price range: ₹{actual_trades_data['price'].min():.2f} - ₹{actual_trades_data['price'].max():.2f}\")\n",
    "\n",
    "# Zero-quantity updates characteristics (if any exist)\n",
    "if zero_qty_updates > 0:\n",
    "    print(f\"\\n--- ZERO-QUANTITY UPDATES (qty = 0) ---\")\n",
    "    zero_qty_data = df[df['qty'] == 0]\n",
    "    print(f\"  Total records: {len(zero_qty_data):,}\")\n",
    "    print(f\"  Price range: ₹{zero_qty_data['price'].min():.2f} - ₹{zero_qty_data['price'].max():.2f}\")\n",
    "    print(f\"  Average price: ₹{zero_qty_data['price'].mean():.2f}\")\n",
    "    \n",
    "    # Check if these are bid-ask spread updates\n",
    "    if zero_qty_data['trnvr'].sum() == 0:\n",
    "        print(f\"  All have zero turnover (typical bid-ask updates)\")\n",
    "    else:\n",
    "        print(f\"  Some have non-zero turnover (data quality issue)\")\n",
    "\n",
    "# Data quality implications\n",
    "print(f\"\\n=== DATA QUALITY IMPLICATIONS ===\")\n",
    "if zero_qty_updates > 0:\n",
    "    print(\"⚠️  Mixed data types detected:\")\n",
    "    print(\"   - Actual trades: Use for volume, turnover, and price analysis\")\n",
    "    print(\"   - Zero-qty updates: Use for bid-ask spread analysis only\")\n",
    "    print(\"   - Consider filtering by qty > 0 for trade-based analysis\")\n",
    "else:\n",
    "    print(\"✓ Clean dataset with only actual trades\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\n=== RECOMMENDATIONS ===\")\n",
    "if zero_qty_updates > 0:\n",
    "    print(\"For different types of analysis:\")\n",
    "    print(\"  📊 Volume/Turnover analysis: Use df[df['qty'] > 0]\")\n",
    "    print(\"  📈 Price movement analysis: Use df[df['qty'] > 0]\")\n",
    "    print(\"  🔍 Bid-ask spread analysis: Use df[df['qty'] == 0]\")\n",
    "    print(\"  📋 Complete market picture: Use full dataset\")\n",
    "else:\n",
    "    print(\"  ✓ Dataset is ready for all types of analysis\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"✓ Total records: {total_records:,}\")\n",
    "print(f\"✓ Actual trades: {actual_trades:,} ({actual_trades_pct:.1f}%)\")\n",
    "print(f\"✓ Zero-qty updates: {zero_qty_updates:,} ({zero_qty_pct:.1f}%)\")\n",
    "print(f\"✓ Data type: {'Mixed (trades + updates)' if zero_qty_updates > 0 else 'Pure trades only'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01afc28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRICE CHANGE CALCULATION ===\n",
      "=== SAMPLE DATA WITH PRICE CHANGE ===\n",
      "                 date   price  price_change    qty        trnvr\n",
      "0 2025-08-07 09:15:00  386.85           NaN  65740  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30         -0.55    895    345738.50\n",
      "2 2025-08-07 09:15:01  386.75          0.45   1401    541836.75\n",
      "3 2025-08-07 09:15:02  386.80          0.05   1795    694306.00\n",
      "4 2025-08-07 09:15:02  386.95          0.15    741    286729.95\n",
      "5 2025-08-07 09:15:03  386.90         -0.05   2717   1051207.30\n",
      "6 2025-08-07 09:15:03  386.80         -0.10   9068   3507502.40\n",
      "7 2025-08-07 09:15:04  386.75         -0.05   1141    441281.75\n",
      "8 2025-08-07 09:15:04  386.90          0.15   1798    695646.20\n",
      "9 2025-08-07 09:15:05  386.75         -0.15   1679    649353.25\n",
      "\n",
      "=== PRICE CHANGE STATISTICS ===\n",
      "Total price changes calculated: 10955\n",
      "First price change: -0.55\n",
      "Last price change: 0.00\n",
      "\n",
      "=== PRICE CHANGE DESCRIPTIVE STATISTICS ===\n",
      "count    10955.000000\n",
      "mean         0.000128\n",
      "std          0.083893\n",
      "min         -0.650000\n",
      "25%         -0.050000\n",
      "50%          0.000000\n",
      "75%          0.050000\n",
      "max          0.750000\n",
      "Name: price_change, dtype: float64\n",
      "\n",
      "=== PRICE CHANGE DISTRIBUTION ANALYSIS ===\n",
      "Positive price changes: 3,216 (29.36%)\n",
      "Negative price changes: 3,299 (30.11%)\n",
      "No price changes: 4,440 (40.53%)\n",
      "\n",
      "=== PRICE CHANGE MAGNITUDE ANALYSIS ===\n",
      "Average absolute price change: ₹0.05\n",
      "Median absolute price change: ₹0.05\n",
      "Largest price increase: ₹0.75\n",
      "Largest price decrease: ₹-0.65\n",
      "\n",
      "=== EXAMPLES OF PRICE CHANGES ===\n",
      "Top 5 largest price increases:\n",
      "               date  price  price_change   qty\n",
      "2025-08-07 09:15:16 386.55          0.75  5645\n",
      "2025-08-07 09:18:55 389.05          0.60 17196\n",
      "2025-08-07 09:20:49 389.85          0.55 43873\n",
      "2025-08-07 09:15:11 386.20          0.50  1962\n",
      "2025-08-07 14:45:13 386.55          0.50   579\n",
      "\n",
      "Top 5 largest price decreases:\n",
      "               date  price  price_change   qty\n",
      "2025-08-07 09:18:47 388.45         -0.65 17426\n",
      "2025-08-07 09:15:01 386.30         -0.55   895\n",
      "2025-08-07 09:15:26 385.90         -0.45  2839\n",
      "2025-08-07 09:16:20 387.15         -0.45 11997\n",
      "2025-08-07 09:15:15 385.80         -0.45  3449\n",
      "\n",
      "Sample of rows with no price change:\n",
      "               date  price  price_change  qty\n",
      "2025-08-07 09:15:06 386.65           0.0 4519\n",
      "2025-08-07 09:15:09 386.00           0.0 1904\n",
      "2025-08-07 09:15:10 386.00           0.0 6328\n",
      "2025-08-07 09:15:12 386.00           0.0 1803\n",
      "2025-08-07 09:15:13 385.75           0.0 8471\n",
      "\n",
      "=== PRICE CHANGE PATTERNS ===\n",
      "Price changes per hour: 1753.0\n",
      "Average price change frequency: 1.00 changes per tick\n",
      "\n",
      "=== CALCULATION VERIFICATION ===\n",
      "✓ Price change column created successfully\n",
      "✓ First row price_change is NaN (no previous price to compare)\n",
      "✓ Total rows: 10,956\n",
      "✓ Price changes calculated: 10,955\n",
      "✓ Ready for price movement analysis\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change']\n",
      "Shape: (10956, 11)\n",
      "Data types:\n",
      "date            datetime64[ns]\n",
      "price                  float64\n",
      "qty                      int64\n",
      "trnvr                  float64\n",
      "cum_trnvr              float64\n",
      "date_only               object\n",
      "time                    object\n",
      "hour                     int32\n",
      "minute                   int32\n",
      "second                   int32\n",
      "price_change           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create price_change = current price - previous price\n",
    "print(\"=== PRICE CHANGE CALCULATION ===\")\n",
    "\n",
    "# Calculate price change (current price - previous price)\n",
    "df['price_change'] = df['price'].diff()\n",
    "\n",
    "# Display the first few rows to verify the calculation\n",
    "print(\"=== SAMPLE DATA WITH PRICE CHANGE ===\")\n",
    "print(df[['date', 'price', 'price_change', 'qty', 'trnvr']].head(10))\n",
    "\n",
    "# Basic statistics of price changes\n",
    "print(f\"\\n=== PRICE CHANGE STATISTICS ===\")\n",
    "print(f\"Total price changes calculated: {len(df['price_change'].dropna())}\")\n",
    "print(f\"First price change: {df['price_change'].iloc[1]:.2f}\")  # First change is at index 1\n",
    "print(f\"Last price change: {df['price_change'].iloc[-1]:.2f}\")\n",
    "\n",
    "# Statistical summary of price changes\n",
    "print(f\"\\n=== PRICE CHANGE DESCRIPTIVE STATISTICS ===\")\n",
    "price_change_stats = df['price_change'].describe()\n",
    "print(price_change_stats)\n",
    "\n",
    "# Analyze price change distribution\n",
    "print(f\"\\n=== PRICE CHANGE DISTRIBUTION ANALYSIS ===\")\n",
    "positive_changes = (df['price_change'] > 0).sum()\n",
    "negative_changes = (df['price_change'] < 0).sum()\n",
    "zero_changes = (df['price_change'] == 0).sum()\n",
    "total_changes = len(df['price_change'].dropna())\n",
    "\n",
    "print(f\"Positive price changes: {positive_changes:,} ({(positive_changes/total_changes*100):.2f}%)\")\n",
    "print(f\"Negative price changes: {negative_changes:,} ({(negative_changes/total_changes*100):.2f}%)\")\n",
    "print(f\"No price changes: {zero_changes:,} ({(zero_changes/total_changes*100):.2f}%)\")\n",
    "\n",
    "# Price change magnitude analysis\n",
    "print(f\"\\n=== PRICE CHANGE MAGNITUDE ANALYSIS ===\")\n",
    "abs_price_changes = df['price_change'].abs()\n",
    "print(f\"Average absolute price change: ₹{abs_price_changes.mean():.2f}\")\n",
    "print(f\"Median absolute price change: ₹{abs_price_changes.median():.2f}\")\n",
    "print(f\"Largest price increase: ₹{df['price_change'].max():.2f}\")\n",
    "print(f\"Largest price decrease: ₹{df['price_change'].min():.2f}\")\n",
    "\n",
    "# Show examples of different types of price changes\n",
    "print(f\"\\n=== EXAMPLES OF PRICE CHANGES ===\")\n",
    "\n",
    "# Largest price increases\n",
    "print(\"Top 5 largest price increases:\")\n",
    "largest_increases = df.nlargest(5, 'price_change')[['date', 'price', 'price_change', 'qty']]\n",
    "print(largest_increases.to_string(index=False))\n",
    "\n",
    "# Largest price decreases\n",
    "print(f\"\\nTop 5 largest price decreases:\")\n",
    "largest_decreases = df.nsmallest(5, 'price_change')[['date', 'price', 'price_change', 'qty']]\n",
    "print(largest_decreases.to_string(index=False))\n",
    "\n",
    "# No change examples\n",
    "if zero_changes > 0:\n",
    "    print(f\"\\nSample of rows with no price change:\")\n",
    "    no_change_sample = df[df['price_change'] == 0][['date', 'price', 'price_change', 'qty']].head(5)\n",
    "    print(no_change_sample.to_string(index=False))\n",
    "\n",
    "# Price change patterns\n",
    "print(f\"\\n=== PRICE CHANGE PATTERNS ===\")\n",
    "print(f\"Price changes per hour: {total_changes / ((df['date'].max() - df['date'].min()).total_seconds() / 3600):.1f}\")\n",
    "print(f\"Average price change frequency: {total_changes / len(df):.2f} changes per tick\")\n",
    "\n",
    "# Verify calculation integrity\n",
    "print(f\"\\n=== CALCULATION VERIFICATION ===\")\n",
    "print(f\"✓ Price change column created successfully\")\n",
    "print(f\"✓ First row price_change is NaN (no previous price to compare)\")\n",
    "print(f\"✓ Total rows: {len(df):,}\")\n",
    "print(f\"✓ Price changes calculated: {total_changes:,}\")\n",
    "print(f\"✓ Ready for price movement analysis\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ee472b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIRECTION COLUMN CREATION ===\n",
      "=== SAMPLE DATA WITH DIRECTION ===\n",
      "                 date   price  price_change  direction    qty        trnvr\n",
      "0 2025-08-07 09:15:00  386.85           NaN  No change  65740  25431519.00\n",
      "1 2025-08-07 09:15:01  386.30         -0.55       Down    895    345738.50\n",
      "2 2025-08-07 09:15:01  386.75          0.45         Up   1401    541836.75\n",
      "3 2025-08-07 09:15:02  386.80          0.05         Up   1795    694306.00\n",
      "4 2025-08-07 09:15:02  386.95          0.15         Up    741    286729.95\n",
      "5 2025-08-07 09:15:03  386.90         -0.05       Down   2717   1051207.30\n",
      "6 2025-08-07 09:15:03  386.80         -0.10       Down   9068   3507502.40\n",
      "7 2025-08-07 09:15:04  386.75         -0.05       Down   1141    441281.75\n",
      "8 2025-08-07 09:15:04  386.90          0.15         Up   1798    695646.20\n",
      "9 2025-08-07 09:15:05  386.75         -0.15       Down   1679    649353.25\n",
      "\n",
      "=== DIRECTION DISTRIBUTION ===\n",
      "direction\n",
      "No change    4441\n",
      "Down         3299\n",
      "Up           3216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== DIRECTION PERCENTAGES ===\n",
      "No change: 4,441 (40.53%)\n",
      "Down: 3,299 (30.11%)\n",
      "Up: 3,216 (29.35%)\n",
      "\n",
      "=== DIRECTION PATTERN ANALYSIS ===\n",
      "Direction sequence analysis:\n",
      "Maximum consecutive 'Up' movements: 7\n",
      "Maximum consecutive 'Down' movements: 5\n",
      "Maximum consecutive 'No change': 13\n",
      "\n",
      "=== DIRECTION BY TIME PERIODS ===\n",
      "Direction distribution by hour:\n",
      "direction  Down  No change   Up\n",
      "hour                           \n",
      "9           348        363  336\n",
      "10          478        531  467\n",
      "11          538        630  485\n",
      "12          565        698  544\n",
      "13          473        751  455\n",
      "14          428        643  450\n",
      "15          469        825  479\n",
      "\n",
      "=== DIRECTION TRANSITIONS ===\n",
      "Most common direction transitions:\n",
      "  No change → No change: 2,073 times\n",
      "  Down → Up: 1,789 times\n",
      "  Up → Down: 1,434 times\n",
      "  No change → Down: 1,382 times\n",
      "  Up → No change: 1,340 times\n",
      "  Down → No change: 1,027 times\n",
      "  No change → Up: 985 times\n",
      "  Down → Down: 483 times\n",
      "  Up → Up: 442 times\n",
      "\n",
      "=== DIRECTION WITH VOLUME ANALYSIS ===\n",
      "Volume analysis by direction:\n",
      "               sum         mean  count\n",
      "direction                             \n",
      "Down       3889213  1178.906638   3299\n",
      "No change  2923497   658.297005   4441\n",
      "Up         4697461  1460.653296   3216\n",
      "\n",
      "=== DIRECTION WITH PRICE CHANGE MAGNITUDE ===\n",
      "Price change magnitude by direction:\n",
      "               mean       std   min   max\n",
      "direction                                \n",
      "Down      -0.091103  0.055096 -0.65 -0.05\n",
      "No change  0.000000  0.000000  0.00  0.00\n",
      "Up         0.093890  0.059423  0.05  0.75\n",
      "\n",
      "=== EXAMPLES OF EACH DIRECTION ===\n",
      "Sample 'Up' movements:\n",
      "               date  price  price_change  qty\n",
      "2025-08-07 09:15:01 386.75          0.45 1401\n",
      "2025-08-07 09:15:02 386.80          0.05 1795\n",
      "2025-08-07 09:15:02 386.95          0.15  741\n",
      "\n",
      "Sample 'Down' movements:\n",
      "               date  price  price_change  qty\n",
      "2025-08-07 09:15:01  386.3         -0.55  895\n",
      "2025-08-07 09:15:03  386.9         -0.05 2717\n",
      "2025-08-07 09:15:03  386.8         -0.10 9068\n",
      "\n",
      "Sample 'No change':\n",
      "               date  price  price_change   qty\n",
      "2025-08-07 09:15:00 386.85           NaN 65740\n",
      "2025-08-07 09:15:06 386.65           0.0  4519\n",
      "2025-08-07 09:15:09 386.00           0.0  1904\n",
      "\n",
      "=== DIRECTION SUMMARY ===\n",
      "✓ Direction column created successfully\n",
      "✓ Total rows: 10,956\n",
      "✓ Up movements: 3,216\n",
      "✓ Down movements: 3,299\n",
      "✓ No change: 4,441\n",
      "✓ Most common direction: No change\n",
      "✓ Ready for directional analysis and pattern recognition\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change', 'direction']\n",
      "Shape: (10956, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create direction column: \"Up\", \"Down\", \"No change\"\n",
    "print(\"=== DIRECTION COLUMN CREATION ===\")\n",
    "\n",
    "# Create direction column based on price_change\n",
    "df['direction'] = df['price_change'].apply(lambda x: \n",
    "    'Up' if x > 0 else \n",
    "    'Down' if x < 0 else \n",
    "    'No change'\n",
    ")\n",
    "\n",
    "# Display the first few rows to verify the direction column\n",
    "print(\"=== SAMPLE DATA WITH DIRECTION ===\")\n",
    "print(df[['date', 'price', 'price_change', 'direction', 'qty', 'trnvr']].head(10))\n",
    "\n",
    "# Count the occurrences of each direction\n",
    "print(f\"\\n=== DIRECTION DISTRIBUTION ===\")\n",
    "direction_counts = df['direction'].value_counts()\n",
    "print(direction_counts)\n",
    "\n",
    "# Calculate percentages\n",
    "total_rows = len(df)\n",
    "print(f\"\\n=== DIRECTION PERCENTAGES ===\")\n",
    "for direction, count in direction_counts.items():\n",
    "    percentage = (count / total_rows) * 100\n",
    "    print(f\"{direction}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "# Analyze direction patterns\n",
    "print(f\"\\n=== DIRECTION PATTERN ANALYSIS ===\")\n",
    "\n",
    "# Check for consecutive directions\n",
    "print(\"Direction sequence analysis:\")\n",
    "consecutive_up = 0\n",
    "consecutive_down = 0\n",
    "consecutive_no_change = 0\n",
    "max_consecutive_up = 0\n",
    "max_consecutive_down = 0\n",
    "max_consecutive_no_change = 0\n",
    "\n",
    "current_up = 0\n",
    "current_down = 0\n",
    "current_no_change = 0\n",
    "\n",
    "for direction in df['direction']:\n",
    "    if direction == 'Up':\n",
    "        current_up += 1\n",
    "        current_down = 0\n",
    "        current_no_change = 0\n",
    "        max_consecutive_up = max(max_consecutive_up, current_up)\n",
    "    elif direction == 'Down':\n",
    "        current_down += 1\n",
    "        current_up = 0\n",
    "        current_no_change = 0\n",
    "        max_consecutive_down = max(max_consecutive_down, current_down)\n",
    "    else:  # No change\n",
    "        current_no_change += 1\n",
    "        current_up = 0\n",
    "        current_down = 0\n",
    "        max_consecutive_no_change = max(max_consecutive_no_change, current_no_change)\n",
    "\n",
    "print(f\"Maximum consecutive 'Up' movements: {max_consecutive_up}\")\n",
    "print(f\"Maximum consecutive 'Down' movements: {max_consecutive_down}\")\n",
    "print(f\"Maximum consecutive 'No change': {max_consecutive_no_change}\")\n",
    "\n",
    "# Direction by time periods\n",
    "print(f\"\\n=== DIRECTION BY TIME PERIODS ===\")\n",
    "df['hour'] = df['date'].dt.hour\n",
    "hourly_direction = df.groupby('hour')['direction'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "print(\"Direction distribution by hour:\")\n",
    "print(hourly_direction)\n",
    "\n",
    "# Direction transitions (what follows what)\n",
    "print(f\"\\n=== DIRECTION TRANSITIONS ===\")\n",
    "transitions = []\n",
    "for i in range(1, len(df)):\n",
    "    prev_direction = df['direction'].iloc[i-1]\n",
    "    curr_direction = df['direction'].iloc[i]\n",
    "    transitions.append((prev_direction, curr_direction))\n",
    "\n",
    "transition_counts = pd.Series(transitions).value_counts().head(10)\n",
    "print(\"Most common direction transitions:\")\n",
    "for transition, count in transition_counts.items():\n",
    "    print(f\"  {transition[0]} → {transition[1]}: {count:,} times\")\n",
    "\n",
    "# Direction with volume analysis\n",
    "print(f\"\\n=== DIRECTION WITH VOLUME ANALYSIS ===\")\n",
    "direction_volume = df.groupby('direction')['qty'].agg(['sum', 'mean', 'count'])\n",
    "print(\"Volume analysis by direction:\")\n",
    "print(direction_volume)\n",
    "\n",
    "# Direction with price change magnitude\n",
    "print(f\"\\n=== DIRECTION WITH PRICE CHANGE MAGNITUDE ===\")\n",
    "direction_magnitude = df.groupby('direction')['price_change'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(\"Price change magnitude by direction:\")\n",
    "print(direction_magnitude)\n",
    "\n",
    "# Show examples of each direction\n",
    "print(f\"\\n=== EXAMPLES OF EACH DIRECTION ===\")\n",
    "\n",
    "# Up movements\n",
    "up_examples = df[df['direction'] == 'Up'][['date', 'price', 'price_change', 'qty']].head(3)\n",
    "print(\"Sample 'Up' movements:\")\n",
    "print(up_examples.to_string(index=False))\n",
    "\n",
    "# Down movements\n",
    "down_examples = df[df['direction'] == 'Down'][['date', 'price', 'price_change', 'qty']].head(3)\n",
    "print(f\"\\nSample 'Down' movements:\")\n",
    "print(down_examples.to_string(index=False))\n",
    "\n",
    "# No change\n",
    "no_change_examples = df[df['direction'] == 'No change'][['date', 'price', 'price_change', 'qty']].head(3)\n",
    "print(f\"\\nSample 'No change':\")\n",
    "print(no_change_examples.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== DIRECTION SUMMARY ===\")\n",
    "print(f\"✓ Direction column created successfully\")\n",
    "print(f\"✓ Total rows: {total_rows:,}\")\n",
    "print(f\"✓ Up movements: {direction_counts.get('Up', 0):,}\")\n",
    "print(f\"✓ Down movements: {direction_counts.get('Down', 0):,}\")\n",
    "print(f\"✓ No change: {direction_counts.get('No change', 0):,}\")\n",
    "print(f\"✓ Most common direction: {direction_counts.index[0]}\")\n",
    "print(f\"✓ Ready for directional analysis and pattern recognition\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6864362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ROLLING AVERAGE CALCULATION ===\n",
      "Calculating rolling averages...\n",
      "=== SAMPLE DATA WITH ROLLING AVERAGES ===\n",
      "                  date   price  price_1min_avg  price_5min_avg  \\\n",
      "0  2025-08-07 09:15:00  386.85      386.850000      386.850000   \n",
      "1  2025-08-07 09:15:01  386.30      386.575000      386.575000   \n",
      "2  2025-08-07 09:15:01  386.75      386.633333      386.633333   \n",
      "3  2025-08-07 09:15:02  386.80      386.675000      386.675000   \n",
      "4  2025-08-07 09:15:02  386.95      386.730000      386.730000   \n",
      "5  2025-08-07 09:15:03  386.90      386.758333      386.758333   \n",
      "6  2025-08-07 09:15:03  386.80      386.764286      386.764286   \n",
      "7  2025-08-07 09:15:04  386.75      386.762500      386.762500   \n",
      "8  2025-08-07 09:15:04  386.90      386.777778      386.777778   \n",
      "9  2025-08-07 09:15:05  386.65      386.765000      386.765000   \n",
      "10 2025-08-07 09:15:05  386.75      386.763636      386.763636   \n",
      "11 2025-08-07 09:15:06  386.65      386.754167      386.754167   \n",
      "12 2025-08-07 09:15:06  386.55      386.738462      386.738462   \n",
      "13 2025-08-07 09:15:07  386.40      386.714286      386.714286   \n",
      "14 2025-08-07 09:15:07  386.10      386.673333      386.673333   \n",
      "\n",
      "    price_15min_avg    qty  \n",
      "0        386.850000  65740  \n",
      "1        386.575000    895  \n",
      "2        386.633333   1401  \n",
      "3        386.675000   1795  \n",
      "4        386.730000    741  \n",
      "5        386.758333   2717  \n",
      "6        386.764286   9068  \n",
      "7        386.762500   1141  \n",
      "8        386.777778   1798  \n",
      "9        386.765000   2092  \n",
      "10       386.763636   1679  \n",
      "11       386.754167   4519  \n",
      "12       386.738462   1316  \n",
      "13       386.714286   2858  \n",
      "14       386.673333    640  \n",
      "\n",
      "=== ROLLING AVERAGE STATISTICS ===\n",
      "\n",
      "price_1min_avg:\n",
      "  Min: ₹383.55\n",
      "  Max: ₹383.55\n",
      "  Mean: ₹386.55\n",
      "  Std: ₹1.56\n",
      "\n",
      "price_5min_avg:\n",
      "  Min: ₹383.68\n",
      "  Max: ₹383.68\n",
      "  Mean: ₹386.52\n",
      "  Std: ₹1.52\n",
      "\n",
      "price_15min_avg:\n",
      "  Min: ₹383.76\n",
      "  Max: ₹383.76\n",
      "  Mean: ₹386.49\n",
      "  Std: ₹1.45\n",
      "\n",
      "=== PRICE VS ROLLING AVERAGES ANALYSIS ===\n",
      "Price differences from rolling averages:\n",
      "  vs 1-min avg: Mean=0.01, Std=0.16\n",
      "  vs 5-min avg: Mean=0.04, Std=0.36\n",
      "  vs 15-min avg: Mean=0.08, Std=0.51\n",
      "\n",
      "=== MOVING AVERAGE CROSSOVER ANALYSIS ===\n",
      "Price above 1-min average: 5,353 times (48.9%)\n",
      "Price above 5-min average: 5,648 times (51.6%)\n",
      "Price above 15-min average: 5,863 times (53.5%)\n",
      "\n",
      "=== MOVING AVERAGE CROSSOVER SIGNALS ===\n",
      "1-min vs 5-min crossovers:\n",
      "  Bullish (1-min crosses above 5-min): 58\n",
      "  Bearish (1-min crosses below 5-min): 58\n",
      "\n",
      "5-min vs 15-min crossovers:\n",
      "  Bullish (5-min crosses above 15-min): 15\n",
      "  Bearish (5-min crosses below 15-min): 14\n",
      "\n",
      "=== SAMPLE CROSSOVER SIGNALS ===\n",
      "Recent 1-min vs 5-min crossovers:\n",
      "               date  price  price_1min_avg  price_5min_avg  ma_1min_5min_signal\n",
      "2025-08-07 09:15:00 386.85      386.850000      386.850000                  NaN\n",
      "2025-08-07 09:16:30 387.10      386.335149      386.333333                  1.0\n",
      "2025-08-07 09:24:03 389.00      389.454167      389.521384                 -1.0\n",
      "2025-08-07 09:31:32 389.05      388.816667      388.760656                  1.0\n",
      "2025-08-07 09:35:27 389.25      389.260000      389.283019                 -1.0\n",
      "2025-08-07 09:38:39 389.20      389.045833      389.041935                  1.0\n",
      "2025-08-07 09:42:04 389.15      389.200000      389.208824                 -1.0\n",
      "2025-08-07 09:46:33 389.00      388.833333      388.809848                  1.0\n",
      "2025-08-07 09:49:52 388.80      388.925000      388.947458                 -1.0\n",
      "2025-08-07 09:52:57 388.95      388.917647      388.917188                  1.0\n",
      "\n",
      "=== ROLLING AVERAGE TRENDS ===\n",
      "1-min moving average trends:\n",
      "  Upward trending periods: 5,275\n",
      "  Downward trending periods: 5,396\n",
      "\n",
      "=== ROLLING AVERAGE SUMMARY ===\n",
      "✓ 1-minute rolling average calculated\n",
      "✓ 5-minute rolling average calculated\n",
      "✓ 15-minute rolling average calculated\n",
      "✓ Crossover signals identified\n",
      "✓ Trend analysis completed\n",
      "✓ Ready for technical analysis and trading signals\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change', 'direction', 'price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'price_vs_1min', 'price_vs_5min', 'price_vs_15min', 'above_1min', 'above_5min', 'above_15min', 'ma_1min_5min_cross', 'ma_1min_5min_signal', 'ma_5min_15min_cross', 'ma_5min_15min_signal', 'ma_1min_slope', 'ma_5min_slope', 'ma_15min_slope']\n",
      "Shape: (10956, 28)\n",
      "New columns added:\n",
      "  ✓ price_1min_avg\n",
      "  ✓ price_5min_avg\n",
      "  ✓ price_15min_avg\n",
      "  ✓ price_vs_1min\n",
      "  ✓ price_vs_5min\n",
      "  ✓ price_vs_15min\n",
      "  ✓ above_1min\n",
      "  ✓ above_5min\n",
      "  ✓ above_15min\n",
      "  ✓ ma_1min_5min_cross\n",
      "  ✓ ma_1min_5min_signal\n",
      "  ✓ ma_5min_15min_cross\n",
      "  ✓ ma_5min_15min_signal\n",
      "  ✓ ma_1min_slope\n",
      "  ✓ ma_5min_slope\n",
      "  ✓ ma_15min_slope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3402582214.py:14: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['price_1min_avg'] = df_temp['price'].rolling(window='1T', min_periods=1).mean()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3402582214.py:17: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['price_5min_avg'] = df_temp['price'].rolling(window='5T', min_periods=1).mean()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3402582214.py:20: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['price_15min_avg'] = df_temp['price'].rolling(window='15T', min_periods=1).mean()\n"
     ]
    }
   ],
   "source": [
    "# Calculate rolling averages (1 min, 5 min, 15 min) for price\n",
    "print(\"=== ROLLING AVERAGE CALCULATION ===\")\n",
    "\n",
    "# First, ensure the dataframe is sorted by datetime\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Set datetime as index for time-based rolling operations\n",
    "df_temp = df.set_index('date')\n",
    "\n",
    "# Calculate rolling averages at different time intervals\n",
    "print(\"Calculating rolling averages...\")\n",
    "\n",
    "# 1-minute rolling average\n",
    "df_temp['price_1min_avg'] = df_temp['price'].rolling(window='1T', min_periods=1).mean()\n",
    "\n",
    "# 5-minute rolling average\n",
    "df_temp['price_5min_avg'] = df_temp['price'].rolling(window='5T', min_periods=1).mean()\n",
    "\n",
    "# 15-minute rolling average\n",
    "df_temp['price_15min_avg'] = df_temp['price'].rolling(window='15T', min_periods=1).mean()\n",
    "\n",
    "# Reset index to get back to normal dataframe format\n",
    "df = df_temp.reset_index()\n",
    "\n",
    "# Display sample data with rolling averages\n",
    "print(\"=== SAMPLE DATA WITH ROLLING AVERAGES ===\")\n",
    "print(df[['date', 'price', 'price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'qty']].head(15))\n",
    "\n",
    "# Basic statistics of rolling averages\n",
    "print(f\"\\n=== ROLLING AVERAGE STATISTICS ===\")\n",
    "rolling_cols = ['price_1min_avg', 'price_5min_avg', 'price_15min_avg']\n",
    "\n",
    "for col in rolling_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: ₹{df[col].min():.2f}\")\n",
    "    print(f\"  Max: ₹{df[col].min():.2f}\")\n",
    "    print(f\"  Mean: ₹{df[col].mean():.2f}\")\n",
    "    print(f\"  Std: ₹{df[col].std():.2f}\")\n",
    "\n",
    "# Compare current price vs rolling averages\n",
    "print(f\"\\n=== PRICE VS ROLLING AVERAGES ANALYSIS ===\")\n",
    "\n",
    "# Calculate differences from rolling averages\n",
    "df['price_vs_1min'] = df['price'] - df['price_1min_avg']\n",
    "df['price_vs_5min'] = df['price'] - df['price_5min_avg']\n",
    "df['price_vs_15min'] = df['price'] - df['price_15min_avg']\n",
    "\n",
    "# Show statistics of these differences\n",
    "print(\"Price differences from rolling averages:\")\n",
    "print(f\"  vs 1-min avg: Mean={df['price_vs_1min'].mean():.2f}, Std={df['price_vs_1min'].std():.2f}\")\n",
    "print(f\"  vs 5-min avg: Mean={df['price_vs_5min'].mean():.2f}, Std={df['price_vs_5min'].std():.2f}\")\n",
    "print(f\"  vs 15-min avg: Mean={df['price_vs_15min'].mean():.2f}, Std={df['price_vs_15min'].std():.2f}\")\n",
    "\n",
    "# Identify when price is above/below each moving average\n",
    "print(f\"\\n=== MOVING AVERAGE CROSSOVER ANALYSIS ===\")\n",
    "\n",
    "# Price position relative to moving averages\n",
    "df['above_1min'] = df['price'] > df['price_1min_avg']\n",
    "df['above_5min'] = df['price'] > df['price_5min_avg']\n",
    "df['above_15min'] = df['price'] > df['price_15min_avg']\n",
    "\n",
    "# Count how many times price is above each moving average\n",
    "above_1min_count = df['above_1min'].sum()\n",
    "above_5min_count = df['above_5min'].sum()\n",
    "above_15min_count = df['above_15min'].sum()\n",
    "\n",
    "print(f\"Price above 1-min average: {above_1min_count:,} times ({(above_1min_count/len(df)*100):.1f}%)\")\n",
    "print(f\"Price above 5-min average: {above_5min_count:,} times ({(above_5min_count/len(df)*100):.1f}%)\")\n",
    "print(f\"Price above 15-min average: {above_15min_count:,} times ({(above_15min_count/len(df)*100):.1f}%)\")\n",
    "\n",
    "# Moving average crossover signals\n",
    "print(f\"\\n=== MOVING AVERAGE CROSSOVER SIGNALS ===\")\n",
    "\n",
    "# 1-min vs 5-min crossover\n",
    "df['ma_1min_5min_cross'] = (df['price_1min_avg'] > df['price_5min_avg']).astype(int)\n",
    "df['ma_1min_5min_signal'] = df['ma_1min_5min_cross'].diff()\n",
    "\n",
    "# 5-min vs 15-min crossover\n",
    "df['ma_5min_15min_cross'] = (df['price_5min_avg'] > df['price_15min_avg']).astype(int)\n",
    "df['ma_5min_15min_signal'] = df['ma_5min_15min_cross'].diff()\n",
    "\n",
    "# Count crossover signals\n",
    "bullish_1min_5min = (df['ma_1min_5min_signal'] == 1).sum()\n",
    "bearish_1min_5min = (df['ma_1min_5min_signal'] == -1).sum()\n",
    "\n",
    "bullish_5min_15min = (df['ma_5min_15min_signal'] == 1).sum()\n",
    "bearish_5min_15min = (df['ma_5min_15min_signal'] == -1).sum()\n",
    "\n",
    "print(f\"1-min vs 5-min crossovers:\")\n",
    "print(f\"  Bullish (1-min crosses above 5-min): {bullish_1min_5min}\")\n",
    "print(f\"  Bearish (1-min crosses below 5-min): {bearish_1min_5min}\")\n",
    "\n",
    "print(f\"\\n5-min vs 15-min crossovers:\")\n",
    "print(f\"  Bullish (5-min crosses above 15-min): {bullish_5min_15min}\")\n",
    "print(f\"  Bearish (5-min crosses below 15-min): {bearish_5min_15min}\")\n",
    "\n",
    "# Show sample of crossover signals\n",
    "print(f\"\\n=== SAMPLE CROSSOVER SIGNALS ===\")\n",
    "crossover_sample = df[df['ma_1min_5min_signal'] != 0][['date', 'price', 'price_1min_avg', 'price_5min_avg', 'ma_1min_5min_signal']].head(10)\n",
    "print(\"Recent 1-min vs 5-min crossovers:\")\n",
    "print(crossover_sample.to_string(index=False))\n",
    "\n",
    "# Rolling average trends\n",
    "print(f\"\\n=== ROLLING AVERAGE TRENDS ===\")\n",
    "\n",
    "# Calculate the slope of each moving average (trend direction)\n",
    "df['ma_1min_slope'] = df['price_1min_avg'].diff()\n",
    "df['ma_5min_slope'] = df['price_5min_avg'].diff()\n",
    "df['ma_15min_slope'] = df['price_15min_avg'].diff()\n",
    "\n",
    "# Count trending periods\n",
    "trending_1min_up = (df['ma_1min_slope'] > 0).sum()\n",
    "trending_1min_down = (df['ma_1min_slope'] < 0).sum()\n",
    "\n",
    "print(f\"1-min moving average trends:\")\n",
    "print(f\"  Upward trending periods: {trending_1min_up:,}\")\n",
    "print(f\"  Downward trending periods: {trending_1min_down:,}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== ROLLING AVERAGE SUMMARY ===\")\n",
    "print(f\"✓ 1-minute rolling average calculated\")\n",
    "print(f\"✓ 5-minute rolling average calculated\")\n",
    "print(f\"✓ 15-minute rolling average calculated\")\n",
    "print(f\"✓ Crossover signals identified\")\n",
    "print(f\"✓ Trend analysis completed\")\n",
    "print(f\"✓ Ready for technical analysis and trading signals\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"New columns added:\")\n",
    "new_cols = ['price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'price_vs_1min', \n",
    "            'price_vs_5min', 'price_vs_15min', 'above_1min', 'above_5min', 'above_15min',\n",
    "            'ma_1min_5min_cross', 'ma_1min_5min_signal', 'ma_5min_15min_cross', \n",
    "            'ma_5min_15min_signal', 'ma_1min_slope', 'ma_5min_slope', 'ma_15min_slope']\n",
    "for col in new_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  ✓ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3afb2c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ROLLING VOLUME SUM CALCULATION ===\n",
      "Calculating rolling volume sums...\n",
      "=== SAMPLE DATA WITH ROLLING VOLUME SUMS ===\n",
      "                  date    qty  volume_1min_sum  volume_5min_sum  \\\n",
      "0  2025-08-07 09:15:00  65740          65740.0          65740.0   \n",
      "1  2025-08-07 09:15:01    895          66635.0          66635.0   \n",
      "2  2025-08-07 09:15:01   1401          68036.0          68036.0   \n",
      "3  2025-08-07 09:15:02   1795          69831.0          69831.0   \n",
      "4  2025-08-07 09:15:02    741          70572.0          70572.0   \n",
      "5  2025-08-07 09:15:03   2717          73289.0          73289.0   \n",
      "6  2025-08-07 09:15:03   9068          82357.0          82357.0   \n",
      "7  2025-08-07 09:15:04   1141          83498.0          83498.0   \n",
      "8  2025-08-07 09:15:04   1798          85296.0          85296.0   \n",
      "9  2025-08-07 09:15:05   2092          87388.0          87388.0   \n",
      "10 2025-08-07 09:15:05   1679          89067.0          89067.0   \n",
      "11 2025-08-07 09:15:06   4519          93586.0          93586.0   \n",
      "12 2025-08-07 09:15:06   1316          94902.0          94902.0   \n",
      "13 2025-08-07 09:15:07   2858          97760.0          97760.0   \n",
      "14 2025-08-07 09:15:07    640          98400.0          98400.0   \n",
      "\n",
      "    volume_15min_sum  volume_30min_sum  \n",
      "0            65740.0           65740.0  \n",
      "1            66635.0           66635.0  \n",
      "2            68036.0           68036.0  \n",
      "3            69831.0           69831.0  \n",
      "4            70572.0           70572.0  \n",
      "5            73289.0           73289.0  \n",
      "6            82357.0           82357.0  \n",
      "7            83498.0           83498.0  \n",
      "8            85296.0           85296.0  \n",
      "9            87388.0           87388.0  \n",
      "10           89067.0           89067.0  \n",
      "11           93586.0           93586.0  \n",
      "12           94902.0           94902.0  \n",
      "13           97760.0           97760.0  \n",
      "14           98400.0           98400.0  \n",
      "\n",
      "=== ROLLING VOLUME SUM STATISTICS ===\n",
      "\n",
      "volume_1min_sum:\n",
      "  Min: 3,271\n",
      "  Max: 240,694\n",
      "  Mean: 41,775\n",
      "  Std: 40,998\n",
      "\n",
      "volume_5min_sum:\n",
      "  Min: 44,608\n",
      "  Max: 751,790\n",
      "  Mean: 183,460\n",
      "  Std: 118,364\n",
      "\n",
      "volume_15min_sum:\n",
      "  Min: 65,740\n",
      "  Max: 1,421,831\n",
      "  Mean: 479,341\n",
      "  Std: 213,644\n",
      "\n",
      "volume_30min_sum:\n",
      "  Min: 65,740\n",
      "  Max: 1,828,633\n",
      "  Mean: 897,923\n",
      "  Std: 342,277\n",
      "\n",
      "=== VOLUME ANALYSIS BY TIME WINDOWS ===\n",
      "Volume comparison across timeframes:\n",
      "  1-min average: 41,775\n",
      "  5-min average: 183,460\n",
      "  15-min average: 479,341\n",
      "  30-min average: 897,923\n",
      "\n",
      "=== VOLUME INTENSITY ANALYSIS ===\n",
      "Volume per minute for each window:\n",
      "  1-min window: 41,775 per minute\n",
      "  5-min window: 36,692 per minute\n",
      "  15-min window: 31,956 per minute\n",
      "  30-min window: 29,931 per minute\n",
      "\n",
      "=== VOLUME SPIKE DETECTION ===\n",
      "volume_1min_sum: 629 periods above 123,771 (2σ threshold)\n",
      "volume_5min_sum: 374 periods above 420,188 (2σ threshold)\n",
      "volume_15min_sum: 334 periods above 906,628 (2σ threshold)\n",
      "volume_30min_sum: 726 periods above 1,582,477 (2σ threshold)\n",
      "\n",
      "=== EXAMPLES OF VOLUME SPIKES ===\n",
      "\n",
      "volume_1min_sum spikes (top 3):\n",
      "               date  volume_1min_sum  qty  price\n",
      "2025-08-07 09:15:09         123896.0 1904  386.0\n",
      "2025-08-07 09:15:10         124376.0  480  385.7\n",
      "2025-08-07 09:15:10         130704.0 6328  386.0\n",
      "\n",
      "volume_5min_sum spikes (top 3):\n",
      "               date  volume_5min_sum   qty  price\n",
      "2025-08-07 09:17:00         424009.0  6377 387.60\n",
      "2025-08-07 09:17:08         441708.0 17699 387.60\n",
      "2025-08-07 09:17:09         446868.0  5160 387.55\n",
      "\n",
      "volume_15min_sum spikes (top 3):\n",
      "               date  volume_15min_sum   qty  price\n",
      "2025-08-07 09:20:49          932902.0 43873 389.85\n",
      "2025-08-07 09:21:01          966465.0 33563 389.65\n",
      "2025-08-07 09:21:01          967610.0  1145 389.55\n",
      "\n",
      "volume_30min_sum spikes (top 3):\n",
      "               date  volume_30min_sum  qty  price\n",
      "2025-08-07 09:35:12         1583813.0 4419 389.25\n",
      "2025-08-07 09:35:19         1583994.0  181 389.20\n",
      "2025-08-07 09:35:27         1586242.0 2248 389.25\n",
      "\n",
      "=== VOLUME TREND ANALYSIS ===\n",
      "Volume 1Min:\n",
      "  Increasing: 7,218 periods\n",
      "  Decreasing: 3,706 periods\n",
      "Volume 5Min:\n",
      "  Increasing: 7,590 periods\n",
      "  Decreasing: 3,342 periods\n",
      "Volume 15Min:\n",
      "  Increasing: 7,651 periods\n",
      "  Decreasing: 3,280 periods\n",
      "Volume 30Min:\n",
      "  Increasing: 7,952 periods\n",
      "  Decreasing: 2,980 periods\n",
      "\n",
      "=== VOLUME-PRICE CORRELATION ===\n",
      "volume_1min_sum vs Price correlation: 0.1923\n",
      "volume_5min_sum vs Price correlation: 0.4227\n",
      "volume_15min_sum vs Price correlation: 0.5060\n",
      "volume_30min_sum vs Price correlation: 0.4976\n",
      "\n",
      "Volume vs Price Change correlation:\n",
      "volume_1min_sum vs Price Change correlation: 0.0107\n",
      "volume_5min_sum vs Price Change correlation: 0.0141\n",
      "volume_15min_sum vs Price Change correlation: 0.0065\n",
      "volume_30min_sum vs Price Change correlation: 0.0019\n",
      "\n",
      "=== TIME-BASED VOLUME ANALYSIS ===\n",
      "Total volume by hour:\n",
      "  09:00 - 09:59: 2,164,111\n",
      "  10:00 - 10:59: 1,436,774\n",
      "  11:00 - 11:59: 1,340,606\n",
      "  12:00 - 12:59: 1,462,840\n",
      "  13:00 - 13:59: 1,428,015\n",
      "  14:00 - 14:59: 1,985,212\n",
      "  15:00 - 15:59: 1,692,613\n",
      "\n",
      "=== ROLLING VS CUMULATIVE VOLUME ===\n",
      "Final cumulative volume: 11,466,759\n",
      "Final 30-min rolling volume: 1,692,613\n",
      "Rolling volume as % of total: 14.8%\n",
      "\n",
      "=== ROLLING VOLUME SUMMARY ===\n",
      "✓ 1-minute rolling volume sum calculated\n",
      "✓ 5-minute rolling volume sum calculated\n",
      "✓ 15-minute rolling volume sum calculated\n",
      "✓ 30-minute rolling volume sum calculated\n",
      "✓ Volume intensity analysis completed\n",
      "✓ Volume spike detection implemented\n",
      "✓ Volume-price correlation analyzed\n",
      "✓ Ready for volume-based analysis and trading signals\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change', 'direction', 'price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'price_vs_1min', 'price_vs_5min', 'price_vs_15min', 'above_1min', 'above_5min', 'above_15min', 'ma_1min_5min_cross', 'ma_1min_5min_signal', 'ma_5min_15min_cross', 'ma_5min_15min_signal', 'ma_1min_slope', 'ma_5min_slope', 'ma_15min_slope', 'volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum', 'volume_1min_per_min', 'volume_5min_per_min', 'volume_15min_per_min', 'volume_30min_per_min', 'volume_1min_trend', 'volume_5min_trend', 'volume_15min_trend', 'volume_30min_trend']\n",
      "Shape: (10956, 40)\n",
      "New volume columns added:\n",
      "  ✓ volume_1min_sum\n",
      "  ✓ volume_5min_sum\n",
      "  ✓ volume_15min_sum\n",
      "  ✓ volume_30min_sum\n",
      "  ✓ volume_1min_per_min\n",
      "  ✓ volume_5min_per_min\n",
      "  ✓ volume_15min_per_min\n",
      "  ✓ volume_30min_per_min\n",
      "  ✓ volume_1min_trend\n",
      "  ✓ volume_5min_trend\n",
      "  ✓ volume_15min_trend\n",
      "  ✓ volume_30min_trend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\559120730.py:11: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['volume_1min_sum'] = df_temp['qty'].rolling(window='1T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\559120730.py:14: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['volume_5min_sum'] = df_temp['qty'].rolling(window='5T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\559120730.py:17: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['volume_15min_sum'] = df_temp['qty'].rolling(window='15T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\559120730.py:20: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['volume_30min_sum'] = df_temp['qty'].rolling(window='30T', min_periods=1).sum()\n"
     ]
    }
   ],
   "source": [
    "# Calculate rolling sum of volume over time windows\n",
    "print(\"=== ROLLING VOLUME SUM CALCULATION ===\")\n",
    "\n",
    "# Ensure the dataframe is sorted by datetime and has datetime index\n",
    "df_temp = df.set_index('date')\n",
    "\n",
    "# Calculate rolling sum of volume at different time intervals\n",
    "print(\"Calculating rolling volume sums...\")\n",
    "\n",
    "# 1-minute rolling volume sum\n",
    "df_temp['volume_1min_sum'] = df_temp['qty'].rolling(window='1T', min_periods=1).sum()\n",
    "\n",
    "# 5-minute rolling volume sum\n",
    "df_temp['volume_5min_sum'] = df_temp['qty'].rolling(window='5T', min_periods=1).sum()\n",
    "\n",
    "# 15-minute rolling volume sum\n",
    "df_temp['volume_15min_sum'] = df_temp['qty'].rolling(window='15T', min_periods=1).sum()\n",
    "\n",
    "# 30-minute rolling volume sum\n",
    "df_temp['volume_30min_sum'] = df_temp['qty'].rolling(window='30T', min_periods=1).sum()\n",
    "\n",
    "# Reset index to get back to normal dataframe format\n",
    "df = df_temp.reset_index()\n",
    "\n",
    "# Display sample data with rolling volume sums\n",
    "print(\"=== SAMPLE DATA WITH ROLLING VOLUME SUMS ===\")\n",
    "print(df[['date', 'qty', 'volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum']].head(15))\n",
    "\n",
    "# Basic statistics of rolling volume sums\n",
    "print(f\"\\n=== ROLLING VOLUME SUM STATISTICS ===\")\n",
    "volume_sum_cols = ['volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum']\n",
    "\n",
    "for col in volume_sum_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: {df[col].min():,.0f}\")\n",
    "    print(f\"  Max: {df[col].max():,.0f}\")\n",
    "    print(f\"  Mean: {df[col].mean():,.0f}\")\n",
    "    print(f\"  Std: {df[col].std():,.0f}\")\n",
    "\n",
    "# Volume analysis by time windows\n",
    "print(f\"\\n=== VOLUME ANALYSIS BY TIME WINDOWS ===\")\n",
    "\n",
    "# Compare volume across different timeframes\n",
    "print(\"Volume comparison across timeframes:\")\n",
    "print(f\"  1-min average: {df['volume_1min_sum'].mean():,.0f}\")\n",
    "print(f\"  5-min average: {df['volume_5min_sum'].mean():,.0f}\")\n",
    "print(f\"  15-min average: {df['volume_15min_sum'].mean():,.0f}\")\n",
    "print(f\"  30-min average: {df['volume_30min_sum'].mean():,.0f}\")\n",
    "\n",
    "# Volume intensity analysis\n",
    "print(f\"\\n=== VOLUME INTENSITY ANALYSIS ===\")\n",
    "\n",
    "# Calculate volume per minute for each window\n",
    "df['volume_1min_per_min'] = df['volume_1min_sum'] / 1\n",
    "df['volume_5min_per_min'] = df['volume_5min_sum'] / 5\n",
    "df['volume_15min_per_min'] = df['volume_15min_sum'] / 15\n",
    "df['volume_30min_per_min'] = df['volume_30min_sum'] / 30\n",
    "\n",
    "print(\"Volume per minute for each window:\")\n",
    "print(f\"  1-min window: {df['volume_1min_per_min'].mean():,.0f} per minute\")\n",
    "print(f\"  5-min window: {df['volume_5min_per_min'].mean():,.0f} per minute\")\n",
    "print(f\"  15-min window: {df['volume_15min_per_min'].mean():,.0f} per minute\")\n",
    "print(f\"  30-min window: {df['volume_30min_per_min'].mean():,.0f} per minute\")\n",
    "\n",
    "# Volume spikes detection\n",
    "print(f\"\\n=== VOLUME SPIKE DETECTION ===\")\n",
    "\n",
    "# Find periods of unusually high volume (above 2 standard deviations)\n",
    "for col in volume_sum_cols:\n",
    "    mean_vol = df[col].mean()\n",
    "    std_vol = df[col].std()\n",
    "    threshold = mean_vol + 2 * std_vol\n",
    "    \n",
    "    high_volume_periods = (df[col] > threshold).sum()\n",
    "    print(f\"{col}: {high_volume_periods} periods above {threshold:,.0f} (2σ threshold)\")\n",
    "\n",
    "# Show examples of volume spikes\n",
    "print(f\"\\n=== EXAMPLES OF VOLUME SPIKES ===\")\n",
    "for col in volume_sum_cols:\n",
    "    mean_vol = df[col].mean()\n",
    "    std_vol = df[col].std()\n",
    "    threshold = mean_vol + 2 * std_vol\n",
    "    \n",
    "    spikes = df[df[col] > threshold][['date', col, 'qty', 'price']].head(3)\n",
    "    if len(spikes) > 0:\n",
    "        print(f\"\\n{col} spikes (top 3):\")\n",
    "        print(spikes.to_string(index=False))\n",
    "\n",
    "# Volume trend analysis\n",
    "print(f\"\\n=== VOLUME TREND ANALYSIS ===\")\n",
    "\n",
    "# Calculate volume trends (slopes) for each window\n",
    "df['volume_1min_trend'] = df['volume_1min_sum'].diff()\n",
    "df['volume_5min_trend'] = df['volume_5min_sum'].diff()\n",
    "df['volume_15min_trend'] = df['volume_15min_sum'].diff()\n",
    "df['volume_30min_trend'] = df['volume_30min_sum'].diff()\n",
    "\n",
    "# Count increasing vs decreasing volume periods\n",
    "for col in ['volume_1min_trend', 'volume_5min_trend', 'volume_15min_trend', 'volume_30min_trend']:\n",
    "    increasing = (df[col] > 0).sum()\n",
    "    decreasing = (df[col] < 0).sum()\n",
    "    window_name = col.replace('_trend', '').replace('_', ' ').title()\n",
    "    print(f\"{window_name}:\")\n",
    "    print(f\"  Increasing: {increasing:,} periods\")\n",
    "    print(f\"  Decreasing: {decreasing:,} periods\")\n",
    "\n",
    "# Volume vs Price correlation\n",
    "print(f\"\\n=== VOLUME-PRICE CORRELATION ===\")\n",
    "\n",
    "# Calculate correlation between volume and price for each timeframe\n",
    "for col in volume_sum_cols:\n",
    "    correlation = df[col].corr(df['price'])\n",
    "    print(f\"{col} vs Price correlation: {correlation:.4f}\")\n",
    "\n",
    "# Volume vs Price change correlation\n",
    "print(f\"\\nVolume vs Price Change correlation:\")\n",
    "for col in volume_sum_cols:\n",
    "    correlation = df[col].corr(df['price_change'])\n",
    "    print(f\"{col} vs Price Change correlation: {correlation:.4f}\")\n",
    "\n",
    "# Time-based volume analysis\n",
    "print(f\"\\n=== TIME-BASED VOLUME ANALYSIS ===\")\n",
    "\n",
    "# Volume by hour of the day\n",
    "df['hour'] = df['date'].dt.hour\n",
    "hourly_volume = df.groupby('hour')['qty'].sum()\n",
    "print(\"Total volume by hour:\")\n",
    "for hour, volume in hourly_volume.items():\n",
    "    print(f\"  {hour:02d}:00 - {hour:02d}:59: {volume:,}\")\n",
    "\n",
    "# Rolling volume vs cumulative volume comparison\n",
    "print(f\"\\n=== ROLLING VS CUMULATIVE VOLUME ===\")\n",
    "print(f\"Final cumulative volume: {df['cum_trnvr'].iloc[-1]/df['price'].iloc[-1]:,.0f}\")\n",
    "print(f\"Final 30-min rolling volume: {df['volume_30min_sum'].iloc[-1]:,.0f}\")\n",
    "print(f\"Rolling volume as % of total: {(df['volume_30min_sum'].iloc[-1]/(df['cum_trnvr'].iloc[-1]/df['price'].iloc[-1])*100):.1f}%\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== ROLLING VOLUME SUMMARY ===\")\n",
    "print(f\"✓ 1-minute rolling volume sum calculated\")\n",
    "print(f\"✓ 5-minute rolling volume sum calculated\")\n",
    "print(f\"✓ 15-minute rolling volume sum calculated\")\n",
    "print(f\"✓ 30-minute rolling volume sum calculated\")\n",
    "print(f\"✓ Volume intensity analysis completed\")\n",
    "print(f\"✓ Volume spike detection implemented\")\n",
    "print(f\"✓ Volume-price correlation analyzed\")\n",
    "print(f\"✓ Ready for volume-based analysis and trading signals\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"New volume columns added:\")\n",
    "volume_new_cols = ['volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum',\n",
    "                   'volume_1min_per_min', 'volume_5min_per_min', 'volume_15min_per_min', 'volume_30min_per_min',\n",
    "                   'volume_1min_trend', 'volume_5min_trend', 'volume_15min_trend', 'volume_30min_trend']\n",
    "for col in volume_new_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  ✓ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c267ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VWAP CALCULATION ===\n",
      "Calculating VWAP...\n",
      "=== OVERALL VWAP ===\n",
      "Total volume: 11,510,171\n",
      "Total price × volume: ₹4,451,969,111.70\n",
      "Overall VWAP: ₹386.79\n",
      "\n",
      "=== ROLLING VWAP CALCULATION ===\n",
      "=== SAMPLE DATA WITH VWAP VALUES ===\n",
      "                  date   price    qty   vwap_1min   vwap_5min  vwap_15min  \\\n",
      "0  2025-08-07 09:15:00  386.85  65740  386.850000  386.850000  386.850000   \n",
      "1  2025-08-07 09:15:01  386.30    895  386.842613  386.842613  386.842613   \n",
      "2  2025-08-07 09:15:01  386.75   1401  386.840706  386.840706  386.840706   \n",
      "3  2025-08-07 09:15:02  386.80   1795  386.839659  386.839659  386.839659   \n",
      "4  2025-08-07 09:15:02  386.95    741  386.840818  386.840818  386.840818   \n",
      "5  2025-08-07 09:15:03  386.90   2717  386.843012  386.843012  386.843012   \n",
      "6  2025-08-07 09:15:03  386.80   9068  386.838276  386.838276  386.838276   \n",
      "7  2025-08-07 09:15:04  386.75   1141  386.837070  386.837070  386.837070   \n",
      "8  2025-08-07 09:15:04  386.90   1798  386.838396  386.838396  386.838396   \n",
      "9  2025-08-07 09:15:05  386.65   2092  386.833886  386.833886  386.833886   \n",
      "10 2025-08-07 09:15:05  386.75   1679  386.832305  386.832305  386.832305   \n",
      "11 2025-08-07 09:15:06  386.65   4519  386.823502  386.823502  386.823502   \n",
      "12 2025-08-07 09:15:06  386.55   1316  386.819709  386.819709  386.819709   \n",
      "13 2025-08-07 09:15:07  386.40   2858  386.807439  386.807439  386.807439   \n",
      "14 2025-08-07 09:15:07  386.10    640  386.802838  386.802838  386.802838   \n",
      "\n",
      "    vwap_30min  \n",
      "0   386.850000  \n",
      "1   386.842613  \n",
      "2   386.840706  \n",
      "3   386.839659  \n",
      "4   386.840818  \n",
      "5   386.843012  \n",
      "6   386.838276  \n",
      "7   386.837070  \n",
      "8   386.838396  \n",
      "9   386.833886  \n",
      "10  386.832305  \n",
      "11  386.823502  \n",
      "12  386.819709  \n",
      "13  386.807439  \n",
      "14  386.802838  \n",
      "\n",
      "=== VWAP STATISTICS ===\n",
      "\n",
      "vwap_1min:\n",
      "  Min: ₹383.54\n",
      "  Max: ₹383.54\n",
      "  Mean: ₹386.55\n",
      "  Std: ₹1.56\n",
      "\n",
      "vwap_5min:\n",
      "  Min: ₹383.66\n",
      "  Max: ₹383.66\n",
      "  Mean: ₹386.52\n",
      "  Std: ₹1.50\n",
      "\n",
      "vwap_15min:\n",
      "  Min: ₹383.79\n",
      "  Max: ₹383.79\n",
      "  Mean: ₹386.48\n",
      "  Std: ₹1.42\n",
      "\n",
      "vwap_30min:\n",
      "  Min: ₹384.00\n",
      "  Max: ₹384.00\n",
      "  Mean: ₹386.47\n",
      "  Std: ₹1.38\n",
      "\n",
      "=== PRICE VS VWAP ANALYSIS ===\n",
      "Price position relative to VWAP:\n",
      "\n",
      "  1min VWAP:\n",
      "    Above: 5,375 times (49.1%)\n",
      "    Below: 5,580 times (50.9%)\n",
      "    Equal: 1 times (0.0%)\n",
      "\n",
      "  5min VWAP:\n",
      "    Above: 5,725 times (52.3%)\n",
      "    Below: 5,230 times (47.7%)\n",
      "    Equal: 1 times (0.0%)\n",
      "\n",
      "  15min VWAP:\n",
      "    Above: 5,933 times (54.2%)\n",
      "    Below: 5,022 times (45.8%)\n",
      "    Equal: 1 times (0.0%)\n",
      "\n",
      "  30min VWAP:\n",
      "    Above: 5,696 times (52.0%)\n",
      "    Below: 5,259 times (48.0%)\n",
      "    Equal: 1 times (0.0%)\n",
      "\n",
      "=== VWAP AS SUPPORT/RESISTANCE ===\n",
      "1min VWAP: 10,780 times price within 0.1% of VWAP\n",
      "5min VWAP: 9,278 times price within 0.1% of VWAP\n",
      "15min VWAP: 6,740 times price within 0.1% of VWAP\n",
      "30min VWAP: 4,183 times price within 0.1% of VWAP\n",
      "\n",
      "=== VWAP CROSSOVER ANALYSIS ===\n",
      "1min VWAP crossovers:\n",
      "  Bullish (price crosses above): 932\n",
      "  Bearish (price crosses below): 931\n",
      "5min VWAP crossovers:\n",
      "  Bullish (price crosses above): 427\n",
      "  Bearish (price crosses below): 427\n",
      "15min VWAP crossovers:\n",
      "  Bullish (price crosses above): 215\n",
      "  Bearish (price crosses below): 214\n",
      "30min VWAP crossovers:\n",
      "  Bullish (price crosses above): 135\n",
      "  Bearish (price crosses below): 134\n",
      "\n",
      "=== VWAP TREND ANALYSIS ===\n",
      "1min VWAP trends:\n",
      "  Upward: 5,522 periods\n",
      "  Downward: 5,430 periods\n",
      "5min VWAP trends:\n",
      "  Upward: 5,691 periods\n",
      "  Downward: 5,264 periods\n",
      "15min VWAP trends:\n",
      "  Upward: 5,766 periods\n",
      "  Downward: 5,188 periods\n",
      "30min VWAP trends:\n",
      "  Upward: 5,418 periods\n",
      "  Downward: 5,537 periods\n",
      "\n",
      "=== VWAP VS SIMPLE MOVING AVERAGE ===\n",
      "VWAP vs Simple Price Average:\n",
      "  Overall VWAP: ₹386.79\n",
      "  Simple Price Average: ₹386.56\n",
      "  Difference: ₹0.22\n",
      "  vwap_1min vs Price correlation: 0.9949\n",
      "  vwap_5min vs Price correlation: 0.9767\n",
      "  vwap_15min vs Price correlation: 0.9531\n",
      "  vwap_30min vs Price correlation: 0.9216\n",
      "\n",
      "=== VWAP TRADING SIGNALS ===\n",
      "VWAP-based trading signals (using 15-min VWAP):\n",
      "  Buy: 5,933 times (54.2%)\n",
      "  Sell: 5,022 times (45.8%)\n",
      "  Hold: 1 times (0.0%)\n",
      "\n",
      "=== VWAP SUMMARY ===\n",
      "✓ Overall VWAP: ₹386.79\n",
      "✓ Rolling VWAP calculated for 1min, 5min, 15min, 30min windows\n",
      "✓ Price vs VWAP analysis completed\n",
      "✓ VWAP crossover signals generated\n",
      "✓ VWAP trend analysis completed\n",
      "✓ Trading signals based on VWAP generated\n",
      "✓ Ready for VWAP-based trading strategies\n",
      "\n",
      "=== UPDATED DATAFRAME INFO ===\n",
      "Columns: ['date', 'price', 'qty', 'trnvr', 'cum_trnvr', 'date_only', 'time', 'hour', 'minute', 'second', 'price_change', 'direction', 'price_1min_avg', 'price_5min_avg', 'price_15min_avg', 'price_vs_1min', 'price_vs_5min', 'price_vs_15min', 'above_1min', 'above_5min', 'above_15min', 'ma_1min_5min_cross', 'ma_1min_5min_signal', 'ma_5min_15min_cross', 'ma_5min_15min_signal', 'ma_1min_slope', 'ma_5min_slope', 'ma_15min_slope', 'volume_1min_sum', 'volume_5min_sum', 'volume_15min_sum', 'volume_30min_sum', 'volume_1min_per_min', 'volume_5min_per_min', 'volume_15min_per_min', 'volume_30min_per_min', 'volume_1min_trend', 'volume_5min_trend', 'volume_15min_trend', 'volume_30min_trend', 'vwap_1min', 'vwap_5min', 'vwap_15min', 'vwap_30min', 'price_vs_vwap_1min', 'price_vs_vwap_5min', 'price_vs_vwap_15min', 'price_vs_vwap_30min', 'above_vwap_1min', 'vwap_1min_cross', 'vwap_1min_signal', 'above_vwap_5min', 'vwap_5min_cross', 'vwap_5min_signal', 'above_vwap_15min', 'vwap_15min_cross', 'vwap_15min_signal', 'above_vwap_30min', 'vwap_30min_cross', 'vwap_30min_signal', 'vwap_1min_trend', 'vwap_5min_trend', 'vwap_15min_trend', 'vwap_30min_trend', 'vwap_signal']\n",
      "Shape: (10956, 65)\n",
      "New VWAP columns added:\n",
      "  ✓ vwap_1min\n",
      "  ✓ vwap_5min\n",
      "  ✓ vwap_15min\n",
      "  ✓ vwap_30min\n",
      "  ✓ price_vs_vwap_1min\n",
      "  ✓ price_vs_vwap_5min\n",
      "  ✓ price_vs_vwap_15min\n",
      "  ✓ price_vs_vwap_30min\n",
      "  ✓ above_vwap_1min\n",
      "  ✓ above_vwap_5min\n",
      "  ✓ above_vwap_15min\n",
      "  ✓ above_vwap_30min\n",
      "  ✓ vwap_1min_cross\n",
      "  ✓ vwap_5min_cross\n",
      "  ✓ vwap_15min_cross\n",
      "  ✓ vwap_30min_cross\n",
      "  ✓ vwap_1min_signal\n",
      "  ✓ vwap_5min_signal\n",
      "  ✓ vwap_15min_signal\n",
      "  ✓ vwap_30min_signal\n",
      "  ✓ vwap_1min_trend\n",
      "  ✓ vwap_5min_trend\n",
      "  ✓ vwap_15min_trend\n",
      "  ✓ vwap_30min_trend\n",
      "  ✓ vwap_signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3292836047.py:24: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['vwap_1min'] = (df_temp['price'] * df_temp['qty']).rolling(window='1T', min_periods=1).sum() / df_temp['qty'].rolling(window='1T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3292836047.py:26: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['vwap_5min'] = (df_temp['price'] * df_temp['qty']).rolling(window='5T', min_periods=1).sum() / df_temp['qty'].rolling(window='5T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3292836047.py:28: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['vwap_15min'] = (df_temp['price'] * df_temp['qty']).rolling(window='15T', min_periods=1).sum() / df_temp['qty'].rolling(window='15T', min_periods=1).sum()\n",
      "C:\\Users\\dindo\\AppData\\Local\\Temp\\ipykernel_484\\3292836047.py:30: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_temp['vwap_30min'] = (df_temp['price'] * df_temp['qty']).rolling(window='30T', min_periods=1).sum() / df_temp['qty'].rolling(window='30T', min_periods=1).sum()\n"
     ]
    }
   ],
   "source": [
    "# Compute VWAP (Volume Weighted Average Price)\n",
    "print(\"=== VWAP CALCULATION ===\")\n",
    "\n",
    "# Calculate VWAP for the entire dataset\n",
    "print(\"Calculating VWAP...\")\n",
    "\n",
    "# Method 1: Simple VWAP for entire dataset\n",
    "total_volume = df['qty'].sum()\n",
    "total_price_volume = (df['price'] * df['qty']).sum()\n",
    "vwap_total = total_price_volume / total_volume\n",
    "\n",
    "print(f\"=== OVERALL VWAP ===\")\n",
    "print(f\"Total volume: {total_volume:,}\")\n",
    "print(f\"Total price × volume: ₹{total_price_volume:,.2f}\")\n",
    "print(f\"Overall VWAP: ₹{vwap_total:.2f}\")\n",
    "\n",
    "# Method 2: Rolling VWAP over different time windows\n",
    "print(f\"\\n=== ROLLING VWAP CALCULATION ===\")\n",
    "\n",
    "# Ensure datetime index for time-based rolling\n",
    "df_temp = df.set_index('date')\n",
    "\n",
    "# Calculate rolling VWAP for different time windows\n",
    "df_temp['vwap_1min'] = (df_temp['price'] * df_temp['qty']).rolling(window='1T', min_periods=1).sum() / df_temp['qty'].rolling(window='1T', min_periods=1).sum()\n",
    "\n",
    "df_temp['vwap_5min'] = (df_temp['price'] * df_temp['qty']).rolling(window='5T', min_periods=1).sum() / df_temp['qty'].rolling(window='5T', min_periods=1).sum()\n",
    "\n",
    "df_temp['vwap_15min'] = (df_temp['price'] * df_temp['qty']).rolling(window='15T', min_periods=1).sum() / df_temp['qty'].rolling(window='15T', min_periods=1).sum()\n",
    "\n",
    "df_temp['vwap_30min'] = (df_temp['price'] * df_temp['qty']).rolling(window='30T', min_periods=1).sum() / df_temp['qty'].rolling(window='30T', min_periods=1).sum()\n",
    "\n",
    "# Reset index\n",
    "df = df_temp.reset_index()\n",
    "\n",
    "# Display sample data with VWAP values\n",
    "print(\"=== SAMPLE DATA WITH VWAP VALUES ===\")\n",
    "print(df[['date', 'price', 'qty', 'vwap_1min', 'vwap_5min', 'vwap_15min', 'vwap_30min']].head(15))\n",
    "\n",
    "# VWAP Statistics\n",
    "print(f\"\\n=== VWAP STATISTICS ===\")\n",
    "vwap_cols = ['vwap_1min', 'vwap_5min', 'vwap_15min', 'vwap_30min']\n",
    "\n",
    "for col in vwap_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: ₹{df[col].min():.2f}\")\n",
    "    print(f\"  Max: ₹{df[col].min():.2f}\")\n",
    "    print(f\"  Mean: ₹{df[col].mean():.2f}\")\n",
    "    print(f\"  Std: ₹{df[col].std():.2f}\")\n",
    "\n",
    "# Price vs VWAP Analysis\n",
    "print(f\"\\n=== PRICE VS VWAP ANALYSIS ===\")\n",
    "\n",
    "# Calculate price position relative to each VWAP\n",
    "df['price_vs_vwap_1min'] = df['price'] - df['vwap_1min']\n",
    "df['price_vs_vwap_5min'] = df['price'] - df['vwap_5min']\n",
    "df['price_vs_vwap_15min'] = df['price'] - df['vwap_15min']\n",
    "df['price_vs_vwap_30min'] = df['price'] - df['vwap_30min']\n",
    "\n",
    "# Count how many times price is above/below each VWAP\n",
    "print(\"Price position relative to VWAP:\")\n",
    "for i, vwap_type in enumerate(['1min', '5min', '15min', '30min']):\n",
    "    col = f'price_vs_vwap_{vwap_type}'\n",
    "    above_count = (df[col] > 0).sum()\n",
    "    below_count = (df[col] < 0).sum()\n",
    "    equal_count = (df[col] == 0).sum()\n",
    "    \n",
    "    print(f\"\\n  {vwap_type} VWAP:\")\n",
    "    print(f\"    Above: {above_count:,} times ({(above_count/len(df)*100):.1f}%)\")\n",
    "    print(f\"    Below: {below_count:,} times ({(below_count/len(df)*100):.1f}%)\")\n",
    "    print(f\"    Equal: {equal_count:,} times ({(equal_count/len(df)*100):.1f}%)\")\n",
    "\n",
    "# VWAP as Support/Resistance\n",
    "print(f\"\\n=== VWAP AS SUPPORT/RESISTANCE ===\")\n",
    "\n",
    "# Find periods when price bounces off VWAP\n",
    "for i, vwap_type in enumerate(['1min', '5min', '15min', '30min']):\n",
    "    vwap_col = f'vwap_{vwap_type}'\n",
    "    price_vs_col = f'price_vs_vwap_{vwap_type}'\n",
    "    \n",
    "    # Find when price is very close to VWAP (within 0.1%)\n",
    "    close_to_vwap = (abs(df[price_vs_col]) / df[vwap_col] * 100) < 0.1\n",
    "    close_count = close_to_vwap.sum()\n",
    "    \n",
    "    print(f\"{vwap_type} VWAP: {close_count:,} times price within 0.1% of VWAP\")\n",
    "\n",
    "# VWAP Crossover Analysis\n",
    "print(f\"\\n=== VWAP CROSSOVER ANALYSIS ===\")\n",
    "\n",
    "# Price crossing above/below VWAP\n",
    "for i, vwap_type in enumerate(['1min', '5min', '15min', '30min']):\n",
    "    price_vs_col = f'price_vs_vwap_{vwap_type}'\n",
    "    \n",
    "    # Create crossover signals\n",
    "    df[f'above_vwap_{vwap_type}'] = df[price_vs_col] > 0\n",
    "    df[f'vwap_{vwap_type}_cross'] = df[f'above_vwap_{vwap_type}'].astype(int)\n",
    "    df[f'vwap_{vwap_type}_signal'] = df[f'vwap_{vwap_type}_cross'].diff()\n",
    "    \n",
    "    # Count crossovers\n",
    "    bullish_crosses = (df[f'vwap_{vwap_type}_signal'] == 1).sum()\n",
    "    bearish_crosses = (df[f'vwap_{vwap_type}_signal'] == -1).sum()\n",
    "    \n",
    "    print(f\"{vwap_type} VWAP crossovers:\")\n",
    "    print(f\"  Bullish (price crosses above): {bullish_crosses}\")\n",
    "    print(f\"  Bearish (price crosses below): {bearish_crosses}\")\n",
    "\n",
    "# VWAP Trend Analysis\n",
    "print(f\"\\n=== VWAP TREND ANALYSIS ===\")\n",
    "\n",
    "# Calculate VWAP trends (slopes)\n",
    "df['vwap_1min_trend'] = df['vwap_1min'].diff()\n",
    "df['vwap_5min_trend'] = df['vwap_5min'].diff()\n",
    "df['vwap_15min_trend'] = df['vwap_15min'].diff()\n",
    "df['vwap_30min_trend'] = df['vwap_30min'].diff()\n",
    "\n",
    "# Count trending periods\n",
    "for i, vwap_type in enumerate(['1min', '5min', '15min', '30min']):\n",
    "    trend_col = f'vwap_{vwap_type}_trend'\n",
    "    up_trend = (df[trend_col] > 0).sum()\n",
    "    down_trend = (df[trend_col] < 0).sum()\n",
    "    \n",
    "    print(f\"{vwap_type} VWAP trends:\")\n",
    "    print(f\"  Upward: {up_trend:,} periods\")\n",
    "    print(f\"  Downward: {down_trend:,} periods\")\n",
    "\n",
    "# VWAP vs Simple Moving Average Comparison\n",
    "print(f\"\\n=== VWAP VS SIMPLE MOVING AVERAGE ===\")\n",
    "\n",
    "# Compare VWAP with price averages\n",
    "print(\"VWAP vs Simple Price Average:\")\n",
    "print(f\"  Overall VWAP: ₹{vwap_total:.2f}\")\n",
    "print(f\"  Simple Price Average: ₹{df['price'].mean():.2f}\")\n",
    "print(f\"  Difference: ₹{vwap_total - df['price'].mean():.2f}\")\n",
    "\n",
    "# Show correlation between VWAP and price\n",
    "for col in vwap_cols:\n",
    "    correlation = df[col].corr(df['price'])\n",
    "    print(f\"  {col} vs Price correlation: {correlation:.4f}\")\n",
    "\n",
    "# Trading Signals based on VWAP\n",
    "print(f\"\\n=== VWAP TRADING SIGNALS ===\")\n",
    "\n",
    "# Generate basic trading signals\n",
    "df['vwap_signal'] = 'Hold'\n",
    "df.loc[df['price'] > df['vwap_15min'], 'vwap_signal'] = 'Buy'\n",
    "df.loc[df['price'] < df['vwap_15min'], 'vwap_signal'] = 'Sell'\n",
    "\n",
    "signal_counts = df['vwap_signal'].value_counts()\n",
    "print(\"VWAP-based trading signals (using 15-min VWAP):\")\n",
    "for signal, count in signal_counts.items():\n",
    "    print(f\"  {signal}: {count:,} times ({(count/len(df)*100):.1f}%)\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== VWAP SUMMARY ===\")\n",
    "print(f\"✓ Overall VWAP: ₹{vwap_total:.2f}\")\n",
    "print(f\"✓ Rolling VWAP calculated for 1min, 5min, 15min, 30min windows\")\n",
    "print(f\"✓ Price vs VWAP analysis completed\")\n",
    "print(f\"✓ VWAP crossover signals generated\")\n",
    "print(f\"✓ VWAP trend analysis completed\")\n",
    "print(f\"✓ Trading signals based on VWAP generated\")\n",
    "print(f\"✓ Ready for VWAP-based trading strategies\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(f\"\\n=== UPDATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"New VWAP columns added:\")\n",
    "vwap_new_cols = ['vwap_1min', 'vwap_5min', 'vwap_15min', 'vwap_30min',\n",
    "                  'price_vs_vwap_1min', 'price_vs_vwap_5min', 'price_vs_vwap_15min', 'price_vs_vwap_30min',\n",
    "                  'above_vwap_1min', 'above_vwap_5min', 'above_vwap_15min', 'above_vwap_30min',\n",
    "                  'vwap_1min_cross', 'vwap_5min_cross', 'vwap_15min_cross', 'vwap_30min_cross',\n",
    "                  'vwap_1min_signal', 'vwap_5min_signal', 'vwap_15min_signal', 'vwap_30min_signal',\n",
    "                  'vwap_1min_trend', 'vwap_5min_trend', 'vwap_15min_trend', 'vwap_30min_trend',\n",
    "                  'vwap_signal']\n",
    "for col in vwap_new_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  ✓ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a5adb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MINUTE-BY-MINUTE TRADE AGGREGATION ===\n",
      "Aggregating trades by minute...\n",
      "Original aggregation columns: [('price', 'mean'), ('price', 'min'), ('price', 'max'), ('price', 'first'), ('price', 'last'), ('qty', 'sum'), ('qty', 'count'), ('trnvr', 'sum')]\n",
      "Column levels: 2\n",
      "=== MINUTE-BY-MINUTE AGGREGATED DATA ===\n",
      "Total minutes with trades: 375\n",
      "Time range: 2025-08-07 09:15:00 to 2025-08-07 15:29:00\n",
      "\n",
      "=== FIRST 15 MINUTES ===\n",
      "             minute  avg_price  min_price  max_price  open_price  close_price  total_qty  trade_count  total_trnvr\n",
      "2025-08-07 09:15:00     386.24     385.70     386.95      386.85       386.00     240694          116  93007031.40\n",
      "2025-08-07 09:16:00     387.07     385.60     387.75      386.00       387.60     176938           94  68447339.50\n",
      "2025-08-07 09:17:00     388.06     387.55     388.55      387.60       388.55     109071           15  42309419.75\n",
      "2025-08-07 09:18:00     389.00     388.45     389.45      388.85       389.00     140751           14  54755417.20\n",
      "2025-08-07 09:19:00     389.09     388.80     389.25      388.95       389.10      84336           96  32813758.65\n",
      "2025-08-07 09:20:00     389.14     388.90     389.85      389.05       389.85     181112           13  70514549.40\n",
      "2025-08-07 09:21:00     389.57     389.35     390.05      389.65       390.05     118951           94  46347599.65\n",
      "2025-08-07 09:22:00     389.89     389.50     390.20      390.00       389.60      61831          105  24107901.00\n",
      "2025-08-07 09:23:00     389.56     389.10     389.85      389.80       389.15      47476           14  18486095.00\n",
      "2025-08-07 09:24:00     388.79     388.60     389.00      389.00       388.65      36466           15  14179668.45\n",
      "2025-08-07 09:25:00     388.73     388.55     388.95      388.95       388.55      48755           14  18956429.90\n",
      "2025-08-07 09:26:00     388.82     388.55     389.10      388.55       389.10      61235           12  23813078.30\n",
      "2025-08-07 09:27:00     388.89     388.75     389.10      389.10       388.75      28115           12  10933185.80\n",
      "2025-08-07 09:28:00     388.73     388.60     388.85      388.75       388.75      35201           14  13684971.50\n",
      "2025-08-07 09:29:00     388.67     388.35     389.00      389.00       388.65      50899           13  19778802.05\n",
      "\n",
      "=== LAST 15 MINUTES ===\n",
      "             minute  avg_price  min_price  max_price  open_price  close_price  total_qty  trade_count  total_trnvr\n",
      "2025-08-07 15:15:00     387.65     387.60     387.70      387.65       387.65      37128           14  14392381.10\n",
      "2025-08-07 15:16:00     387.59     387.40     387.70      387.65       387.55      62291           14  24142605.80\n",
      "2025-08-07 15:17:00     387.84     387.60     388.05      387.65       387.95      97099           94  37662171.75\n",
      "2025-08-07 15:18:00     387.98     387.85     388.15      388.00       387.95      53970           93  20939667.55\n",
      "2025-08-07 15:19:00     387.86     387.75     387.95      387.95       387.80      39053           62  15146003.50\n",
      "2025-08-07 15:20:00     387.93     387.75     388.10      387.80       388.10      79031           12  30656893.05\n",
      "2025-08-07 15:21:00     388.16     388.00     388.45      388.10       388.40      74877           92  29068703.85\n",
      "2025-08-07 15:22:00     388.59     388.30     388.75      388.45       388.50      48699           90  18924501.55\n",
      "2025-08-07 15:23:00     388.51     388.40     388.60      388.40       388.55      31765           98  12340817.95\n",
      "2025-08-07 15:24:00     388.47     388.30     388.55      388.50       388.45      39660           91  15407011.65\n",
      "2025-08-07 15:25:00     388.40     388.25     388.50      388.40       388.50      44664           92  17349093.45\n",
      "2025-08-07 15:26:00     388.50     388.35     388.65      388.45       388.45      44340           96  17225461.25\n",
      "2025-08-07 15:27:00     388.38     388.20     388.55      388.55       388.25      48761           89  18936710.55\n",
      "2025-08-07 15:28:00     388.28     388.25     388.30      388.30       388.30      74245           17  28827043.95\n",
      "2025-08-07 15:29:00     388.19     387.90     388.30      388.25       388.25      47555           17  18457526.00\n",
      "\n",
      "=== AGGREGATED DATA STATISTICS ===\n",
      "Price Statistics:\n",
      "  Average price range: ₹383.55 - ₹389.89\n",
      "  Overall average price: ₹386.58\n",
      "  Price volatility (std): ₹1.61\n",
      "\n",
      "Volume Statistics:\n",
      "  Total volume across all minutes: 11,510,171\n",
      "  Average volume per minute: 30,694\n",
      "  Highest volume minute: 240,694\n",
      "  Lowest volume minute: 3,927\n",
      "\n",
      "Turnover Statistics:\n",
      "  Total turnover across all minutes: ₹4,451,969,111.70\n",
      "  Average turnover per minute: ₹11,871,917.63\n",
      "  Highest turnover minute: ₹93,007,031.40\n",
      "  Lowest turnover minute: ₹1,521,495.85\n",
      "\n",
      "Trade Count Statistics:\n",
      "  Total trades across all minutes: 10,956\n",
      "  Average trades per minute: 29.2\n",
      "  Busiest minute: 116 trades\n",
      "  Quietest minute: 9 trades\n",
      "\n",
      "=== MINUTE-BY-MINUTE ANALYSIS ===\n",
      "Highest volume minute:\n",
      "  Time: 2025-08-07 09:15:00\n",
      "  Volume: 240,694\n",
      "  Turnover: ₹93,007,031.40\n",
      "  Avg Price: ₹386.24\n",
      "  Trades: 116\n",
      "\n",
      "Lowest volume minute:\n",
      "  Time: 2025-08-07 11:21:00\n",
      "  Volume: 3,927\n",
      "  Turnover: ₹1,521,495.85\n",
      "  Avg Price: ₹387.43\n",
      "  Trades: 15\n",
      "\n",
      "Highest turnover minute:\n",
      "  Time: 2025-08-07 09:15:00\n",
      "  Turnover: ₹93,007,031.40\n",
      "  Volume: 240,694\n",
      "  Avg Price: ₹386.24\n",
      "\n",
      "=== TIME-BASED PATTERNS ===\n",
      "Total volume by hour:\n",
      "  09:00 - 09:59: 2,164,111\n",
      "  10:00 - 10:59: 1,436,774\n",
      "  11:00 - 11:59: 1,340,606\n",
      "  12:00 - 12:59: 1,462,840\n",
      "  13:00 - 13:59: 1,428,015\n",
      "  14:00 - 14:59: 1,985,212\n",
      "  15:00 - 15:59: 1,692,613\n",
      "\n",
      "Total turnover by hour:\n",
      "  09:00 - 09:59: ₹840,800,983.15\n",
      "  10:00 - 10:59: ₹557,748,903.30\n",
      "  11:00 - 11:59: ₹518,188,746.40\n",
      "  12:00 - 12:59: ₹563,482,164.95\n",
      "  13:00 - 13:59: ₹548,979,275.10\n",
      "  14:00 - 14:59: ₹766,416,677.25\n",
      "  15:00 - 15:59: ₹656,352,361.55\n",
      "\n",
      "=== PRICE MOVEMENT ANALYSIS PER MINUTE ===\n",
      "Minute-to-minute price changes:\n",
      "  Average change: ₹-0.00\n",
      "  Average change %: -0.00%\n",
      "  Largest increase: ₹1.60\n",
      "  Largest decrease: ₹-0.85\n",
      "\n",
      "=== VOLUME-WEIGHTED ANALYSIS ===\n",
      "VWAP vs Average Price analysis:\n",
      "  Average difference: ₹0.00\n",
      "  Max difference: ₹0.31\n",
      "  Min difference: ₹-0.24\n",
      "\n",
      "=== TRADING INTENSITY ANALYSIS ===\n",
      "Volume per trade analysis:\n",
      "  Average volume per trade: 1,385\n",
      "  Highest volume per trade: 13,932\n",
      "  Lowest volume per trade: 104\n",
      "\n",
      "================================================================================\n",
      "=== SUMMARY TABLE ===\n",
      "          Metric             Value\n",
      "   Total Minutes               375\n",
      "    Total Volume        11,510,171\n",
      "  Total Turnover ₹4,451,969,111.70\n",
      "    Total Trades            10,956\n",
      "       Avg Price           ₹386.58\n",
      "  Avg Volume/Min            30,694\n",
      "Avg Turnover/Min    ₹11,871,917.63\n",
      "\n",
      "=== DATA EXPORT ===\n",
      "✓ Minute-by-minute aggregation completed\n",
      "✓ 375 minutes of aggregated data\n",
      "✓ Ready for time-series analysis and visualization\n",
      "✓ Data can be exported to CSV for further analysis\n",
      "\n",
      "=== AGGREGATED DATAFRAME INFO ===\n",
      "Columns: ['minute', 'avg_price', 'min_price', 'max_price', 'open_price', 'close_price', 'total_qty', 'trade_count', 'total_trnvr', 'hour', 'price_change', 'price_change_pct', 'minute_vwap', 'vwap_vs_avg_diff', 'volume_per_trade']\n",
      "Shape: (375, 15)\n",
      "Data types:\n",
      "minute              datetime64[ns]\n",
      "avg_price                  float64\n",
      "min_price                  float64\n",
      "max_price                  float64\n",
      "open_price                 float64\n",
      "close_price                float64\n",
      "total_qty                    int64\n",
      "trade_count                  int64\n",
      "total_trnvr                float64\n",
      "hour                         int32\n",
      "price_change               float64\n",
      "price_change_pct           float64\n",
      "minute_vwap                float64\n",
      "vwap_vs_avg_diff           float64\n",
      "volume_per_trade           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Aggregate trades per minute: avg price, total qty, total trnvr\n",
    "print(\"=== MINUTE-BY-MINUTE TRADE AGGREGATION ===\")\n",
    "\n",
    "# Create minute-level aggregation\n",
    "print(\"Aggregating trades by minute...\")\n",
    "\n",
    "# Extract minute from datetime for grouping (using 'min' instead of 'T')\n",
    "df['minute_key'] = df['date'].dt.floor('1min')  # Floor to nearest minute\n",
    "\n",
    "# Group by minute and aggregate\n",
    "minute_agg = df.groupby('minute_key').agg({\n",
    "    'price': ['mean', 'min', 'max', 'first', 'last'],  # Price statistics\n",
    "    'qty': ['sum', 'count'],                           # Total quantity and trade count\n",
    "    'trnvr': 'sum'                                     # Total turnover\n",
    "}).round(2)\n",
    "\n",
    "# Check the actual column structure before flattening\n",
    "print(f\"Original aggregation columns: {minute_agg.columns.tolist()}\")\n",
    "print(f\"Column levels: {minute_agg.columns.nlevels}\")\n",
    "\n",
    "# Flatten column names correctly\n",
    "minute_agg.columns = ['avg_price', 'min_price', 'max_price', 'open_price', 'close_price', \n",
    "                      'total_qty', 'trade_count', 'total_trnvr']\n",
    "\n",
    "# Reset index to make minute_key a column\n",
    "minute_agg = minute_agg.reset_index()\n",
    "minute_agg.rename(columns={'minute_key': 'minute'}, inplace=True)\n",
    "\n",
    "# Display the aggregated data\n",
    "print(\"=== MINUTE-BY-MINUTE AGGREGATED DATA ===\")\n",
    "print(f\"Total minutes with trades: {len(minute_agg)}\")\n",
    "print(f\"Time range: {minute_agg['minute'].min()} to {minute_agg['minute'].max()}\")\n",
    "\n",
    "# Show first 15 rows\n",
    "print(f\"\\n=== FIRST 15 MINUTES ===\")\n",
    "print(minute_agg.head(15).to_string(index=False))\n",
    "\n",
    "# Show last 15 rows\n",
    "print(f\"\\n=== LAST 15 MINUTES ===\")\n",
    "print(minute_agg.tail(15).to_string(index=False))\n",
    "\n",
    "# Basic statistics of aggregated data\n",
    "print(f\"\\n=== AGGREGATED DATA STATISTICS ===\")\n",
    "print(\"Price Statistics:\")\n",
    "print(f\"  Average price range: ₹{minute_agg['avg_price'].min():.2f} - ₹{minute_agg['avg_price'].max():.2f}\")\n",
    "print(f\"  Overall average price: ₹{minute_agg['avg_price'].mean():.2f}\")\n",
    "print(f\"  Price volatility (std): ₹{minute_agg['avg_price'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nVolume Statistics:\")\n",
    "print(f\"  Total volume across all minutes: {minute_agg['total_qty'].sum():,}\")\n",
    "print(f\"  Average volume per minute: {minute_agg['total_qty'].mean():,.0f}\")\n",
    "print(f\"  Highest volume minute: {minute_agg['total_qty'].max():,}\")\n",
    "print(f\"  Lowest volume minute: {minute_agg['total_qty'].min():,}\")\n",
    "\n",
    "print(f\"\\nTurnover Statistics:\")\n",
    "print(f\"  Total turnover across all minutes: ₹{minute_agg['total_trnvr'].sum():,.2f}\")\n",
    "print(f\"  Average turnover per minute: ₹{minute_agg['total_trnvr'].mean():,.2f}\")\n",
    "print(f\"  Highest turnover minute: ₹{minute_agg['total_trnvr'].max():,.2f}\")\n",
    "print(f\"  Lowest turnover minute: ₹{minute_agg['total_trnvr'].min():,.2f}\")\n",
    "\n",
    "print(f\"\\nTrade Count Statistics:\")\n",
    "print(f\"  Total trades across all minutes: {minute_agg['trade_count'].sum():,}\")\n",
    "print(f\"  Average trades per minute: {minute_agg['trade_count'].mean():.1f}\")\n",
    "print(f\"  Busiest minute: {minute_agg['trade_count'].max():,} trades\")\n",
    "print(f\"  Quietest minute: {minute_agg['trade_count'].min():,} trades\")\n",
    "\n",
    "# Minute-by-minute analysis\n",
    "print(f\"\\n=== MINUTE-BY-MINUTE ANALYSIS ===\")\n",
    "\n",
    "# Find highest and lowest volume minutes\n",
    "highest_volume_minute = minute_agg.loc[minute_agg['total_qty'].idxmax()]\n",
    "lowest_volume_minute = minute_agg.loc[minute_agg['total_qty'].idxmin()]\n",
    "\n",
    "print(\"Highest volume minute:\")\n",
    "print(f\"  Time: {highest_volume_minute['minute']}\")\n",
    "print(f\"  Volume: {highest_volume_minute['total_qty']:,}\")\n",
    "print(f\"  Turnover: ₹{highest_volume_minute['total_trnvr']:,.2f}\")\n",
    "print(f\"  Avg Price: ₹{highest_volume_minute['avg_price']:.2f}\")\n",
    "print(f\"  Trades: {highest_volume_minute['trade_count']}\")\n",
    "\n",
    "print(f\"\\nLowest volume minute:\")\n",
    "print(f\"  Time: {lowest_volume_minute['minute']}\")\n",
    "print(f\"  Volume: {lowest_volume_minute['total_qty']:,}\")\n",
    "print(f\"  Turnover: ₹{lowest_volume_minute['total_trnvr']:,.2f}\")\n",
    "print(f\"  Avg Price: ₹{lowest_volume_minute['avg_price']:.2f}\")\n",
    "print(f\"  Trades: {lowest_volume_minute['trade_count']}\")\n",
    "\n",
    "# Find highest and lowest turnover minutes\n",
    "highest_turnover_minute = minute_agg.loc[minute_agg['total_trnvr'].idxmax()]\n",
    "lowest_turnover_minute = minute_agg.loc[minute_agg['total_trnvr'].idxmin()]\n",
    "\n",
    "print(f\"\\nHighest turnover minute:\")\n",
    "print(f\"  Time: {highest_turnover_minute['minute']}\")\n",
    "print(f\"  Turnover: ₹{highest_turnover_minute['total_trnvr']:,.2f}\")\n",
    "print(f\"  Volume: {highest_turnover_minute['total_qty']:,}\")\n",
    "print(f\"  Avg Price: ₹{highest_turnover_minute['avg_price']:.2f}\")\n",
    "\n",
    "# Time-based patterns\n",
    "print(f\"\\n=== TIME-BASED PATTERNS ===\")\n",
    "\n",
    "# Add hour column for hourly analysis\n",
    "minute_agg['hour'] = minute_agg['minute'].dt.hour\n",
    "\n",
    "# Hourly volume analysis\n",
    "hourly_volume = minute_agg.groupby('hour')['total_qty'].sum()\n",
    "print(\"Total volume by hour:\")\n",
    "for hour, volume in hourly_volume.items():\n",
    "    print(f\"  {hour:02d}:00 - {hour:02d}:59: {volume:,}\")\n",
    "\n",
    "# Hourly turnover analysis\n",
    "hourly_turnover = minute_agg.groupby('hour')['total_trnvr'].sum()\n",
    "print(f\"\\nTotal turnover by hour:\")\n",
    "for hour, turnover in hourly_turnover.items():\n",
    "    print(f\"  {hour:02d}:00 - {hour:02d}:59: ₹{turnover:,.2f}\")\n",
    "\n",
    "# Price movement analysis per minute\n",
    "print(f\"\\n=== PRICE MOVEMENT ANALYSIS PER MINUTE ===\")\n",
    "\n",
    "# Calculate minute-to-minute price changes\n",
    "minute_agg['price_change'] = minute_agg['close_price'] - minute_agg['open_price']\n",
    "minute_agg['price_change_pct'] = (minute_agg['price_change'] / minute_agg['open_price']) * 100\n",
    "\n",
    "# Price change statistics\n",
    "print(f\"Minute-to-minute price changes:\")\n",
    "print(f\"  Average change: ₹{minute_agg['price_change'].mean():.2f}\")\n",
    "print(f\"  Average change %: {minute_agg['price_change_pct'].mean():.2f}%\")\n",
    "print(f\"  Largest increase: ₹{minute_agg['price_change'].max():.2f}\")\n",
    "print(f\"  Largest decrease: ₹{minute_agg['price_change'].min():.2f}\")\n",
    "\n",
    "# Volume-weighted price analysis\n",
    "print(f\"\\n=== VOLUME-WEIGHTED ANALYSIS ===\")\n",
    "\n",
    "# Calculate VWAP for each minute\n",
    "minute_agg['minute_vwap'] = minute_agg['total_trnvr'] / minute_agg['total_qty']\n",
    "\n",
    "# Compare VWAP with average price\n",
    "minute_agg['vwap_vs_avg_diff'] = minute_agg['minute_vwap'] - minute_agg['avg_price']\n",
    "print(f\"VWAP vs Average Price analysis:\")\n",
    "print(f\"  Average difference: ₹{minute_agg['vwap_vs_avg_diff'].mean():.2f}\")\n",
    "print(f\"  Max difference: ₹{minute_agg['vwap_vs_avg_diff'].max():.2f}\")\n",
    "print(f\"  Min difference: ₹{minute_agg['vwap_vs_avg_diff'].min():.2f}\")\n",
    "\n",
    "# Trading intensity analysis\n",
    "print(f\"\\n=== TRADING INTENSITY ANALYSIS ===\")\n",
    "\n",
    "# Calculate volume per trade for each minute\n",
    "minute_agg['volume_per_trade'] = minute_agg['total_qty'] / minute_agg['trade_count']\n",
    "\n",
    "print(f\"Volume per trade analysis:\")\n",
    "print(f\"  Average volume per trade: {minute_agg['volume_per_trade'].mean():,.0f}\")\n",
    "print(f\"  Highest volume per trade: {minute_agg['volume_per_trade'].max():,.0f}\")\n",
    "print(f\"  Lowest volume per trade: {minute_agg['volume_per_trade'].min():,.0f}\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"=== SUMMARY TABLE ===\")\n",
    "summary_data = {\n",
    "    'Metric': ['Total Minutes', 'Total Volume', 'Total Turnover', 'Total Trades', 'Avg Price', 'Avg Volume/Min', 'Avg Turnover/Min'],\n",
    "    'Value': [\n",
    "        f\"{len(minute_agg):,}\",\n",
    "        f\"{minute_agg['total_qty'].sum():,}\",\n",
    "        f\"₹{minute_agg['total_trnvr'].sum():,.2f}\",\n",
    "        f\"{minute_agg['trade_count'].sum():,}\",\n",
    "        f\"₹{minute_agg['avg_price'].mean():.2f}\",\n",
    "        f\"{minute_agg['total_qty'].mean():,.0f}\",\n",
    "        f\"₹{minute_agg['total_trnvr'].mean():,.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save aggregated data\n",
    "print(f\"\\n=== DATA EXPORT ===\")\n",
    "print(f\"✓ Minute-by-minute aggregation completed\")\n",
    "print(f\"✓ {len(minute_agg)} minutes of aggregated data\")\n",
    "print(f\"✓ Ready for time-series analysis and visualization\")\n",
    "print(f\"✓ Data can be exported to CSV for further analysis\")\n",
    "\n",
    "# Display final aggregated dataframe info\n",
    "print(f\"\\n=== AGGREGATED DATAFRAME INFO ===\")\n",
    "print(f\"Columns: {list(minute_agg.columns)}\")\n",
    "print(f\"Shape: {minute_agg.shape}\")\n",
    "print(f\"Data types:\")\n",
    "print(minute_agg.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70e3d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HOURLY AGGREGATION ANALYSIS ===\n",
      "Aggregating data by hour...\n",
      "\n",
      "=== HOURLY AGGREGATION RESULTS ===\n",
      "Shape: (7, 14)\n",
      "   hour  avg_price  min_price  max_price  price_std  open_price  close_price  \\\n",
      "0     9     388.60     385.60     390.20       1.13      386.85       388.30   \n",
      "1    10     388.23     387.45     389.25       0.39      388.10       388.10   \n",
      "2    11     386.51     385.25     388.05       0.65      388.00       385.55   \n",
      "3    12     385.22     384.40     386.50       0.44      385.70       385.40   \n",
      "4    13     384.43     383.50     385.60       0.49      385.55       384.75   \n",
      "5    14     385.97     384.70     387.10       0.63      384.70       387.05   \n",
      "6    15     387.92     387.00     388.75       0.46      387.35       388.25   \n",
      "\n",
      "   total_qty  trade_count   total_trnvr  avg_price_change  price_change_std  \\\n",
      "0    2164111         1047  8.408010e+08               0.0              0.12   \n",
      "1    1436774         1476  5.577489e+08              -0.0              0.09   \n",
      "2    1340606         1653  5.181887e+08              -0.0              0.09   \n",
      "3    1462840         1807  5.634822e+08              -0.0              0.08   \n",
      "4    1428015         1679  5.489793e+08              -0.0              0.07   \n",
      "5    1985212         1521  7.664167e+08               0.0              0.08   \n",
      "6    1692613         1773  6.563524e+08               0.0              0.06   \n",
      "\n",
      "   min_price_change  max_price_change  \n",
      "0             -0.65              0.75  \n",
      "1             -0.35              0.45  \n",
      "2             -0.35              0.35  \n",
      "3             -0.30              0.30  \n",
      "4             -0.45              0.40  \n",
      "5             -0.45              0.50  \n",
      "6             -0.40              0.30  \n",
      "\n",
      "=== VOLUME ANALYSIS BY HOUR ===\n",
      "Highest volume hour:\n",
      "  Hour: 09:00 - 09:59\n",
      "  Volume: 2,164,111.0\n",
      "  Turnover: ₹840,800,983.15\n",
      "  Average price: ₹388.60\n",
      "\n",
      "Lowest volume hour:\n",
      "  Hour: 11:00 - 11:59\n",
      "  Volume: 1,340,606.0\n",
      "  Turnover: ₹518,188,746.40\n",
      "  Average price: ₹386.51\n",
      "\n",
      "=== VOLATILITY ANALYSIS BY HOUR ===\n",
      "Highest volatility hour: 09:00\n",
      "  Price standard deviation: ₹1.13\n",
      "  Price range: ₹385.60 - ₹390.20\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total trading hours: 7\n",
      "Average hourly volume: 1,644,310\n",
      "Average hourly turnover: ₹635,995,587.39\n",
      "Average hourly price volatility: ₹0.60\n"
     ]
    }
   ],
   "source": [
    "# Aggregate per hour: price volatility, volume, turnover\n",
    "print(\"=== HOURLY AGGREGATION ANALYSIS ===\")\n",
    "\n",
    "# Create hourly aggregation\n",
    "print(\"Aggregating data by hour...\")\n",
    "\n",
    "# Extract hour from datetime for grouping\n",
    "df['hour_key'] = df['date'].dt.hour\n",
    "\n",
    "# Group by hour and aggregate\n",
    "hourly_agg = df.groupby('hour_key').agg({\n",
    "    'price': ['mean', 'min', 'max', 'std', 'first', 'last'],  # Price statistics including volatility\n",
    "    'qty': ['sum', 'count'],                                   # Total volume and trade count\n",
    "    'trnvr': 'sum',                                            # Total turnover\n",
    "    'price_change': ['mean', 'std', 'min', 'max']              # Price change statistics\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "hourly_agg.columns = [\n",
    "    'avg_price', 'min_price', 'max_price', 'price_std', 'open_price', 'close_price',\n",
    "    'total_qty', 'trade_count', 'total_trnvr',\n",
    "    'avg_price_change', 'price_change_std', 'min_price_change', 'max_price_change'\n",
    "]\n",
    "\n",
    "# Reset index to make hour_key a column\n",
    "hourly_agg = hourly_agg.reset_index()\n",
    "hourly_agg.rename(columns={'hour_key': 'hour'}, inplace=True)\n",
    "\n",
    "# Display the hourly aggregation\n",
    "print(f\"\\n=== HOURLY AGGREGATION RESULTS ===\")\n",
    "print(f\"Shape: {hourly_agg.shape}\")\n",
    "print(hourly_agg)\n",
    "\n",
    "# Find highest and lowest volume hours\n",
    "print(f\"\\n=== VOLUME ANALYSIS BY HOUR ===\")\n",
    "highest_volume_hour = hourly_agg.loc[hourly_agg['total_qty'].idxmax()]\n",
    "lowest_volume_hour = hourly_agg.loc[hourly_agg['total_qty'].idxmin()]\n",
    "\n",
    "print(\"Highest volume hour:\")\n",
    "print(f\"  Hour: {int(highest_volume_hour['hour']):02d}:00 - {int(highest_volume_hour['hour']):02d}:59\")\n",
    "print(f\"  Volume: {highest_volume_hour['total_qty']:,}\")\n",
    "print(f\"  Turnover: ₹{highest_volume_hour['total_trnvr']:,.2f}\")\n",
    "print(f\"  Average price: ₹{highest_volume_hour['avg_price']:.2f}\")\n",
    "\n",
    "print(\"\\nLowest volume hour:\")\n",
    "print(f\"  Hour: {int(lowest_volume_hour['hour']):02d}:00 - {int(lowest_volume_hour['hour']):02d}:59\")\n",
    "print(f\"  Volume: {lowest_volume_hour['total_qty']:,}\")\n",
    "print(f\"  Turnover: ₹{lowest_volume_hour['total_trnvr']:,.2f}\")\n",
    "print(f\"  Average price: ₹{lowest_volume_hour['avg_price']:.2f}\")\n",
    "\n",
    "# Volatility analysis by hour\n",
    "print(f\"\\n=== VOLATILITY ANALYSIS BY HOUR ===\")\n",
    "highest_volatility_hour = hourly_agg.loc[hourly_agg['price_std'].idxmax()]\n",
    "print(f\"Highest volatility hour: {int(highest_volatility_hour['hour']):02d}:00\")\n",
    "print(f\"  Price standard deviation: ₹{highest_volatility_hour['price_std']:.2f}\")\n",
    "print(f\"  Price range: ₹{highest_volatility_hour['min_price']:.2f} - ₹{highest_volatility_hour['max_price']:.2f}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Total trading hours: {len(hourly_agg)}\")\n",
    "print(f\"Average hourly volume: {hourly_agg['total_qty'].mean():,.0f}\")\n",
    "print(f\"Average hourly turnover: ₹{hourly_agg['total_trnvr'].mean():,.2f}\")\n",
    "print(f\"Average hourly price volatility: ₹{hourly_agg['price_std'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15b204f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADING SESSION OHLC ANALYSIS ===\n",
      "Aggregating data by trading session...\n",
      "=== SINGLE TRADING SESSION OHLC ===\n",
      "Date: 2025-08-07\n",
      "Open: ₹386.85\n",
      "High: ₹390.20\n",
      "Low: ₹383.50\n",
      "Close: ₹388.25\n",
      "Price Range: ₹6.70\n",
      "Total Volume: 11,510,171\n",
      "Total Turnover: ₹4,451,969,111.70\n",
      "Trade Count: 10,956\n",
      "Average Price: ₹386.56\n",
      "\n",
      "=== ADDITIONAL METRICS ===\n",
      "Price Change: ₹1.40\n",
      "Price Change %: 0.36%\n",
      "Session VWAP: ₹386.79\n",
      "\n",
      "=== COMPLETE SESSION DATA ===\n",
      "         date    open   high    low   close  total_volume  total_turnover  \\\n",
      "0  2025-08-07  386.85  390.2  383.5  388.25      11510171    4.451969e+09   \n",
      "\n",
      "   trade_count  price_range   avg_price  price_change  price_change_pct  \n",
      "0        10956          6.7  386.561094           1.4          0.361897  \n"
     ]
    }
   ],
   "source": [
    "# Aggregate per trading session: OHLC + total volume\n",
    "print(\"=== TRADING SESSION OHLC ANALYSIS ===\")\n",
    "\n",
    "# Create trading session aggregation (assuming single day data)\n",
    "print(\"Aggregating data by trading session...\")\n",
    "\n",
    "# For single day data, we can create session-level OHLC\n",
    "# If you have multiple days, you can group by date_only instead\n",
    "if len(df['date_only'].unique()) == 1:\n",
    "    # Single trading day - create session OHLC\n",
    "    session_ohlc = {\n",
    "        'date': df['date_only'].iloc[0],\n",
    "        'open': df['price'].iloc[0],           # First price of the day\n",
    "        'high': df['price'].max(),             # Highest price of the day\n",
    "        'low': df['price'].min(),              # Lowest price of the day\n",
    "        'close': df['price'].iloc[-1],         # Last price of the day\n",
    "        'total_volume': df['qty'].sum(),       # Total volume for the day\n",
    "        'total_turnover': df['trnvr'].sum(),   # Total turnover for the day\n",
    "        'trade_count': len(df),                # Total number of trades\n",
    "        'price_range': df['price'].max() - df['price'].min(),  # High - Low\n",
    "        'avg_price': df['price'].mean()        # Average price for the day\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame from the session data\n",
    "    session_df = pd.DataFrame([session_ohlc])\n",
    "    \n",
    "    print(f\"=== SINGLE TRADING SESSION OHLC ===\")\n",
    "    print(f\"Date: {session_df['date'].iloc[0]}\")\n",
    "    print(f\"Open: ₹{session_df['open'].iloc[0]:.2f}\")\n",
    "    print(f\"High: ₹{session_df['high'].iloc[0]:.2f}\")\n",
    "    print(f\"Low: ₹{session_df['low'].iloc[0]:.2f}\")\n",
    "    print(f\"Close: ₹{session_df['close'].iloc[0]:.2f}\")\n",
    "    print(f\"Price Range: ₹{session_df['price_range'].iloc[0]:.2f}\")\n",
    "    print(f\"Total Volume: {session_df['total_volume'].iloc[0]:,}\")\n",
    "    print(f\"Total Turnover: ₹{session_df['total_turnover'].iloc[0]:,.2f}\")\n",
    "    print(f\"Trade Count: {session_df['trade_count'].iloc[0]:,}\")\n",
    "    print(f\"Average Price: ₹{session_df['avg_price'].iloc[0]:.2f}\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    print(f\"\\n=== ADDITIONAL METRICS ===\")\n",
    "    session_df['price_change'] = session_df['close'] - session_df['open']\n",
    "    session_df['price_change_pct'] = (session_df['price_change'] / session_df['open']) * 100\n",
    "    \n",
    "    print(f\"Price Change: ₹{session_df['price_change'].iloc[0]:.2f}\")\n",
    "    print(f\"Price Change %: {session_df['price_change_pct'].iloc[0]:.2f}%\")\n",
    "    \n",
    "    # VWAP calculation for the session\n",
    "    vwap = (df['price'] * df['qty']).sum() / df['qty'].sum()\n",
    "    print(f\"Session VWAP: ₹{vwap:.2f}\")\n",
    "    \n",
    "    # Display the complete session DataFrame\n",
    "    print(f\"\\n=== COMPLETE SESSION DATA ===\")\n",
    "    print(session_df)\n",
    "    \n",
    "else:\n",
    "    # Multiple trading days - group by date\n",
    "    print(\"Multiple trading days detected, grouping by date...\")\n",
    "    \n",
    "    # Group by date and create OHLC for each day\n",
    "    daily_ohlc = df.groupby('date_only').agg({\n",
    "        'price': ['first', 'max', 'min', 'last'],  # OHLC\n",
    "        'qty': 'sum',                               # Total volume\n",
    "        'trnvr': 'sum',                             # Total turnover\n",
    "        'qty': 'count'                              # Trade count\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    daily_ohlc.columns = ['open', 'high', 'low', 'close', 'total_volume', 'total_turnover', 'trade_count']\n",
    "    \n",
    "    # Reset index\n",
    "    daily_ohlc = daily_ohlc.reset_index()\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    daily_ohlc['price_range'] = daily_ohlc['high'] - daily_ohlc['low']\n",
    "    daily_ohlc['price_change'] = daily_ohlc['close'] - daily_ohlc['open']\n",
    "    daily_ohlc['price_change_pct'] = (daily_ohlc['price_change'] / daily_ohlc['open']) * 100\n",
    "    \n",
    "    print(f\"\\n=== MULTI-DAY OHLC DATA ===\")\n",
    "    print(daily_ohlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "465a5193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRADE ACTIVITY DENSITY ANALYSIS ===\n",
      "Analyzing trade activity density across different time intervals...\n",
      "\n",
      "=== MINUTE-BY-MINUTE TRADE COUNT ===\n",
      "Total minutes with trades: 375\n",
      "Average trades per minute: 29.2\n",
      "Max trades in a minute: 116\n",
      "Min trades in a minute: 9\n",
      "\n",
      "=== TOP 10 MOST ACTIVE MINUTES ===\n",
      "09:15:00: 116 trades\n",
      "15:09:00: 108 trades\n",
      "09:22:00: 105 trades\n",
      "15:23:00: 98 trades\n",
      "09:19:00: 96 trades\n",
      "15:26:00: 96 trades\n",
      "09:16:00: 94 trades\n",
      "09:21:00: 94 trades\n",
      "15:17:00: 94 trades\n",
      "12:49:00: 93 trades\n",
      "\n",
      "=== 5-MINUTE INTERVAL TRADE COUNT ===\n",
      "Total 5-minute intervals: 75\n",
      "Average trades per 5-min: 146.1\n",
      "Max trades in 5-min: 383\n",
      "\n",
      "=== 15-MINUTE INTERVAL TRADE COUNT ===\n",
      "Total 15-minute intervals: 25\n",
      "Average trades per 15-min: 438.2\n",
      "Max trades in 15-min: 971\n",
      "\n",
      "=== HOURLY TRADE COUNT ===\n",
      "Total trading hours: 7\n",
      "Average trades per hour: 1565.1\n",
      "Max trades in an hour: 1807\n",
      "\n",
      "=== HOURLY BREAKDOWN ===\n",
      "09:00-09:59: 1,047 trades\n",
      "10:00-10:59: 1,476 trades\n",
      "11:00-11:59: 1,653 trades\n",
      "12:00-12:59: 1,807 trades\n",
      "13:00-13:59: 1,679 trades\n",
      "14:00-14:59: 1,521 trades\n",
      "15:00-15:59: 1,773 trades\n",
      "\n",
      "=== ACTIVITY DENSITY ANALYSIS ===\n",
      "Peak activity minute: 09:15:00 (116 trades)\n",
      "Peak activity 5-min: 15:20:00 (383 trades)\n",
      "Peak activity 15-min: 15:15:00 (971 trades)\n",
      "Peak activity hour: 12:00-12:59 (1,807 trades)\n",
      "\n",
      "=== QUIET PERIODS ANALYSIS ===\n",
      "Minutes with minimum activity (9 trades):\n",
      "  09:33:00\n",
      "  09:35:00\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total trades: 10,956\n",
      "Total active minutes: 375\n",
      "Total trading hours: 7\n",
      "Average trades per minute: 29.2\n",
      "Average trades per hour: 1565.1\n",
      "\n",
      "=== SAMPLE MINUTE-BY-MINUTE DATA (First 10 rows) ===\n",
      "           minute_key  trade_count      time\n",
      "0 2025-08-07 09:15:00          116  09:15:00\n",
      "1 2025-08-07 09:16:00           94  09:16:00\n",
      "2 2025-08-07 09:17:00           15  09:17:00\n",
      "3 2025-08-07 09:18:00           14  09:18:00\n",
      "4 2025-08-07 09:19:00           96  09:19:00\n",
      "5 2025-08-07 09:20:00           13  09:20:00\n",
      "6 2025-08-07 09:21:00           94  09:21:00\n",
      "7 2025-08-07 09:22:00          105  09:22:00\n",
      "8 2025-08-07 09:23:00           14  09:23:00\n",
      "9 2025-08-07 09:24:00           15  09:24:00\n"
     ]
    }
   ],
   "source": [
    "# Count trades per time interval (activity density)\n",
    "print(\"=== TRADE ACTIVITY DENSITY ANALYSIS ===\")\n",
    "\n",
    "# Create different time intervals for analysis\n",
    "print(\"Analyzing trade activity density across different time intervals...\")\n",
    "\n",
    "# 1. Minute-by-minute trade count\n",
    "print(\"\\n=== MINUTE-BY-MINUTE TRADE COUNT ===\")\n",
    "df['minute_key'] = df['date'].dt.floor('1min')\n",
    "minute_trades = df.groupby('minute_key').size().reset_index(name='trade_count')\n",
    "minute_trades['time'] = minute_trades['minute_key'].dt.time\n",
    "\n",
    "print(f\"Total minutes with trades: {len(minute_trades)}\")\n",
    "print(f\"Average trades per minute: {minute_trades['trade_count'].mean():.1f}\")\n",
    "print(f\"Max trades in a minute: {minute_trades['trade_count'].max()}\")\n",
    "print(f\"Min trades in a minute: {minute_trades['trade_count'].min()}\")\n",
    "\n",
    "# Display top 10 most active minutes\n",
    "print(f\"\\n=== TOP 10 MOST ACTIVE MINUTES ===\")\n",
    "top_active_minutes = minute_trades.nlargest(10, 'trade_count')\n",
    "for idx, row in top_active_minutes.iterrows():\n",
    "    print(f\"{row['time']}: {row['trade_count']} trades\")\n",
    "\n",
    "# 2. 5-minute interval trade count\n",
    "print(f\"\\n=== 5-MINUTE INTERVAL TRADE COUNT ===\")\n",
    "df['five_min_key'] = df['date'].dt.floor('5min')\n",
    "five_min_trades = df.groupby('five_min_key').size().reset_index(name='trade_count')\n",
    "five_min_trades['time'] = five_min_trades['five_min_key'].dt.time\n",
    "\n",
    "print(f\"Total 5-minute intervals: {len(five_min_trades)}\")\n",
    "print(f\"Average trades per 5-min: {five_min_trades['trade_count'].mean():.1f}\")\n",
    "print(f\"Max trades in 5-min: {five_min_trades['trade_count'].max()}\")\n",
    "\n",
    "# 3. 15-minute interval trade count\n",
    "print(f\"\\n=== 15-MINUTE INTERVAL TRADE COUNT ===\")\n",
    "df['fifteen_min_key'] = df['date'].dt.floor('15min')\n",
    "fifteen_min_trades = df.groupby('fifteen_min_key').size().reset_index(name='trade_count')\n",
    "fifteen_min_trades['time'] = fifteen_min_trades['fifteen_min_key'].dt.time\n",
    "\n",
    "print(f\"Total 15-minute intervals: {len(fifteen_min_trades)}\")\n",
    "print(f\"Average trades per 15-min: {fifteen_min_trades['trade_count'].mean():.1f}\")\n",
    "print(f\"Max trades in 15-min: {fifteen_min_trades['trade_count'].max()}\")\n",
    "\n",
    "# 4. Hourly trade count\n",
    "print(f\"\\n=== HOURLY TRADE COUNT ===\")\n",
    "df['hour_key'] = df['date'].dt.hour\n",
    "hourly_trades = df.groupby('hour_key').size().reset_index(name='trade_count')\n",
    "hourly_trades['time_range'] = hourly_trades['hour_key'].apply(lambda x: f\"{x:02d}:00-{x:02d}:59\")\n",
    "\n",
    "print(f\"Total trading hours: {len(hourly_trades)}\")\n",
    "print(f\"Average trades per hour: {hourly_trades['trade_count'].mean():.1f}\")\n",
    "print(f\"Max trades in an hour: {hourly_trades['trade_count'].max()}\")\n",
    "\n",
    "# Display hourly breakdown\n",
    "print(f\"\\n=== HOURLY BREAKDOWN ===\")\n",
    "for idx, row in hourly_trades.iterrows():\n",
    "    print(f\"{row['time_range']}: {row['trade_count']:,} trades\")\n",
    "\n",
    "# 5. Activity density analysis\n",
    "print(f\"\\n=== ACTIVITY DENSITY ANALYSIS ===\")\n",
    "\n",
    "# Find peak activity periods\n",
    "peak_minute = minute_trades.loc[minute_trades['trade_count'].idxmax()]\n",
    "peak_five_min = five_min_trades.loc[five_min_trades['trade_count'].idxmax()]\n",
    "peak_fifteen_min = fifteen_min_trades.loc[fifteen_min_trades['trade_count'].idxmax()]\n",
    "peak_hour = hourly_trades.loc[hourly_trades['trade_count'].idxmax()]\n",
    "\n",
    "print(f\"Peak activity minute: {peak_minute['time']} ({peak_minute['trade_count']} trades)\")\n",
    "print(f\"Peak activity 5-min: {peak_five_min['time']} ({peak_five_min['trade_count']} trades)\")\n",
    "print(f\"Peak activity 15-min: {peak_fifteen_min['time']} ({peak_fifteen_min['trade_count']} trades)\")\n",
    "print(f\"Peak activity hour: {peak_hour['time_range']} ({peak_hour['trade_count']:,} trades)\")\n",
    "\n",
    "# 6. Quiet periods analysis\n",
    "print(f\"\\n=== QUIET PERIODS ANALYSIS ===\")\n",
    "quiet_minutes = minute_trades[minute_trades['trade_count'] == minute_trades['trade_count'].min()]\n",
    "print(f\"Minutes with minimum activity ({minute_trades['trade_count'].min()} trades):\")\n",
    "for idx, row in quiet_minutes.head(5).iterrows():\n",
    "    print(f\"  {row['time']}\")\n",
    "\n",
    "# 7. Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "total_trades = len(df)\n",
    "total_minutes = len(minute_trades)\n",
    "total_hours = len(hourly_trades)\n",
    "\n",
    "print(f\"Total trades: {total_trades:,}\")\n",
    "print(f\"Total active minutes: {total_minutes}\")\n",
    "print(f\"Total trading hours: {total_hours}\")\n",
    "print(f\"Average trades per minute: {total_trades/total_minutes:.1f}\")\n",
    "print(f\"Average trades per hour: {total_trades/total_hours:.1f}\")\n",
    "\n",
    "# Display sample of minute-by-minute data\n",
    "print(f\"\\n=== SAMPLE MINUTE-BY-MINUTE DATA (First 10 rows) ===\")\n",
    "print(minute_trades.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f4fbac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTRADAY VOLATILITY ANALYSIS ===\n",
      "Calculating price volatility across different time intervals...\n",
      "\n",
      "=== MINUTE-BY-MINUTE VOLATILITY ===\n",
      "Total minutes analyzed: 375\n",
      "Minutes with volatility (multiple trades): 375\n",
      "Average minute volatility: ₹0.0957\n",
      "Max minute volatility: ₹0.7306\n",
      "\n",
      "=== 5-MINUTE INTERVAL VOLATILITY ===\n",
      "Total 5-minute intervals: 75\n",
      "Intervals with volatility: 75\n",
      "Average 5-min volatility: ₹0.1911\n",
      "Max 5-min volatility: ₹1.2729\n",
      "\n",
      "=== 15-MINUTE INTERVAL VOLATILITY ===\n",
      "Total 15-minute intervals: 25\n",
      "Intervals with volatility: 25\n",
      "Average 15-min volatility: ₹0.3198\n",
      "Max 15-min volatility: ₹1.3852\n",
      "\n",
      "=== HOURLY VOLATILITY ===\n",
      "Total trading hours: 7\n",
      "Average hourly volatility: ₹0.5978\n",
      "Max hourly volatility: ₹1.1315\n",
      "\n",
      "=== PEAK VOLATILITY PERIODS ===\n",
      "Highest minute volatility: 09:16:00 (₹0.7306)\n",
      "  Price range: ₹385.60 - ₹387.75\n",
      "  Trades: 94\n",
      "Highest 5-min volatility: 09:15:00 (₹1.2729)\n",
      "  Price range: ₹385.60 - ₹389.45\n",
      "Highest 15-min volatility: 09:15:00 (₹1.3852)\n",
      "  Price range: ₹385.60 - ₹390.20\n",
      "Highest hourly volatility: 09:00-09:59 (₹1.1315)\n",
      "  Price range: ₹385.60 - ₹390.20\n",
      "\n",
      "=== VOLATILITY DISTRIBUTION ANALYSIS ===\n",
      "Minute volatility percentiles:\n",
      "  25th percentile: ₹0.0611\n",
      "  50th percentile: ₹0.0832\n",
      "  75th percentile: ₹0.1143\n",
      "  90th percentile: ₹0.1575\n",
      "  95th percentile: ₹0.1931\n",
      "  99th percentile: ₹0.2773\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Overall price standard deviation: ₹1.5743\n",
      "Overall price range: ₹6.70\n",
      "Overall coefficient of variation: 0.41%\n",
      "\n",
      "=== SAMPLE MINUTE VOLATILITY DATA (First 10 rows) ===\n",
      "       time  avg_price  price_std  min_price  max_price  trade_count\n",
      "0  09:15:00   386.2414     0.2694     385.70     386.95          116\n",
      "1  09:16:00   387.0718     0.7306     385.60     387.75           94\n",
      "2  09:17:00   388.0600     0.3531     387.55     388.55           15\n",
      "3  09:18:00   389.0036     0.2742     388.45     389.45           14\n",
      "4  09:19:00   389.0891     0.0907     388.80     389.25           96\n",
      "5  09:20:00   389.1423     0.2465     388.90     389.85           13\n",
      "6  09:21:00   389.5707     0.1650     389.35     390.05           94\n",
      "7  09:22:00   389.8905     0.1754     389.50     390.20          105\n",
      "8  09:23:00   389.5607     0.2419     389.10     389.85           14\n",
      "9  09:24:00   388.7867     0.1157     388.60     389.00           15\n"
     ]
    }
   ],
   "source": [
    "# Calculate intraday volatility using standard deviation of price per minute/hour\n",
    "print(\"=== INTRADAY VOLATILITY ANALYSIS ===\")\n",
    "\n",
    "# Calculate volatility at different time intervals\n",
    "print(\"Calculating price volatility across different time intervals...\")\n",
    "\n",
    "# 1. Minute-by-minute volatility\n",
    "print(\"\\n=== MINUTE-BY-MINUTE VOLATILITY ===\")\n",
    "df['minute_key'] = df['date'].dt.floor('1min')\n",
    "minute_volatility = df.groupby('minute_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']  # Price statistics including std dev\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "minute_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "minute_volatility = minute_volatility.reset_index()\n",
    "minute_volatility['time'] = minute_volatility['minute_key'].dt.time\n",
    "\n",
    "# Filter out minutes with only 1 trade (std dev = 0 or NaN)\n",
    "minute_volatility_filtered = minute_volatility[minute_volatility['trade_count'] > 1]\n",
    "\n",
    "print(f\"Total minutes analyzed: {len(minute_volatility)}\")\n",
    "print(f\"Minutes with volatility (multiple trades): {len(minute_volatility_filtered)}\")\n",
    "print(f\"Average minute volatility: ₹{minute_volatility_filtered['price_std'].mean():.4f}\")\n",
    "print(f\"Max minute volatility: ₹{minute_volatility_filtered['price_std'].max():.4f}\")\n",
    "\n",
    "# 2. 5-minute interval volatility\n",
    "print(f\"\\n=== 5-MINUTE INTERVAL VOLATILITY ===\")\n",
    "df['five_min_key'] = df['date'].dt.floor('5min')\n",
    "five_min_volatility = df.groupby('five_min_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).round(4)\n",
    "\n",
    "five_min_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "five_min_volatility = five_min_volatility.reset_index()\n",
    "five_min_volatility['time'] = five_min_volatility['five_min_key'].dt.time\n",
    "\n",
    "five_min_filtered = five_min_volatility[five_min_volatility['trade_count'] > 1]\n",
    "\n",
    "print(f\"Total 5-minute intervals: {len(five_min_volatility)}\")\n",
    "print(f\"Intervals with volatility: {len(five_min_filtered)}\")\n",
    "print(f\"Average 5-min volatility: ₹{five_min_filtered['price_std'].mean():.4f}\")\n",
    "print(f\"Max 5-min volatility: ₹{five_min_filtered['price_std'].max():.4f}\")\n",
    "\n",
    "# 3. 15-minute interval volatility\n",
    "print(f\"\\n=== 15-MINUTE INTERVAL VOLATILITY ===\")\n",
    "df['fifteen_min_key'] = df['date'].dt.floor('15min')\n",
    "fifteen_min_volatility = df.groupby('fifteen_min_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).round(4)\n",
    "\n",
    "fifteen_min_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "fifteen_min_volatility = fifteen_min_volatility.reset_index()\n",
    "fifteen_min_volatility['time'] = fifteen_min_volatility['fifteen_min_key'].dt.time\n",
    "\n",
    "fifteen_min_filtered = fifteen_min_volatility[fifteen_min_volatility['trade_count'] > 1]\n",
    "\n",
    "print(f\"Total 15-minute intervals: {len(fifteen_min_volatility)}\")\n",
    "print(f\"Intervals with volatility: {len(fifteen_min_filtered)}\")\n",
    "print(f\"Average 15-min volatility: ₹{fifteen_min_volatility['price_std'].mean():.4f}\")\n",
    "print(f\"Max 15-min volatility: ₹{fifteen_min_volatility['price_std'].max():.4f}\")\n",
    "\n",
    "# 4. Hourly volatility\n",
    "print(f\"\\n=== HOURLY VOLATILITY ===\")\n",
    "df['hour_key'] = df['date'].dt.hour\n",
    "hourly_volatility = df.groupby('hour_key').agg({\n",
    "    'price': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).round(4)\n",
    "\n",
    "hourly_volatility.columns = ['avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']\n",
    "hourly_volatility = hourly_volatility.reset_index()\n",
    "hourly_volatility['time_range'] = hourly_volatility['hour_key'].apply(lambda x: f\"{x:02d}:00-{x:02d}:59\")\n",
    "\n",
    "print(f\"Total trading hours: {len(hourly_volatility)}\")\n",
    "print(f\"Average hourly volatility: ₹{hourly_volatility['price_std'].mean():.4f}\")\n",
    "print(f\"Max hourly volatility: ₹{hourly_volatility['price_std'].max():.4f}\")\n",
    "\n",
    "# 5. Peak volatility periods identification\n",
    "print(f\"\\n=== PEAK VOLATILITY PERIODS ===\")\n",
    "\n",
    "# Find highest volatility periods\n",
    "highest_vol_minute = minute_volatility_filtered.loc[minute_volatility_filtered['price_std'].idxmax()]\n",
    "highest_vol_five_min = five_min_filtered.loc[five_min_filtered['price_std'].idxmax()]\n",
    "highest_vol_fifteen_min = fifteen_min_filtered.loc[fifteen_min_filtered['price_std'].idxmax()]\n",
    "highest_vol_hour = hourly_volatility.loc[hourly_volatility['price_std'].idxmax()]\n",
    "\n",
    "print(f\"Highest minute volatility: {highest_vol_minute['time']} (₹{highest_vol_minute['price_std']:.4f})\")\n",
    "print(f\"  Price range: ₹{highest_vol_minute['min_price']:.2f} - ₹{highest_vol_minute['max_price']:.2f}\")\n",
    "print(f\"  Trades: {highest_vol_minute['trade_count']}\")\n",
    "\n",
    "print(f\"Highest 5-min volatility: {highest_vol_five_min['time']} (₹{highest_vol_five_min['price_std']:.4f})\")\n",
    "print(f\"  Price range: ₹{highest_vol_five_min['min_price']:.2f} - ₹{highest_vol_five_min['max_price']:.2f}\")\n",
    "\n",
    "print(f\"Highest 15-min volatility: {highest_vol_fifteen_min['time']} (₹{highest_vol_fifteen_min['price_std']:.4f})\")\n",
    "print(f\"  Price range: ₹{highest_vol_fifteen_min['min_price']:.2f} - ₹{highest_vol_fifteen_min['max_price']:.2f}\")\n",
    "\n",
    "print(f\"Highest hourly volatility: {highest_vol_hour['time_range']} (₹{highest_vol_hour['price_std']:.4f})\")\n",
    "print(f\"  Price range: ₹{highest_vol_hour['min_price']:.2f} - ₹{highest_vol_hour['max_price']:.2f}\")\n",
    "\n",
    "# 6. Volatility distribution analysis\n",
    "print(f\"\\n=== VOLATILITY DISTRIBUTION ANALYSIS ===\")\n",
    "\n",
    "# Calculate volatility percentiles\n",
    "volatility_percentiles = minute_volatility_filtered['price_std'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n",
    "print(\"Minute volatility percentiles:\")\n",
    "for p, v in volatility_percentiles.items():\n",
    "    print(f\"  {p*100:2.0f}th percentile: ₹{v:.4f}\")\n",
    "\n",
    "# 7. Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Overall price standard deviation: ₹{df['price'].std():.4f}\")\n",
    "print(f\"Overall price range: ₹{df['price'].max() - df['price'].min():.2f}\")\n",
    "print(f\"Overall coefficient of variation: {(df['price'].std() / df['price'].mean() * 100):.2f}%\")\n",
    "\n",
    "# Display sample volatility data\n",
    "print(f\"\\n=== SAMPLE MINUTE VOLATILITY DATA (First 10 rows) ===\")\n",
    "print(minute_volatility_filtered[['time', 'avg_price', 'price_std', 'min_price', 'max_price', 'trade_count']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82467e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a9292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6a4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
